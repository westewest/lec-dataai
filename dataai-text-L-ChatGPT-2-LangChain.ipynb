{"cells":[{"cell_type":"markdown","metadata":{"id":"bHZ54p4iIfem"},"source":["---\n",">「不用意にもらす言葉こそ、ほんとうらしいものをふくんでいるのだ。 」\n",">\n","> 太宰治\n","---"]},{"cell_type":"markdown","metadata":{"id":"L9HXMz2Zvn8D"},"source":["# LangChain\n","LangChainは日々更新されている\n","- これは、この授業テキスト全般に言えることであるが、特に後半は更新が頻繁に行われている\n","- アップデートにより実行できない場合もあるが、その場合は速やかに申し出ること\n","\n","その前に、OpenAPIのChat APIについて学ぶ\n","\n","なお、このノートブックは、GPUを使わないCPUランタイムを利用している\n","\n","*** 注意 ***\n","\n","ChatGPTは大人気のサービスのため負荷が集中しており、無償利用枠がかなり少なく、期限切れや、無料利用料金枠切れ、さらには、1分あたり利用は3回までという厳しい制限が課せられている\n","\n","無料料金枠などの問題は再度アカウントを取得すればよいが、1分あたり利用は3回までという制限はかなり厳しい\n","\n","例えば、次のような文章を含むエラーが出力された場合は、しばらく待って再度実行する必要がある\n","\n","```\n","WARNING:RateLimitError: Rate limit reached for default-gpt-3.5-turbo on requests per min. Limit: 3 / min. Please try again in 20s.\n","```\n","\n","したがって、無償枠の場合、このノートブックを纏めて全て実行とするとエラーになるため注意すること\n","\n","もし、まとめて実行する場合、途中で実行を待ってスロットを使いつくさないようにする必要があるため、次の設定を行うとよい"]},{"cell_type":"code","source":["import time\n","openai_wait = True"],"metadata":{"id":"WMatVzE3Xfaq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chat APIを利用する\n"],"metadata":{"id":"-dyt3hia9vY1"}},{"cell_type":"markdown","source":["## API Keyの発行\n","\n","openai.comにアクセスし、USERメニュにあるAPI keysでAPI keyを発行する\n","- セキュリティのため、プロジェクトごとに異なるキーを利用すること\n","- ここでは、dataai-keyという鍵をつくるとよい\n","- 発行された鍵をコピーしておくこと"],"metadata":{"id":"3ojZHInfAtB9"}},{"cell_type":"markdown","source":["## API Keyを使えるようにする\n","\n","発行したKeyを次のコードにペーストして利用する"],"metadata":{"id":"oCgLsK6z_wCo"}},{"cell_type":"code","source":["!pip install python-dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uY86HoG2T2jc","executionInfo":{"status":"ok","timestamp":1694772620236,"user_tz":-540,"elapsed":7188,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"cfafc98b-2490-4225-af35-a2cdc1b8ae18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.0\n"]}]},{"cell_type":"code","source":["!echo \"OPENAI_API_KEY=発行したAPI Keyをここに張り付けること\" > .env"],"metadata":{"id":"r0cuW-PeOD_s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv(verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjWTvXKWUTT9","executionInfo":{"status":"ok","timestamp":1694772629448,"user_tz":-540,"elapsed":238,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"d23e5e78-1974-4302-fe8d-87e87a38193b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["APIはOpenAI Chat APIに統一された\n","\n","モデルは、2023年夏時点で最新かつ無料で利用できる、gpt-3.5-turboを利用する"],"metadata":{"id":"pZ8jrQtABH08"}},{"cell_type":"markdown","source":["## APIを使う\n","\n","まず、ChatGPTに、挨拶して、ちゃんとAPIが使えているかどうかを確認する\n","\n","\"Hello. Am I using the API correctly?\"\n","\n","と聞いて回答を実際に得る\n","\n","必要なライブラリは、単純に次の2つ\n","- インターネットを利用して、シンプルにRESTでリクエストを投げてレスポンスを得るためのrequests\n","- JSONフォーマットを扱うためのjson"],"metadata":{"id":"McSntSfqJWVP"}},{"cell_type":"code","source":["import requests\n","import json"],"metadata":{"id":"Rr8d5MVyeTIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = \"https://api.openai.com/v1/chat/completions\"\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"]\n","}\n","data = {\n","    \"model\": \"gpt-3.5-turbo\",\n","    \"messages\": [\n","        {\"role\": \"user\", \"content\": \"Hello. Am I using the API correctly?\"}\n","    ],\n","    \"temperature\": 0,\n","}\n","\n","response = requests.post(url=url, headers=headers, json=data)\n","print(json.dumps(response.json(), indent=2))"],"metadata":{"id":"bOzgI4KGOIcj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769350757,"user_tz":-540,"elapsed":1747,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"7248abb3-0c14-437b-e926-cab32927890c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"chatcmpl-7yzDI7g6SSeBubXU97KPgQ7zAhkK6\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1694769340,\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"Hello! I'm an AI language model and I'm here to help you. Could you please provide more details about which API you are referring to and what specific issue or question you have?\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 16,\n","    \"completion_tokens\": 38,\n","    \"total_tokens\": 54\n","  }\n","}\n"]}]},{"cell_type":"markdown","source":["返事として、\"content\"にあるように、\n","\n","\"Hello! I'm an AI language model and I'm here to help you. Could you please provide more details about the API you are using and what you are trying to achieve?\"\n","\n","と返ってきた\n","\n","「こんにちは！私はAI言語モデルです。使用されているAPIの詳細と、何を達成しようとしているのかを教えていただけますか？」\n","\n","だそうだ\n","\n","なお、パラメータについて、\n","- temperatureは0に近いほど、同じ回答を出力するようになる\n","- max_tokensは返答として最大何文字返すかを指定する\n","  - ChatGPTのAPIは、利用文字数(トークン数)により課金されるため、コスト低減を考えるのであれば重要である  \n","  デフォルトは16であるが、これは通常の利用ではかなり少ないといえる\n","- nは同一質問に対する返答数を指定する  \n","  この場合temparatureを大きめの値にしなければ、同じ回答が並ぶことになる\n","\n","ひとまず使えるようになったであろう"],"metadata":{"id":"hw4z_Ng7KUco"}},{"cell_type":"markdown","source":["### エラートラブル(1)\n","\n","次のように表示される場合は、APIを利用するための無償枠を既に使い切ったか、時間が過ぎたためExpireしたことを意味する\n","\n","```\n","{\n","  \"error\": {\n","    \"message\": \"You exceeded your current quota, please check your plan and billing details.\",\n","    \"type\": \"insufficient_quota\",\n","    \"param\": null,\n","    \"code\": \"insufficient_quota\"\n","  }\n","}\n","```\n","\n","- 無償で続けたい場合は、新しいアカウントをつくるとよい\n","- もちろん、コストを支払ってもよい\n","\n","新しいアカウントをつくる\n","\n","- ただし、メールアドレスが必要となる\n","  - 既にメールアドレスが枯渇している場合は、フリーメールアドレスを取得するとよい\n","\n","- ブラウザのシークレットモードで、openai.comを開く(クッキーで既に持っているアカウント情報を利用しないようにするため)\n","\n","- 右上のメニューからLoginを選択し、Sign upを選択する\n","  - メールアドレスとパスワードを入力する\n","  - 確認メールが届くのでVerifyする\n","\n","- OpenAIのページに行くと、名前や誕生日の入力が求められる\n","\n","- スマートフォンの番号を入れて、コードを受け取る\n","  - 利用済の番号でも問題ない\n","\n","- APIをクリックして、OpenAI platformに行き、右上の丸いアイコンをクリックして個人メニューに入る\n","\n","- 左のタブでAPI Keysを選択する\n","\n","- \"Create new secret key\"を選択し、dataai-keyという鍵を作成してコピーしておく\n","\n","以上、あらたに入手した鍵を利用して再実行すること\n","- ただし5ドル分しかないので注意すること"],"metadata":{"id":"vI5oDCjZEcJb"}},{"cell_type":"markdown","source":["### エラートラブル(2)\n","\n","頻繁にアクセスすると、エラーが発生する\n","\n","これは、単位時間あたりのアクセス数が制限されているためである\n","- しばらく待ってリトライすること"],"metadata":{"id":"12TmNkeaPkMV"}},{"cell_type":"markdown","source":["### roleについて\n","\n","\"role\"は、次の3つがある\n","- userはChatGPTのユーザで、皆さんのこと\n","- assistantがChatGPTによる回答を指し、ChatGPTのこと\n","- systemはassistantのふるまいを制御するために利用\n","\n","但し、gpt-3.5-turboでは、systemは利用しない\n"],"metadata":{"id":"o6grQLKrN9xo"}},{"cell_type":"markdown","source":["## 重要なこと\n","\n","### ブラウザとの違い\n","\n","APIを利用するのと、ブラウザを利用して利用する場合と最も異なるのは、APIの利用では過去の会話のやり取りを一切考慮しないという点である\n","\n","したがって、APIを利用する場合で過去の会話を参照したい場合は、過去の会話そのものを全てmessageに記載する必要がある\n","\n","### 料金を確認すること\n","\n","https://openai.com/pricing にアクセスすると、\n","\n","| Model\t| Input\t| Output |\n","|:---|:---|:---|\n","| GPT-3.5-Turbo 4K context | \\$0.0015 / 1K tokens | \\$0.002 / 1K tokens |\n","\n","と記載されている\n","\n","現在いくらつかったかは、\n","\n","https://platform.openai.com/account/usage\n","\n","にアクセスして確認するとよい\n","\n","### トークン数\n","\n","トークンは基本的に単語数であるが、ChatGPTを含む多くのLMにおいて、膨大な単語を効率よく学習するため、一つの単語を複数のトークンに分割するということが良く行われる\n","- 例えば、\"humburger\"は、\"hum\", \"bur\", \"ger\"の3つに分解される\n","\n","また、日本語と英語ではトークン数のカウント方法が異なる\n","- 日本語は内部で英語に変換されて処理されているため\n","\n","- 日本語は1トークンはおよそ4文字、英語では主疎0.75語に相当する\n","  - 一般に直接英語を利用した方がお得といわれている\n","  - 実際2倍程度の開きがある\n","\n","このトークン数は、各モデルの入力や出力サイズの制限にも利用される\n","\n","直接文字数を計数したい場合は、https://platform.openai.com/tokenizer にアクセスして、文章を入力するとよい\n","\n","\n"],"metadata":{"id":"1LggZY0MRJ7W"}},{"cell_type":"markdown","source":["# GPT APIを用いたアプリケーション実装\n","\n","料理名を入力することで、材料と手順、調理時間、お勧めのサイドメニューなどを表示するというアプリを作成する"],"metadata":{"id":"yw6W-1k9kQ7T"}},{"cell_type":"markdown","source":["## 全体の構成\n","\n","### APIまでの通信手順\n","\n","以下の手順を踏む\n","- スマートフォンやPC、Webのアプリを利用して、レシピ名をサーバプログラムに送信する\n","- サーバプログラムは、プロンプトエンジニアリングを行い、APIキーを付与してOpenAIのAPIを叩く\n","\n","レシピ生成アプリが直接OpenAI APIを叩くような構成は、APIキーが漏えいするため普通は行わない\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/chatapi1.jpg\" width=700>"],"metadata":{"id":"toaMHvttly4S"}},{"cell_type":"markdown","source":["# LangChain"],"metadata":{"id":"AFbLFE6gqLkD"}},{"cell_type":"markdown","source":["## LangChainとは？\n","\n","LLMを使ったアプリケーション開発フレームワーク\n","- PythonとJavaScript/TypeScriptの2つがある\n","- フリーで利用できる\n","\n","詳細は公式のドキュメントを参照すること\n","- 過去のバージョンのマニュアルを見る場合は、githubにあるlangchainに行き、docsのreleasesから目的のバージョンを選択するとよい"],"metadata":{"id":"XpZ3ySBfqQGu"}},{"cell_type":"markdown","source":["## Module\n","\n","LangChainにはmoduleと呼ばれる要素があり、Models, Prompts, Chains, Indexes, Memory, Agentsである\n","\n"],"metadata":{"id":"gUfbxuHqrE-W"}},{"cell_type":"markdown","source":["### Models module\n","\n","LongChainで利用する機械学習モデルのこと\n","- Chat Models: Open AIのChatAPIのためのモジュール\n","- Text Embedding Models: テキストをベクトル化するモデル\n","\n"],"metadata":{"id":"Czl2ZbdordE3"}},{"cell_type":"markdown","source":["先に示した簡単な対話プログラムを再構成する\n","- 先ほどよりもシンプルに記述できることがわかるであろう\n","- 内部でjsonに変換され通信が行なわれている"],"metadata":{"id":"6sB2-PQgsrMO"}},{"cell_type":"code","source":["!pip install --quiet langchain openai"],"metadata":{"id":"lVxZFGSagE1C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769360520,"user_tz":-540,"elapsed":9766,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"dec7f854-5d9c-4514-86b3-c5175052269d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","result = llm.predict(\"自己紹介してください。\")\n","print(result)"],"metadata":{"id":"gJHDUhwwgKc6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769370369,"user_tz":-540,"elapsed":9853,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"86d8f866-2f78-41e4-b046-18316d2da448"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["こんにちは、私はAIです。私はOpenAIが開発した自然言語処理モデルです。私の目的は、ユーザーが質問や要求をすると、最善の回答や応答を提供することです。私は様々なトピックについての情報を持っており、文法やスタイルの修正も行うことができます。どのようにお手伝いできますか？\n"]}]},{"cell_type":"markdown","source":["### Prompts module\n","\n","モデルへの入力を組み立てるmoduleであり、次の要素がある\n","- Prompt Templates\n","- Chat Prompt Templates\n","- Example Selectors\n","- Output Parsers\n","\n","ここでは、Prompt Templatesについて説明する\n","- ChatGPTへのプロンプトについてテンプレートつまり例文を作成することができる\n","\n"],"metadata":{"id":"eVvTlTgDtQgX"}},{"cell_type":"markdown","source":["次のコードでは、commandがlsに置き換わる\n","- Promptの長さを考慮して埋め込む\n","- 出力する形式を指定して埋め込む\n","\n","などが可能であり、単純なPythonコードによる埋め込みよりも高度な処理が可能である"],"metadata":{"id":"0giJqxftt69A"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","template = \"\"\"\n","次のコマンドの概要を説明してください。\n","\n","コマンド: {command}\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"command\"],\n","    template=template,\n",")\n","\n","result = prompt.format(command=\"ls\")\n","print(result)"],"metadata":{"id":"-sZIx1e8iwJ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769370369,"user_tz":-540,"elapsed":5,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"c951d2dd-fd51-4069-c13f-3d1a7b8f2f93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","次のコマンドの概要を説明してください。\n","\n","コマンド: ls\n","\n"]}]},{"cell_type":"markdown","source":["### Chains module\n","\n","Models, Templates, Chainsなどのmoduleを連結する\n","\n","なお、LangChainの挙動の詳細を確認するため、\n","`langchain.verbose = True`\n","としている\n","- いろいろと意味のない文章や宣伝も表示されるが、不要な場合は、Falseとするとよい"],"metadata":{"id":"cI2F8zKJuV-M"}},{"cell_type":"code","source":["import langchain\n","from langchain.chains import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import PromptTemplate\n","\n","langchain.verbose = True\n","\n","# Model を用意\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","# Prompt を用意\n","template = \"\"\"\n","次のコマンドの概要を説明してください。\n","\n","コマンド: {command}\n","\"\"\"\n","prompt = PromptTemplate(\n","    input_variables=[\"command\"],\n","    template=template,\n",")\n","\n","# Chain を作成\n","chain = LLMChain(llm=chat, prompt=prompt)\n","\n","# 実行\n","result = chain.run(\"ls\")\n","print(result)"],"metadata":{"id":"9QyYR_Iixyuy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769376333,"user_tz":-540,"elapsed":5968,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"90ae1c38-e929-45d2-c580-b3c83c6bddcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3m\n","次のコマンドの概要を説明してください。\n","\n","コマンド: ls\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","lsコマンドは、UnixやUnix系のオペレーティングシステムで使用されるコマンドで、指定されたディレクトリ内のファイルやディレクトリの一覧を表示するために使用されます。デフォルトでは、現在のディレクトリの内容が表示されますが、オプションを使用して他のディレクトリの内容を表示することもできます。ファイルやディレクトリの名前、パーミッション、所有者、サイズなどの情報が表示されます。\n"]}]},{"cell_type":"markdown","source":["chain.runを用いて、構築したcheinが順に実行される\n","- 最初に文字の埋め込み(prompt)が行なわれる\n","- 次にchat modelにより実際に通信が行なわれる\n","\n","このChainには各種存在する"],"metadata":{"id":"B-A400ZJu2ws"}},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"OfIPskvyXo_3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### SimpleSequentialChain\n","\n","ChainとChainを直列に連結する\n","\n"],"metadata":{"id":"nSMyGRodvnbL"}},{"cell_type":"markdown","source":["例えば、次の例を考えてみよう\n","\n","簡単な算数の問題を問い合わせ、それに対して回答を得る場合、詳細な手順を聞くようにすると解答の精度が向上する\n","\n","しかしながら、欲しいのは最終的な答えであって、途中経過は不要であるとする\n","\n","すると、まず、詳細な手順を含む答えを得てから、その答えを要約して最後の答えだけ得るようにするとよい\n","\n","つまり、ChatGPTを2回利用して最終的に欲しい回答を獲得することになる"],"metadata":{"id":"DwtbSXduwJO-"}},{"cell_type":"code","source":["from langchain.chains import LLMChain\n","from langchain.chains import SimpleSequentialChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import PromptTemplate\n","\n","langchain.verbose = True\n","\n","# Model を用意\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","# 1 つ目の Prompt と Chain を用意\n","cot_template = \"\"\"\n","以下の質問に回答してください。\n","\n","### 質問 ###\n","{question}\n","### 質問終了 ###\n","\n","ステップバイステップで考えましょう。\n","\"\"\"\n","cot_prompt = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=cot_template,\n",")\n","cot_chain = LLMChain(llm=chat, prompt=cot_prompt)\n","\n","# 2 つ目の Prompt と Chain を用意\n","summarize_template = \"\"\"\n","入力を結論だけ抜き出して記述してください。\n","\n","### 入力 ###\n","{input}\n","### 入力終了 ###\n","\"\"\"\n","summarize_prompt = PromptTemplate(\n","    input_variables=[\"input\"],\n","    template=summarize_template,\n",")\n","summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n","\n","# 2 つの Chain を直列に繋ぐ\n","cot_summarize_chain = SimpleSequentialChain(\n","    chains=[cot_chain, summarize_chain])\n","\n","# 実行\n","result = cot_summarize_chain(\n","    \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\")\n","print(result[\"output\"])"],"metadata":{"id":"BETIBsg104QZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769443220,"user_tz":-540,"elapsed":6840,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"df7c3b98-7899-49e3-9f46-b37e8827aadd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3m\n","以下の質問に回答してください。\n","\n","### 質問 ###\n","私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\n","### 質問終了 ###\n","\n","ステップバイステップで考えましょう。\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[36;1m\u001b[1;3m1. 最初に市場で10個のリンゴを買いました。\n","2. 隣人に2つのリンゴを渡しました。残りは8個です。\n","3. 修理工に2つのリンゴを渡しました。残りは6個です。\n","4. さらに5つのリンゴを買いました。残りは11個です。\n","5. 1つのリンゴを食べました。残りは10個です。\n","\n","したがって、残りのリンゴは10個です。\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3m\n","入力を結論だけ抜き出して記述してください。\n","\n","### 入力 ###\n","1. 最初に市場で10個のリンゴを買いました。\n","2. 隣人に2つのリンゴを渡しました。残りは8個です。\n","3. 修理工に2つのリンゴを渡しました。残りは6個です。\n","4. さらに5つのリンゴを買いました。残りは11個です。\n","5. 1つのリンゴを食べました。残りは10個です。\n","\n","したがって、残りのリンゴは10個です。\n","### 入力終了 ###\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[33;1m\u001b[1;3m残りのリンゴは10個です。\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","残りのリンゴは10個です。\n"]}]},{"cell_type":"markdown","source":["なお、独自のpromptsやchains moduleを作成することも可能である\n","\n","詳細は、LangChainのマニュアル https://python.langchain.com/docs/get_started/introduction を参照されたい\n"],"metadata":{"id":"V-oQdKENxWo_"}},{"cell_type":"markdown","source":["#### Output Persers\n","\n","出力形式を指定するプロンプトの作成とPythonオブジェクトとのマッピングを提供する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/chatapi2.jpg\" width=700>"],"metadata":{"id":"CXZ034oXyCvv"}},{"cell_type":"code","source":["from langchain.chains import LLMChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.output_parsers import PydanticOutputParser\n","from langchain.prompts import PromptTemplate\n","from pydantic import BaseModel, Field, validator\n","from typing import List\n","\n","langchain.verbose = True\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","class Recipe(BaseModel):\n","    ingredients: List[str] = Field(description=\"ingredients of the dish\")\n","    steps: List[str] = Field(description=\"steps to make the dish\")\n","    time: List[str] = Field(description=\"time to make the dish\")\n","    sides: List[str] = Field(description=\"side menu of the dish\")\n","\n","template = \"\"\"料理のレシピを教えてください。\n","\n","{format_instructions}\n","\n","料理名: {dish}\n","\"\"\"\n","\n","parser = PydanticOutputParser(pydantic_object=Recipe)\n","\n","prompt = PromptTemplate(\n","    template=template,\n","    input_variables=[\"dish\"],\n","    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",")\n","\n","chain = LLMChain(llm=chat, prompt=prompt)\n","\n","output = chain.run(dish=\"カレー\")\n","print(\"=== output ===\")\n","print(output)"],"metadata":{"id":"qkm0Ys9k4t3h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769450870,"user_tz":-540,"elapsed":7656,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"8893f47c-01a2-4619-f122-1ecf76103b33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3m料理のレシピを教えてください。\n","\n","The output should be formatted as a JSON instance that conforms to the JSON schema below.\n","\n","As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n","the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n","\n","Here is the output schema:\n","```\n","{\"properties\": {\"ingredients\": {\"title\": \"Ingredients\", \"description\": \"ingredients of the dish\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"steps\": {\"title\": \"Steps\", \"description\": \"steps to make the dish\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"time\": {\"title\": \"Time\", \"description\": \"time to make the dish\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"sides\": {\"title\": \"Sides\", \"description\": \"side menu of the dish\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"ingredients\", \"steps\", \"time\", \"sides\"]}\n","```\n","\n","料理名: カレー\n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","=== output ===\n","{\n","  \"ingredients\": [\n","    \"玉ねぎ\",\n","    \"にんじん\",\n","    \"じゃがいも\",\n","    \"豚肉\",\n","    \"カレールー\",\n","    \"水\"\n","  ],\n","  \"steps\": [\n","    \"玉ねぎ、にんじん、じゃがいもを切る\",\n","    \"豚肉を炒める\",\n","    \"野菜を加えて炒める\",\n","    \"水を加えて煮込む\",\n","    \"カレールーを加えて溶かす\",\n","    \"煮込んで完成\"\n","  ],\n","  \"time\": [\n","    \"30分\"\n","  ],\n","  \"sides\": [\n","    \"ごはん\",\n","    \"フライドチキン\"\n","  ]\n","}\n"]}]},{"cell_type":"markdown","source":["最後に、recipe型にマッピングする"],"metadata":{"id":"YEJA39jxzwdW"}},{"cell_type":"code","source":["recipe = parser.parse(output)\n","print(\"=== recipe object ===\")\n","print(recipe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TW2oh6_QzrGk","executionInfo":{"status":"ok","timestamp":1694769450870,"user_tz":-540,"elapsed":6,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"5792fb7d-28ac-4181-a088-055e22eea776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== recipe object ===\n","ingredients=['玉ねぎ', 'にんじん', 'じゃがいも', '豚肉', 'カレールー', '水'] steps=['玉ねぎ、にんじん、じゃがいもを切る', '豚肉を炒める', '野菜を加えて炒める', '水を加えて煮込む', 'カレールーを加えて溶かす', '煮込んで完成'] time=['30分'] sides=['ごはん', 'フライドチキン']\n"]}]},{"cell_type":"markdown","source":["### Indexes"],"metadata":{"id":"prFUg4G3QfbA"}},{"cell_type":"markdown","source":["ChatGPTは学習に用いたデータセットの範疇でのみ答えを出すため、新しい知識や概念については、正しく解答することが難しい\n","\n","例えば、次のような質問に対しては、お手上げになっている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/langchain1.jpg\" width=500>\n","\n","ここで、質問に対する回答を得るうえで必要となる情報を渡してから処理させると、おおよそ正しい回答を得ることができるようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/langchain2.jpg\" width=500>\n"],"metadata":{"id":"p3Gp3u-hJHR_"}},{"cell_type":"markdown","source":["コンテキストとして、情報を加えることで正しい回答を与えることができており、これは強力な方法であるが、実際に用いる場合は注意が必要である\n","\n","- ChatGPTには、入力文字数に制限があるため、長い文章を入力する必要がある場合はともかく、様々な情報を大量に与えておいて、そこから適切な回答を得るという利用は困難である\n","- 文字数、つまり入力トークン数も課金に関係するため、高コストとなる\n","\n","まず、全ての情報を与えておいて、何かしら回答を得るということは非現実的であるが、自動化という点では有効な手段である\n","\n"],"metadata":{"id":"R59skBRVYMJp"}},{"cell_type":"markdown","source":["#### Vector Store\n","\n","そこで、Vector Storeを活用する\n","- 文章をベクトル化してVector Storeに保存、入力と近しいベクトルの文章をVector Storeから検索してcontextに含める手法\n","- 全文章ではなく、「大事と思われる部分文章群についてのみ」情報を与える\n","  - これには、、embeddingと呼ばれる内部ベクトル表現への変換を行い、そのベクトルの近接性を用いて、どの文章が重要かを判断している\n","  - 単語をベクトル化するトークンではない点に注意すること\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/langchain3.jpg\" width=700>\n","\n"],"metadata":{"id":"ob50Tp4IZaSW"}},{"cell_type":"markdown","source":["実際にindexを扱う\n","\n","ここでは、LangChainのドキュメントを参考にして、質問できるようにする\n","\n","最新のドキュメントはgitで公開されているため、LangChainのgitをcloneする"],"metadata":{"id":"PVg3gQRLcb2X"}},{"cell_type":"code","source":["!git clone https://github.com/hwchase17/langchain.git"],"metadata":{"id":"8VY_0R_VGcHv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769457849,"user_tz":-540,"elapsed":6984,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"9e297b5f-adcc-416e-d1d1-182bedd65f80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'langchain'...\n","remote: Enumerating objects: 66945, done.\u001b[K\n","remote: Counting objects: 100% (7800/7800), done.\u001b[K\n","remote: Compressing objects: 100% (498/498), done.\u001b[K\n","remote: Total 66945 (delta 7499), reused 7396 (delta 7300), pack-reused 59145\u001b[K\n","Receiving objects: 100% (66945/66945), 70.74 MiB | 25.34 MiB/s, done.\n","Resolving deltas: 100% (48440/48440), done.\n"]}]},{"cell_type":"markdown","source":["langchainのディレクトリに入る"],"metadata":{"id":"UdmH-q4VcpFn"}},{"cell_type":"code","source":["!cd langchain"],"metadata":{"id":"uhcQzqUqR1t3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["以降の動作確認で必要となるライブラリを導入する"],"metadata":{"id":"gK1vJgKmgpG1"}},{"cell_type":"code","source":["!pip install --quiet unstructured tabulate pdf2image pytesseract chromadb tiktoken"],"metadata":{"id":"znXiN1W1Rd8Q","executionInfo":{"status":"ok","timestamp":1694769490321,"user_tz":-540,"elapsed":32475,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c71bd34-cfb9-41fd-e962-a32710962b35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.4/422.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["まず、ディレクトリの中の全体を読むための便利なDirectoryLoaderを用いて、ある場所にあるファイルをサブディレクトリもまとめて取得する\n","- ここでは拡張子がmdであるファイルに限定している\n","\n","- そこから次々に文章を取得して、VectorstoreIndexCreatorで、Vectorsoreに格納していく\n","  - この時、embeddingと呼ばれる内部ベクトル表現への変換も同時に行っている"],"metadata":{"id":"waRfWzSLhL_p"}},{"cell_type":"code","source":["from langchain.document_loaders import DirectoryLoader\n","from langchain.indexes import VectorstoreIndexCreator\n","\n","loader = DirectoryLoader(\"./langchain/docs/\", glob=\"**/*.md\")\n","index = VectorstoreIndexCreator().from_loaders([loader])"],"metadata":{"id":"Q10Ff7vNQuV1","executionInfo":{"status":"ok","timestamp":1694769505169,"user_tz":-540,"elapsed":14853,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b3be7b7-db2f-4365-fb01-56fa59486c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"markdown","source":["では、そのvector storeを利用して、質問する\n","\n","なお、現時点でChatGPTに\"LangChain\"について問い合わせると、データセットに含まれていないという回答になる"],"metadata":{"id":"2-k97WTohvnK"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","result = index.query(\"LangChainにおけるIndex moduleについて概要を1文で説明してください。\", llm=chat)\n","print(result)"],"metadata":{"id":"mJbppn-lRblc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694769506997,"user_tz":-540,"elapsed":1831,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"9492277d-d772-4a2b-9585-7ce0d6e8dcf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n","If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","----------------\n","Integrate with LangChain: if your product integrates with LangChain–or aspires to–we want to help make sure the experience is as smooth as possible for you and end users. Send us an email at hello@langchain.dev and tell us what you’re working on.\n","Become an Integration Maintainer: Partner with our team to ensure your integration stays up-to-date and talk directly with users (and answer their inquiries) in our Discord. Introduce yourself at hello@langchain.dev if you’d like to explore this role.\n","\n","🌍 Meetups, Events, and Hackathons\n","\n","global events calendar.\n","\n","📣 Help Us Amplify Your Work\n","\n","If you’re working on something you’re proud of, and think the LangChain community would benefit from knowing about it, we want to help you show it off.\n","\n","Post about your work and mention us: we love hanging out on Twitter to see what people in the space are talking about and working on. If you tag @langchainai, we’ll almost certainly see it and can show you some love.\n","\n","Community navigator\n","\n","Hi! Thanks for being here. We’re lucky to have a community of so many passionate developers building with LangChain–we have so much to teach and learn from each other. Community members contribute code, host meetups, write blog posts, amplify each other’s work, become each other's customers and collaborators, and so much more.\n","\n","Whether you’re new to LangChain, looking to go deeper, or just want to get more exposure to the world of building with LLMs, this page can point you in the right direction.\n","\n","🦜 Contribute to LangChain\n","\n","🌍 Meetups, Events, and Hackathons\n","\n","📣 Help Us Amplify Your Work\n","\n","💬 Stay in the loop\n","\n","🦜 Contribute to LangChain\n","\n","LangChain is the product of over 5,000+ contributions by 1,500+ contributors, and there is **still**** so much to do together. Here are some ways to get involved:\n","\n","Databricks MLflow makes it more convenient to develop LangChain applications on Databricks. For MLflow tracking, you don't need to set the tracking uri. For MLflow Model Serving, you can save LangChain Chains in the MLflow langchain flavor, and then register and serve the Chain with a few clicks on Databricks, with credentials securely managed by MLflow Model Serving.\n","\n","Databricks MLflow AI Gateway\n","\n","See MLflow AI Gateway.\n","\n","Databricks as an LLM provider\n","\n","The notebook Wrap Databricks endpoints as LLMs illustrates the method to wrap Databricks endpoints as LLMs in LangChain. It supports two types of endpoints: the serving endpoint, which is recommended for both production and development, and the cluster driver proxy app, which is recommended for interactive development.\n","\n","Publish something on our blog: if you’re writing about your experience building with LangChain, we’d love to post (or crosspost) it on our blog! E-mail hello@langchain.dev with a draft of your post! Or even an idea for something you want to write about.\n","\n","Get your product onto our integrations hub: Many developers take advantage of our seamless integrations with other products, and come to our integrations hub to find out who those are. If you want to get your product up there, tell us about it (and how it works with LangChain) at hello@langchain.dev.\n","\n","☀️ Stay in the loop\n","\n","Here’s where our team hangs out, talks shop, spotlights cool work, and shares what we’re up to. We’d love to see you there too.\n","\n","Twitter: we post about what we’re working on and what cool things we’re seeing in the space. If you tag @langchainai in your post, we’ll almost certainly see it, and can show you some love!\n","\n","Discord: connect with >30k developers who are building with LangChain\n","Human: LangChainにおけるIndex moduleについて概要を1文で説明してください。\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Index moduleはLangChainの一部であり、ユーザーがデータを索引付けして検索するための機能を提供します。\n"]}]},{"cell_type":"markdown","source":["`langchain.verbose = True`のため、無意味な動作確認メッセージも表示されているが、要約文が出力されていることがわかる\n","- なお、若干回答は的を得ていない\n"],"metadata":{"id":"jFRjpFYqiJh3"}},{"cell_type":"markdown","source":["DocumentLoadersは、webサイト、GoogleDrive、Slackなどを読み込む機能が存在しているため、様々な情報をVctor Storeに格納することができる"],"metadata":{"id":"8PBuUnC4jU0_"}},{"cell_type":"markdown","source":["このように、ある特定分野のデータを一連の要素としてエンコードし、それぞれが内部で 1 つの「ベクトル」として表現している\n","- これには、単語であればWord2Vecなどが利用できるが、センテンスであるため、BERTをFine-TuningしたSentenceTransformerがある\n","- このベクトル数値は、多次元ベクトル空間で要素を相互に関連づけてマッピングしている\n","\n","ベクトル要素がセマンティックであり、ある一つの意味を表していると考えるならば、そのベクトルの近接性が文脈関係の指標となりえる\n","- このベクトルはエンベディングと呼ばれる\n","- 互いに関連性のある意味要素がまとまって配置されるようにエンベディングを行う\n","\n","特定分野の文脈によって、セマンティック要素は単語、フレーズ、センテンス、パラグラフ、文書全体、画像、あるいはまったく別のものになる可能性があり、エンベディングが最善というわけではない\n","\n","\n","\n","プロンプトで必要となる文脈を生成するため、データベースに問い合わせを行い、ベクトル空間の入力と密接に関連する要素を抽出する必要がある\n","\n","ベクトルデータストアは、大量のベクトルを保存し、問い合わせに答えるシステム\n","- 効率的な最近傍クエリアルゴリズム(k-NNなど)と適切なインデックスにより、データ検索を行う"],"metadata":{"id":"S10hxRg_kURG"}},{"cell_type":"markdown","source":["#### SentenceTransformer\n","\n","BERTのトークンごとのEmbeddingをPoolingすることで、テキストのEmbeddingを計算し、同じ意味のテキスト間のEmbeddingの距離を最小化するようにFine Tuningされている\n","\n","次の図の左のようなSBERT構造を用いて学習を行い、例えばSNLI データセットを用いる\n","- なお、ここでは分類を目的関数としている\n","- 2つのBERTネットワークは、重みが同値である(シャムネットワーク構造)\n","\n","推論時のSBERTでは、コサイン類似度を用いて2つの文章の類似度を求めるなどが可能となる\n","\n","このuおよびvが、文章AとBのembeddingということになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/sentencetransformer.png\" width=700>\n","\n","OpenAIが提供するembeddingがSentenceTransformerを採用しているというわけではないが、このような文章を意味に基づいてベクトル化する技術は以前より構築されてきた\n","\n","\n"],"metadata":{"id":"JEAtqorRJcI8"}},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"ycwwiO5ZYPm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### OpenAIのEmbedding\n","\n","では、実際にOpenAIのAPIを用いて文章のembeddingを行う\n","- 実際にはLangChainを用いていれば自動的にembeddingが行なわれるため、次に示すコードや仕組みが必要となることはない"],"metadata":{"id":"0nprWQe7NbJ6"}},{"cell_type":"code","source":["from openai.embeddings_utils import cosine_similarity\n","def text_to_embedding(text):\n","\tresponse = openai.Embedding.create(\n","    \tmodel= \"text-embedding-ada-002\",\n","    \tinput=[text]\n","\t)\n","\treturn response[\"data\"][0][\"embedding\"]"],"metadata":{"id":"Y_jLcvlINyAV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["embeddingするテキストを準備する"],"metadata":{"id":"NU6cK285N_Xw"}},{"cell_type":"code","source":["texts = [\"吾輩は猫である\", \"私は猫です\", \"データサイエンスが好きです\"]"],"metadata":{"id":"yucIY_q7N-uI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["準備したテキストのembeddingを求める"],"metadata":{"id":"suyNgET4OE-z"}},{"cell_type":"code","source":["import openai\n","embeddings = []\n","for text in texts:\n","  embeddings.append(text_to_embedding(text))"],"metadata":{"id":"sNEQw0zrOHF0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["embeddingの次元を確認すると、1536次元とわかる"],"metadata":{"id":"H8BANqGyPxtS"}},{"cell_type":"code","source":["len(embeddings[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJAI1vEAPlSO","executionInfo":{"status":"ok","timestamp":1694769568241,"user_tz":-540,"elapsed":24,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"fcb00e31-7228-49a9-969b-7cb46d9c8c9b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1536"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["実際に値を確認する\n","- ほぼ意味はないが…"],"metadata":{"id":"kwcBg_XvP-M7"}},{"cell_type":"code","source":["embeddings[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdD5hZVpQAGw","executionInfo":{"status":"ok","timestamp":1694769568241,"user_tz":-540,"elapsed":19,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"62f61658-69e7-4a50-9f04-4a81da00eecb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.0025837705470621586,\n"," -0.007356963120400906,\n"," -0.005908915773034096,\n"," -0.01717465929687023,\n"," -0.024922816082835197,\n"," 0.013363677076995373,\n"," -0.012007119134068489,\n"," -0.0196353942155838,\n"," -0.002706807106733322,\n"," -0.023597804829478264,\n"," 0.005460936110466719,\n"," 0.01487797498703003,\n"," 0.003249430563300848,\n"," -0.02796403132379055,\n"," -0.020443018525838852,\n"," -0.008353875949978828,\n"," 0.034223128110170364,\n"," -0.00903530977666378,\n"," 0.032658353447914124,\n"," -0.025200437754392624,\n"," 0.030311191454529762,\n"," -0.002498591085895896,\n"," 0.0018218894256278872,\n"," -0.013780108653008938,\n"," -0.027787363156676292,\n"," 0.008820784278213978,\n"," 0.007962682284414768,\n"," -0.028569750487804413,\n"," 0.011262589134275913,\n"," -0.013300581835210323,\n"," 0.006744934245944023,\n"," -0.011218422092497349,\n"," 0.014562495984137058,\n"," -0.015508932061493397,\n"," -0.005473555065691471,\n"," -0.018663719296455383,\n"," -0.003760505933314562,\n"," 0.004050746094435453,\n"," -0.002695765346288681,\n"," -0.00340086012147367,\n"," 0.005470400210469961,\n"," 0.0020048669539391994,\n"," -0.0025601095985621214,\n"," 0.010549607686698437,\n"," -0.02068278193473816,\n"," 0.010991277173161507,\n"," -0.035863615572452545,\n"," -0.016783466562628746,\n"," -0.0206954013556242,\n"," 0.013590821996331215,\n"," 0.021048737689852715,\n"," -0.026878783479332924,\n"," -0.02386280708014965,\n"," -0.015395360067486763,\n"," -0.024910196661949158,\n"," 0.011369851417839527,\n"," -0.014373209327459335,\n"," -0.001347093959338963,\n"," -0.017919190227985382,\n"," -0.00536944717168808,\n"," 0.0033724671229720116,\n"," 0.01480226032435894,\n"," -0.012732720002532005,\n"," 0.018323002383112907,\n"," -0.0011041753459721804,\n"," -0.005640758667141199,\n"," 0.003921400289982557,\n"," -0.005845820065587759,\n"," -0.018676338717341423,\n"," -0.007035174872726202,\n"," 0.02227279543876648,\n"," -0.0011925094295293093,\n"," 0.016303937882184982,\n"," -0.019420867785811424,\n"," 0.021629218012094498,\n"," 0.022600892931222916,\n"," -0.02217184193432331,\n"," 0.009571623057126999,\n"," -0.012209025211632252,\n"," -0.013426773250102997,\n"," 0.02395114116370678,\n"," -0.021250644698739052,\n"," 0.00700362678617239,\n"," 0.0006490973755717278,\n"," 0.01655632071197033,\n"," 0.014537258073687553,\n"," -0.022739702835679054,\n"," 0.035863615572452545,\n"," 0.00196858705021441,\n"," -0.016139889135956764,\n"," 0.012909388169646263,\n"," 0.025844013318419456,\n"," 0.0040286630392074585,\n"," 0.044949404895305634,\n"," -0.006826958619058132,\n"," -0.0006778848473913968,\n"," 0.005707009229809046,\n"," 0.018411336466670036,\n"," 0.00030305670225061476,\n"," -0.03942221775650978,\n"," -0.006864816416054964,\n"," 0.012739029712975025,\n"," -0.021667076274752617,\n"," 0.0003286893479526043,\n"," -0.019648011773824692,\n"," -0.0034481820184737444,\n"," 0.0023629353381693363,\n"," 0.004495571367442608,\n"," 0.006517789792269468,\n"," -0.01978682354092598,\n"," 0.009842935018241405,\n"," 0.02872117981314659,\n"," 0.014347970485687256,\n"," -0.0462365560233593,\n"," -0.018259907141327858,\n"," -0.00995019730180502,\n"," 0.013035579584538937,\n"," -0.01275164820253849,\n"," -0.02483448199927807,\n"," -0.0043315221555531025,\n"," 0.011647473089396954,\n"," 0.006319038104265928,\n"," 0.011268898844718933,\n"," 0.004918312653899193,\n"," 0.027661170810461044,\n"," 0.012619147077202797,\n"," -0.01408296823501587,\n"," -0.022045651450753212,\n"," -0.006517789792269468,\n"," -0.002888207323849201,\n"," 0.022764941677451134,\n"," -0.014739164151251316,\n"," 0.021995173767209053,\n"," 0.02816593647003174,\n"," -0.012051286175847054,\n"," 0.02483448199927807,\n"," -0.021768029779195786,\n"," 0.005587127525359392,\n"," -0.0025758834090083838,\n"," -0.02374923601746559,\n"," 0.005732247605919838,\n"," 0.013351057656109333,\n"," -0.007886966690421104,\n"," -0.0019575452897697687,\n"," 0.030765481293201447,\n"," 0.011066991835832596,\n"," 0.02791355364024639,\n"," -0.01104806363582611,\n"," -0.006883745081722736,\n"," -0.003293597372248769,\n"," 0.008341256529092789,\n"," -0.002855082042515278,\n"," 0.03207787126302719,\n"," -0.016682513058185577,\n"," 0.015862267464399338,\n"," 0.021238025277853012,\n"," -0.003344074124470353,\n"," 0.03227977827191353,\n"," 0.004240033682435751,\n"," 0.0041990214958786964,\n"," 0.0029307969380170107,\n"," 0.017553234472870827,\n"," 0.041466519236564636,\n"," -0.027661170810461044,\n"," 0.0143858278170228,\n"," 0.03727696090936661,\n"," 0.016859181225299835,\n"," -0.0045018806122243404,\n"," -0.0021310586016625166,\n"," 0.007262319326400757,\n"," 0.0062243943102657795,\n"," 0.021932078525424004,\n"," -0.001624715281650424,\n"," 0.03200215846300125,\n"," -0.008461138233542442,\n"," 0.016228223219513893,\n"," -0.01728823222219944,\n"," 0.0035491352900862694,\n"," -0.015496312640607357,\n"," -0.017098944634199142,\n"," -0.04376320168375969,\n"," 0.014259636402130127,\n"," 0.007287557702511549,\n"," -0.0010686840396374464,\n"," 0.0015600421465933323,\n"," -0.010101627558469772,\n"," 0.008808164857327938,\n"," 0.010126865468919277,\n"," 0.016669893637299538,\n"," -0.016657274216413498,\n"," 0.017868712544441223,\n"," 0.04361177235841751,\n"," 0.018537526950240135,\n"," 0.0053757568821311,\n"," -0.6186410784721375,\n"," -0.026045920327305794,\n"," 0.00451134517788887,\n"," 0.00740113016217947,\n"," 0.01637965254485607,\n"," 0.01354034524410963,\n"," -0.017515376210212708,\n"," 0.012713790871202946,\n"," -0.00412646122276783,\n"," 0.025162579491734505,\n"," -0.01150235254317522,\n"," 0.013086056336760521,\n"," 0.015862267464399338,\n"," -0.008530544117093086,\n"," -0.00268472358584404,\n"," -0.028468796983361244,\n"," -0.0010150526650249958,\n"," -0.004609143827110529,\n"," -0.0132374856621027,\n"," -0.005088671110570431,\n"," -0.0025585321709513664,\n"," -0.0016625727294012904,\n"," -0.01728823222219944,\n"," -0.0034608012065291405,\n"," 0.019345153123140335,\n"," 0.014461543411016464,\n"," 0.0071298182010650635,\n"," -0.010328772477805614,\n"," -0.010120556689798832,\n"," 0.03273406997323036,\n"," -0.030942149460315704,\n"," 0.026702115312218666,\n"," 0.019256819039583206,\n"," -0.008467447943985462,\n"," 0.045580361038446426,\n"," -0.00017065425345208496,\n"," -0.0011727920500561595,\n"," 0.03699934110045433,\n"," -0.002806182950735092,\n"," 0.007230771705508232,\n"," -0.02239898592233658,\n"," -0.03053833730518818,\n"," 0.010114246979355812,\n"," -0.0037037197034806013,\n"," -0.01641751080751419,\n"," -0.010846157558262348,\n"," 0.0230551827698946,\n"," -0.015937983989715576,\n"," 0.007937443442642689,\n"," 0.027837838977575302,\n"," -0.01639227196574211,\n"," -0.024342335760593414,\n"," 0.003246275708079338,\n"," -0.005394685547798872,\n"," -0.0035333612468093634,\n"," 0.004527118988335133,\n"," 0.019231580197811127,\n"," -0.035888854414224625,\n"," -0.009129953570663929,\n"," 0.004085449036210775,\n"," 0.005823736544698477,\n"," 0.016644654795527458,\n"," 0.0035712188109755516,\n"," 0.022752322256565094,\n"," -0.006744934245944023,\n"," 0.016897037625312805,\n"," -0.02555377408862114,\n"," 0.002795141190290451,\n"," 0.0328097827732563,\n"," 0.0038898522034287453,\n"," -0.0012958287261426449,\n"," -0.01158437691628933,\n"," -0.01518083456903696,\n"," 0.01576131582260132,\n"," 0.02629830315709114,\n"," 0.021704932674765587,\n"," 0.0008533698273822665,\n"," -0.013691774569451809,\n"," -0.013048198074102402,\n"," -0.02058183029294014,\n"," 0.0006329290918074548,\n"," -0.009445431642234325,\n"," -0.01640489138662815,\n"," -0.0009140995098277926,\n"," -0.0007106157136149704,\n"," -0.023332804441452026,\n"," -0.02458209916949272,\n"," 0.004258962348103523,\n"," 0.013515107333660126,\n"," -0.0005071319756098092,\n"," -0.011735807172954082,\n"," 0.0009898144053295255,\n"," 0.007035174872726202,\n"," -0.0222475565969944,\n"," -0.010877705179154873,\n"," 0.01579917222261429,\n"," -0.02632354199886322,\n"," -0.02142731286585331,\n"," 0.002785676857456565,\n"," -0.007653512991964817,\n"," -0.012082833796739578,\n"," 0.004940396174788475,\n"," 0.010051150806248188,\n"," -0.008120421320199966,\n"," 0.00576379569247365,\n"," -0.0013573470059782267,\n"," -0.03457646444439888,\n"," -0.011805212125182152,\n"," -0.0011278362944722176,\n"," -0.023471614345908165,\n"," 0.018297763541340828,\n"," 0.001260337303392589,\n"," 0.004997182171791792,\n"," -0.004987718071788549,\n"," 0.0054356977343559265,\n"," -0.021200167015194893,\n"," 0.032658353447914124,\n"," 0.020379923284053802,\n"," 0.017818236723542213,\n"," 0.0075273215770721436,\n"," 0.024392811581492424,\n"," 0.02313089743256569,\n"," 0.027358312159776688,\n"," -0.018297763541340828,\n"," 0.002874010941013694,\n"," 0.02541496232151985,\n"," -0.010202581062912941,\n"," -0.006164453458040953,\n"," -0.01981206238269806,\n"," 0.01978682354092598,\n"," 0.0016562631353735924,\n"," -0.01408296823501587,\n"," 0.007237080950289965,\n"," -0.020089682191610336,\n"," -0.008852331899106503,\n"," -0.004482951946556568,\n"," 0.03154786676168442,\n"," -0.015887506306171417,\n"," 0.026878783479332924,\n"," 0.013111294247210026,\n"," -0.014272255823016167,\n"," 0.00014472584007307887,\n"," -0.02222231775522232,\n"," 0.010322462767362595,\n"," 0.016846561804413795,\n"," 0.0019480808405205607,\n"," 0.005536650773137808,\n"," -0.013717013411223888,\n"," 0.0029828508850187063,\n"," 0.02147778868675232,\n"," -0.004971944261342287,\n"," -0.001971741672605276,\n"," -0.008763997815549374,\n"," 0.012789505533874035,\n"," 0.03121977113187313,\n"," 0.0027383549604564905,\n"," -0.030916910618543625,\n"," -0.007287557702511549,\n"," -0.0039971149526536465,\n"," 0.004801585804671049,\n"," 0.013300581835210323,\n"," 0.008732450194656849,\n"," -0.014221779070794582,\n"," 0.0047069420106709,\n"," -0.0031058876775205135,\n"," -0.024291858077049255,\n"," -0.010801990516483784,\n"," 0.02955404296517372,\n"," -0.02472090907394886,\n"," -0.02710592932999134,\n"," -0.02228541485965252,\n"," 0.008801855146884918,\n"," 0.0008454828639514744,\n"," -0.01066317968070507,\n"," 0.006391598377376795,\n"," -0.006927912123501301,\n"," 0.013918919488787651,\n"," -0.01114270742982626,\n"," -0.012429860420525074,\n"," -0.027004975825548172,\n"," 0.010473892092704773,\n"," -0.012499265372753143,\n"," -0.0021184394136071205,\n"," -0.017527995631098747,\n"," -0.005189624149352312,\n"," -0.002864546375349164,\n"," 0.010385558009147644,\n"," 0.008473757654428482,\n"," -0.01807061955332756,\n"," 0.013464630581438541,\n"," -0.013729632832109928,\n"," 0.02639925666153431,\n"," -0.01635441556572914,\n"," 0.02130112051963806,\n"," 0.007438987493515015,\n"," -0.018575385212898254,\n"," 0.03687315061688423,\n"," 0.020241113379597664,\n"," 0.011401399970054626,\n"," 0.02154088392853737,\n"," -0.021250644698739052,\n"," 0.00393401924520731,\n"," 0.005789034068584442,\n"," -0.02049349620938301,\n"," 0.016758227720856667,\n"," -0.04881086200475693,\n"," 0.0008817629422992468,\n"," 0.010309843346476555,\n"," 0.016859181225299835,\n"," 0.016001079231500626,\n"," -0.026979736983776093,\n"," 0.0007232349016703665,\n"," -0.011338303796947002,\n"," -0.01814633421599865,\n"," 0.022790180519223213,\n"," 0.036646004766225815,\n"," -8.976354729384184e-05,\n"," 0.007653512991964817,\n"," -0.002440227661281824,\n"," -0.0011404554825276136,\n"," 0.0028361533768475056,\n"," 0.006240168586373329,\n"," -0.020430399104952812,\n"," -0.016682513058185577,\n"," 0.0023865962866693735,\n"," 0.011483424343168736,\n"," -0.009085786528885365,\n"," 0.04512606933712959,\n"," -0.0038961616810411215,\n"," 0.0018313537584617734,\n"," -0.048129428178071976,\n"," -0.01812109537422657,\n"," 0.008663044311106205,\n"," 0.01637965254485607,\n"," -0.012095453217625618,\n"," -0.03303692862391472,\n"," 0.023332804441452026,\n"," -0.013325819745659828,\n"," 0.037453629076480865,\n"," 0.012032357044517994,\n"," 0.0042463429272174835,\n"," 0.0015852804062888026,\n"," 0.005536650773137808,\n"," -0.017641568556427956,\n"," -0.0019149556756019592,\n"," 0.03212834894657135,\n"," 0.033314548432826996,\n"," 0.016632037237286568,\n"," -0.010820918716490269,\n"," 0.031800251454114914,\n"," -0.021868983283638954,\n"," -0.00870721135288477,\n"," -0.001531649031676352,\n"," 0.0002677625452633947,\n"," -0.006467313040047884,\n"," -0.03210311010479927,\n"," -0.016707751899957657,\n"," 0.0048142047598958015,\n"," 0.029528804123401642,\n"," 0.03147215396165848,\n"," 0.026045920327305794,\n"," 0.025705203413963318,\n"," 0.0010071657598018646,\n"," -0.001083669252693653,\n"," 0.007287557702511549,\n"," 0.006050880998373032,\n"," 0.006240168586373329,\n"," -0.021831125020980835,\n"," -0.012480337172746658,\n"," -0.02634877897799015,\n"," -0.03278454393148422,\n"," -0.01571083813905716,\n"," 0.007287557702511549,\n"," -0.03127024695277214,\n"," 0.023332804441452026,\n"," -0.009180429391562939,\n"," -0.004271581303328276,\n"," 0.0004870202101301402,\n"," 0.0165310837328434,\n"," 0.009527456015348434,\n"," -0.01894134096801281,\n"," -0.05577663332223892,\n"," -0.0025569547433406115,\n"," -0.00044640235137194395,\n"," 0.004546047654002905,\n"," -0.02055659145116806,\n"," -0.014423685148358345,\n"," -0.0034355628304183483,\n"," -0.0190170556306839,\n"," 0.019471343606710434,\n"," 0.02458209916949272,\n"," 0.0082339933142066,\n"," 0.0165310837328434,\n"," 0.0012966174399480224,\n"," -0.00825923215597868,\n"," 0.027837838977575302,\n"," 0.03717600926756859,\n"," -0.0264749713242054,\n"," -0.04767514020204544,\n"," 0.0024780849926173687,\n"," 0.008593639358878136,\n"," -0.011767354793846607,\n"," -0.006713386625051498,\n"," 0.0020206409972161055,\n"," 0.007306486368179321,\n"," -0.00902900006622076,\n"," -0.0205061137676239,\n"," -0.004148544743657112,\n"," 0.0024670432321727276,\n"," -0.012013427913188934,\n"," -0.020077062770724297,\n"," -0.011729497462511063,\n"," -0.028367843478918076,\n"," -0.02049349620938301,\n"," -0.030790720134973526,\n"," 0.0028519274201244116,\n"," -0.011798902414739132,\n"," -0.0014062462141737342,\n"," 0.044066064059734344,\n"," -0.0014054575003683567,\n"," -0.009931269101798534,\n"," -0.004833133425563574,\n"," -0.037504106760025024,\n"," -0.013565583154559135,\n"," 0.055574726313352585,\n"," -0.0007815984426997602,\n"," -0.008423280902206898,\n"," -0.004183247219771147,\n"," 0.016202984377741814,\n"," -0.013060817494988441,\n"," -0.02049349620938301,\n"," -0.02132635936141014,\n"," 0.011363542638719082,\n"," -0.007356963120400906,\n"," -0.0065935044549405575,\n"," 0.0010197848314419389,\n"," 0.026096396148204803,\n"," -0.013843204826116562,\n"," 0.003053833730518818,\n"," 0.0001608941238373518,\n"," -0.03154786676168442,\n"," -0.012057594954967499,\n"," 0.01725037395954132,\n"," -0.021566122770309448,\n"," 0.0035522899124771357,\n"," -7.655287481611595e-05,\n"," 0.032532162964344025,\n"," 0.017666805535554886,\n"," -0.032607875764369965,\n"," -0.015092500485479832,\n"," 0.01643013022840023,\n"," 0.0328097827732563,\n"," 0.016606798395514488,\n"," -0.026045920327305794,\n"," 0.0013825853820890188,\n"," -0.0074137491174042225,\n"," -0.03381931409239769,\n"," -0.008025777526199818,\n"," -0.0019401939352974296,\n"," 0.0011104849399998784,\n"," -0.024455906823277473,\n"," 0.057997602969408035,\n"," 0.0001141638495028019,\n"," -0.0009093672852031887,\n"," 0.019648011773824692,\n"," 0.025149960070848465,\n"," 0.008581019937992096,\n"," 0.003877233015373349,\n"," 0.008581019937992096,\n"," -0.02133897878229618,\n"," 0.007804942782968283,\n"," 0.02126326411962509,\n"," 0.0032178827095776796,\n"," -0.02054397203028202,\n"," 0.029124991968274117,\n"," -0.008038396947085857,\n"," -0.03404645994305611,\n"," -0.00824030302464962,\n"," 0.0024717755150049925,\n"," 0.03397074341773987,\n"," -0.0070793419145047665,\n"," -0.013780108653008938,\n"," -0.004577595740556717,\n"," 0.01635441556572914,\n"," 0.007773394696414471,\n"," -0.0062559423968195915,\n"," -0.0123036690056324,\n"," -0.008997452445328236,\n"," -0.007628274615854025,\n"," -0.03399598225951195,\n"," -0.008505305275321007,\n"," -0.020405162125825882,\n"," -0.03712553158402443,\n"," -0.014688687399029732,\n"," -0.017452280968427658,\n"," -0.020834213122725487,\n"," -0.016960134729743004,\n"," -0.03222930431365967,\n"," 0.0032525851856917143,\n"," 0.02468305267393589,\n"," 0.016796085983514786,\n"," -0.015370121225714684,\n"," -0.014928451739251614,\n"," 0.03475313261151314,\n"," -0.010612702928483486,\n"," -0.01972372829914093,\n"," 0.01713680289685726,\n"," -0.04444463551044464,\n"," -0.01487797498703003,\n"," 0.015117738395929337,\n"," 0.007716608699411154,\n"," -0.013086056336760521,\n"," 0.020291589200496674,\n"," 0.0029244874604046345,\n"," 0.022676607593894005,\n"," -0.015042023733258247,\n"," 0.014764402061700821,\n"," 0.022840656340122223,\n"," 0.01399463415145874,\n"," -0.016695132479071617,\n"," -0.0030349050648510456,\n"," -0.007256009615957737,\n"," -0.028569750487804413,\n"," -0.023370660841464996,\n"," 0.0360402837395668,\n"," -0.03215358778834343,\n"," -0.020834213122725487,\n"," -0.020367303863167763,\n"," 0.015130357816815376,\n"," 0.004205330740660429,\n"," 0.03470265492796898,\n"," 0.007110889535397291,\n"," -0.018297763541340828,\n"," 3.2256464237434557e-06,\n"," 0.019925633445382118,\n"," -0.02048087678849697,\n"," 0.03187596797943115,\n"," -0.007142437621951103,\n"," 0.0007685849559493363,\n"," 0.03472789376974106,\n"," -0.008789235725998878,\n"," 0.04285462573170662,\n"," 0.005454626400023699,\n"," -0.022878514602780342,\n"," -0.0011507085291668773,\n"," 0.001616828260011971,\n"," 0.029427852481603622,\n"," 0.032582636922597885,\n"," -0.006978388410061598,\n"," -0.0021137071307748556,\n"," 0.000315478682750836,\n"," -0.0023708222433924675,\n"," -0.013578202575445175,\n"," -0.00950852781534195,\n"," 0.007975300773978233,\n"," 0.036570288240909576,\n"," -0.012511884793639183,\n"," -0.04219843074679375,\n"," -0.042551763355731964,\n"," 0.008082563988864422,\n"," -0.006669219583272934,\n"," 0.021162310615181923,\n"," -0.006199156399816275,\n"," -0.01892872154712677,\n"," -0.03351645544171333,\n"," 0.0019023364875465631,\n"," -0.003981341142207384,\n"," -0.007262319326400757,\n"," -0.001990670571103692,\n"," -0.03874078392982483,\n"," -0.02290375344455242,\n"," 0.012865221127867699,\n"," 0.018550146371126175,\n"," 0.009344479069113731,\n"," -0.0031311260536313057,\n"," 0.009792458266019821,\n"," -0.006120286416262388,\n"," -0.004665929824113846,\n"," 0.009243525564670563,\n"," -0.047296565026044846,\n"," -0.009350787848234177,\n"," -0.01036032009869814,\n"," 0.002790408907458186,\n"," 0.01656894013285637,\n"," 0.009085786528885365,\n"," -0.0011814676690846682,\n"," 0.00394032895565033,\n"," -0.015508932061493397,\n"," -0.001578182098455727,\n"," 0.005672306753695011,\n"," -0.0007445297087542713,\n"," 0.012682243250310421,\n"," -0.014108207076787949,\n"," 0.023660901933908463,\n"," 0.017805617302656174,\n"," 0.017856093123555183,\n"," 0.011779974214732647,\n"," -0.005965701770037413,\n"," -0.011464495211839676,\n"," 0.02377447299659252,\n"," 0.000558791623916477,\n"," -0.005811117589473724,\n"," -0.019395628944039345,\n"," -0.04555512219667435,\n"," 0.013502487912774086,\n"," -0.0005051602493040264,\n"," 0.026601163670420647,\n"," -0.004523964133113623,\n"," 0.014701306819915771,\n"," -0.004378844052553177,\n"," 0.006467313040047884,\n"," -0.019383009523153305,\n"," 0.017666805535554886,\n"," -0.003426098497584462,\n"," 0.036519814282655716,\n"," -0.030008332803845406,\n"," 0.0060918936505913734,\n"," -0.025793537497520447,\n"," 0.0012753226328641176,\n"," -0.013792728073894978,\n"," -0.006019333377480507,\n"," 0.02304256334900856,\n"," 0.02391328476369381,\n"," 0.01114270742982626,\n"," -0.0014243862824514508,\n"," 0.022689227014780045,\n"," -0.008530544117093086,\n"," -0.0009519569575786591,\n"," 0.01891610212624073,\n"," 0.01650584489107132,\n"," -0.015471074730157852,\n"," -0.018550146371126175,\n"," 0.023635663092136383,\n"," -0.021742790937423706,\n"," -0.014562495984137058,\n"," -0.025162579491734505,\n"," -0.036620765924453735,\n"," -0.035156942903995514,\n"," -0.0006707865395583212,\n"," 0.002615318400785327,\n"," -0.03046262264251709,\n"," 0.02468305267393589,\n"," -0.004722715821117163,\n"," -0.01990039460361004,\n"," -0.013439391739666462,\n"," 0.003249430563300848,\n"," 0.01399463415145874,\n"," -0.015534170903265476,\n"," 0.021174930036067963,\n"," 0.03205263614654541,\n"," 0.0019275747472420335,\n"," -0.015950601547956467,\n"," -0.0626414492726326,\n"," -0.006599814165383577,\n"," -0.016871800646185875,\n"," 0.017969666048884392,\n"," 0.03881649672985077,\n"," -0.0041138422675430775,\n"," -0.008202445693314075,\n"," 0.007249700371176004,\n"," 0.013060817494988441,\n"," -0.028973562642931938,\n"," -0.04068413004279137,\n"," 0.005940463859587908,\n"," 0.01564774289727211,\n"," -0.009615790098905563,\n"," 0.006700767204165459,\n"," 0.019420867785811424,\n"," 0.006350585725158453,\n"," 0.028973562642931938,\n"," -0.017818236723542213,\n"," -0.019458726048469543,\n"," -0.044116538017988205,\n"," -0.004738489631563425,\n"," -0.015130357816815376,\n"," 0.005902606062591076,\n"," -0.008101492188870907,\n"," 0.01322486624121666,\n"," -0.020998261868953705,\n"," -0.007173985242843628,\n"," -0.0007610923494212329,\n"," -0.019244199618697166,\n"," -0.01563512347638607,\n"," -0.0005832412280142307,\n"," -0.010114246979355812,\n"," 0.03894268721342087,\n"," 0.013313200324773788,\n"," 0.005647068377584219,\n"," 0.009836625307798386,\n"," 0.0037888989318162203,\n"," -0.013414153829216957,\n"," -0.006350585725158453,\n"," -0.022865895181894302,\n"," 0.04850800335407257,\n"," 0.01393153890967369,\n"," 0.016177747398614883,\n"," -0.035081230103969574,\n"," 0.007262319326400757,\n"," 0.018638480454683304,\n"," -0.0020111766643822193,\n"," 0.008991142734885216,\n"," 0.017805617302656174,\n"," -0.02634877897799015,\n"," -0.00490884855389595,\n"," 0.029175469651818275,\n"," -0.01439844723790884,\n"," 0.010499130934476852,\n"," -0.014423685148358345,\n"," -0.017023229971528053,\n"," 0.0035365161020308733,\n"," -0.021137071773409843,\n"," -0.00023858076019678265,\n"," -0.005662842188030481,\n"," 0.0015001011779531837,\n"," 0.0035649091005325317,\n"," -0.0021799576934427023,\n"," -0.004224259406328201,\n"," 0.015483694151043892,\n"," -0.016127269715070724,\n"," -0.01804538071155548,\n"," 0.020783735439181328,\n"," 0.02392590418457985,\n"," -0.018247287720441818,\n"," 0.017742522060871124,\n"," -0.013477249071002007,\n"," 0.005968856625258923,\n"," -0.008398042991757393,\n"," 0.00987448263913393,\n"," 0.021856363862752914,\n"," -0.014095587655901909,\n"," 0.014650830067694187,\n"," -0.011029134504497051,\n"," -0.02141469344496727,\n"," -0.03477837145328522,\n"," -6.965178181417286e-05,\n"," 0.017086325213313103,\n"," 0.01036032009869814,\n"," 0.01486535556614399,\n"," 0.025301391258835793,\n"," 0.02403947524726391,\n"," 0.011338303796947002,\n"," -0.009653647430241108,\n"," -0.016152508556842804,\n"," 0.0036532431840896606,\n"," 0.0027131165843456984,\n"," 0.003135858103632927,\n"," 0.0019118008203804493,\n"," -0.028594987466931343,\n"," 0.030084047466516495,\n"," -0.0018140024039894342,\n"," -0.017628949135541916,\n"," 0.003959257621318102,\n"," -0.003779434598982334,\n"," -0.0348036102950573,\n"," -0.011660092510282993,\n"," 0.015950601547956467,\n"," -0.01968587003648281,\n"," -0.04030555859208107,\n"," -0.009798767976462841,\n"," -0.019231580197811127,\n"," 0.0010142639512196183,\n"," 0.010398177430033684,\n"," -0.004053900949656963,\n"," 0.009439121931791306,\n"," -0.0006285912822932005,\n"," 0.017944427207112312,\n"," -0.006864816416054964,\n"," -0.0054356977343559265,\n"," -0.006883745081722736,\n"," -0.015105119906365871,\n"," 0.01150235254317522,\n"," -0.0007141648675315082,\n"," -0.026803068816661835,\n"," -0.0036532431840896606,\n"," -0.044015586376190186,\n"," 0.025276152417063713,\n"," 0.0014299071626737714,\n"," -0.0038046729750931263,\n"," -0.026777829974889755,\n"," 0.008896498940885067,\n"," -0.025995444506406784,\n"," 0.0005386798293329775,\n"," -0.009281382896006107,\n"," 0.01890348270535469,\n"," -0.008328637108206749,\n"," -0.009641028940677643,\n"," 0.007741847075521946,\n"," 0.013250105082988739,\n"," -0.01027198601514101,\n"," -0.008189826272428036,\n"," -0.021957317367196083,\n"," -0.012486645951867104,\n"," 0.004230569116771221,\n"," -0.01268855296075344,\n"," 0.015975840389728546,\n"," -0.003041214542463422,\n"," 0.0008249767706729472,\n"," -0.0164679866284132,\n"," 0.025970205664634705,\n"," -0.0007906684768386185,\n"," 0.007968991994857788,\n"," 0.015849649906158447,\n"," -0.016796085983514786,\n"," 0.018550146371126175,\n"," -0.02308041974902153,\n"," -0.00863149669021368,\n"," 0.0051549216732382774,\n"," -0.0035712188109755516,\n"," 0.01114901714026928,\n"," -0.01726299338042736,\n"," -0.014234398491680622,\n"," 0.0008612567908130586,\n"," 0.014953689649701118,\n"," -0.0024859721306711435,\n"," -0.010682107880711555,\n"," 0.012581289745867252,\n"," -0.010467582382261753,\n"," 0.01900443620979786,\n"," -0.008151968941092491,\n"," -0.00865673553198576,\n"," -0.017098944634199142,\n"," -0.013439391739666462,\n"," 0.009546385146677494,\n"," -0.0037131840363144875,\n"," 0.010025912895798683,\n"," 0.030664527788758278,\n"," -0.025200437754392624,\n"," -0.012423550710082054,\n"," -0.030058808624744415,\n"," 0.02301732450723648,\n"," 0.012026047334074974,\n"," 0.017452280968427658,\n"," 0.021162310615181923,\n"," 0.0005745655507780612,\n"," 0.025238294154405594,\n"," -0.00359961180947721,\n"," 0.01567298173904419,\n"," -0.044091302901506424,\n"," -0.008006849326193333,\n"," 0.007293867412954569,\n"," -0.0012374651851132512,\n"," -0.023257087916135788,\n"," 0.016720369458198547,\n"," 0.01189354620873928,\n"," -0.005748021882027388,\n"," -0.009363407269120216,\n"," -0.0032715140841901302,\n"," -0.001695697894319892,\n"," -0.0016483761137351394,\n"," -0.026828307658433914,\n"," 0.013805347494781017,\n"," -0.0019133782479912043,\n"," 0.0006143947248347104,\n"," -0.004571286030113697,\n"," -0.008814474567770958,\n"," -0.021629218012094498,\n"," -0.017957046627998352,\n"," -0.0057701049372553825,\n"," 0.0026358244940638542,\n"," 0.01723775453865528,\n"," 0.2881203591823578,\n"," -0.026702115312218666,\n"," 0.01361605990678072,\n"," 0.018701575696468353,\n"," 0.006833268329501152,\n"," 0.010480201803147793,\n"," 0.04136556386947632,\n"," -0.010492821224033833,\n"," 0.006306419149041176,\n"," 0.02892308682203293,\n"," -0.008928046561777592,\n"," 0.010991277173161507,\n"," 0.0071298182010650635,\n"," 0.015811791643500328,\n"," 0.01065056025981903,\n"," -0.031699299812316895,\n"," -0.012051286175847054,\n"," 0.006186536978930235,\n"," -0.02300470508635044,\n"," -0.01361605990678072,\n"," 0.0005481442203745246,\n"," -0.0006589561235159636,\n"," 0.009672576561570168,\n"," -0.0008715098956599832,\n"," 0.0032715140841901302,\n"," 0.023332804441452026,\n"," -0.024203523993492126,\n"," -0.013982015661895275,\n"," -0.0026405565440654755,\n"," 0.009363407269120216,\n"," -0.01972372829914093,\n"," 0.0009645760874263942,\n"," -0.0007788380025885999,\n"," -0.010057460516691208,\n"," -0.00413277093321085,\n"," -0.0032163052819669247,\n"," 0.01892872154712677,\n"," 0.007760775741189718,\n"," 0.021137071773409843,\n"," 0.0025837705470621586,\n"," -0.02213398367166519,\n"," -0.001086824107915163,\n"," 0.007962682284414768,\n"," 0.013187008909881115,\n"," -0.019193723797798157,\n"," 0.033314548432826996,\n"," ...]"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["コサイン類似度を用いて類似度を求める\n","- OpenAIのライブラリが提供しているcosine_similarity関数を利用する"],"metadata":{"id":"qwYEc_WjO1Tk"}},{"cell_type":"markdown","source":["最初の2つの文章の類似度と後ろの2つの文章の類似度を求める"],"metadata":{"id":"JjZcv2JvPFTH"}},{"cell_type":"code","source":["cosine_similarity(embeddings[0], embeddings[1]), cosine_similarity(embeddings[1], embeddings[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzCVEPQfPDFK","executionInfo":{"status":"ok","timestamp":1694769568241,"user_tz":-540,"elapsed":14,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"7095c403-5653-492e-b575-6d4be406c663"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9513884610918777, 0.8207579882295654)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["値から判断できるように、最初の2つの文章の類似度の方が高いといえる"],"metadata":{"id":"2FWkF0vVPZUy"}},{"cell_type":"markdown","source":["### Memory"],"metadata":{"id":"ARj8Y8_RdlD6"}},{"cell_type":"markdown","source":["ChatGPTをブラウザで利用した場合、過去の会話の履歴を踏まえて返答するが、APIではそのような振る舞いは行わない\n","\n","APIを利用する場合は、過去の履歴をプロンプトに入力する必要がある\n","\n","実際にその振る舞いを確認する"],"metadata":{"id":"B0EPjzsTQntU"}},{"cell_type":"markdown","source":["次のような関数を用意してAPIを用いて文章を渡す"],"metadata":{"id":"YzABPdjkRm7e"}},{"cell_type":"code","source":["def post_chat_completions(content):\n","  url = \"https://api.openai.com/v1/chat/completions\"\n","  headers = {\n","      \"Content-Type\": \"application/json\",\n","      \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"]\n","  }\n","  data = {\n","      \"model\": \"gpt-3.5-turbo\",\n","      \"messages\": [\n","          {\"role\": \"user\", \"content\": content}\n","      ],\n","      \"temperature\": 0,\n","  }\n","\n","  response = requests.post(url=url, headers=headers, json=data)\n","  print(json.dumps(response.json(), indent=2))"],"metadata":{"id":"f7pxRwGnUDvn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["では、実際に名前を伝える"],"metadata":{"id":"2tIxorsKRxtu"}},{"cell_type":"code","source":["post_chat_completions(\"Hi! I'm Keio Yukichi!\")"],"metadata":{"id":"V_OBzUQGVAwa","executionInfo":{"status":"ok","timestamp":1694769569124,"user_tz":-540,"elapsed":887,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b804111d-3954-4cd4-e22b-2301995137d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"chatcmpl-7yzGp2HDSlmT28HyaAu7MKhl68fEV\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1694769559,\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"Hello Keio Yukichi! How can I assist you today?\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 16,\n","    \"completion_tokens\": 13,\n","    \"total_tokens\": 29\n","  }\n","}\n"]}]},{"cell_type":"markdown","source":["\"Hello Keio Yukichi! How can I assist you today?\" といった回答が得られているであろう\n","- Generativeであるため、この答えは毎回異なる\n","\n","その上で、名前を憶えているか聞いてみよう"],"metadata":{"id":"3-ruccLKR-Zi"}},{"cell_type":"code","source":["post_chat_completions(\"Do you know my name?\")"],"metadata":{"id":"EYjoBKp8VAjZ","executionInfo":{"status":"ok","timestamp":1694769570598,"user_tz":-540,"elapsed":1484,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a98aed7e-1623-4e62-94f2-ce056afec522"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"chatcmpl-7yzGqb7hdNxkhwKzMDECkAhRRE9Vg\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1694769560,\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"No, I do not know your name. As an AI language model, I don't have access to personal information unless you provide it to me.\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 13,\n","    \"completion_tokens\": 30,\n","    \"total_tokens\": 43\n","  }\n","}\n"]}]},{"cell_type":"markdown","source":["当然であるが、知らないという答えになる\n","\n","そこで、過去の会話の履歴を全て入れて、同じ質問を行ってみよう"],"metadata":{"id":"RpXJqn09SJS0"}},{"cell_type":"code","source":["post_chat_completions(\"\"\"A: Hi! I'm Keio Yukichi!\n","B: Hello Keio Yukichi! How can I assist you today?\n","A: Do you know my name?\n","B: \"\"\")"],"metadata":{"id":"2ctwcsZ-VLdD","executionInfo":{"status":"ok","timestamp":1694769571537,"user_tz":-540,"elapsed":949,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bddadcc0-c93a-47fc-8066-b02acf1d1477"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"chatcmpl-7yzGsfPLXoKjtNpcT6NqQHYSABAKN\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1694769562,\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"Yes, you introduced yourself as Keio Yukichi.\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 44,\n","    \"completion_tokens\": 11,\n","    \"total_tokens\": 55\n","  }\n","}\n"]}]},{"cell_type":"markdown","source":["となり、今度は\"Yes, you introduced yourself as Keio Yukichi.\"と回答している\n","\n","A:やB:は、会話しているのがどちらかを示す識別子であり、どのような形でもよい\n","- ただしLangChainは、内部でhumanとAIという用語を利用している\n","\n","このように、会話の過去の履歴を含めて問い合わせを行うため、過去の履歴を記録し、挿入するという処理が必要となる\n","- これがMemory moduleの役割である"],"metadata":{"id":"PuqgDlE5SipG"}},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"KZHfxu9hY62e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実際に使うには、Chainの中にmemoryとしてConversationBufferMemory()を加えるだけでよい\n","\n","プロンプト(文字を入力するための入力窓)が出てきたら、\n","- Hello. I'm Keio Yukichi\n","- Do you know my name?\n","- EOC\n","と入力する\n","\n","EOCは会話を終了させるおまじないである\n","- これは、ChatGPTの機能ではなく、そのようにプログラムしている"],"metadata":{"id":"Bu3uKzYrYo8a"}},{"cell_type":"code","source":["from langchain.chains import ConversationChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.memory import ConversationBufferMemory\n","\n","\n","langchain.verbose = True\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n","conversation = ConversationChain(\n","    llm=chat,\n","    memory=ConversationBufferMemory()\n",")\n","\n","while True:\n","    user_message = input(\"You: \")\n","    if(user_message == 'EOC'):\n","      break\n","    ai_message = conversation.predict(input=user_message)\n","    print(f\"AI: {ai_message}\")"],"metadata":{"id":"LjkhKO7nVeEK","executionInfo":{"status":"ok","timestamp":1694769689417,"user_tz":-540,"elapsed":57871,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b2cd0ce-8666-40bc-f0ed-f3e48d42d85e"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["You: Hello. I'm Keio Yukichi\n","\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hello. I'm Keio Yukichi\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","AI: Hello Keio Yukichi! How can I assist you today?\n","You: Do you know my name?\n","\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hello. I'm Keio Yukichi\n","AI: Hello Keio Yukichi! How can I assist you today?\n","Human: Do you know my name?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","AI: Yes, your name is Keio Yukichi.\n","You: EOC\n"]}]},{"cell_type":"markdown","source":["roleには、system, assistant, userの3つがあることは述べた\n","- systemは設定に利用され、例えばChatGPTにキャラを与えるような命令も存在する\n","\n","assistantとuserについて、assistant はAIからの回答、 user はユーザーからの発話であり、基本的にuserとして聞きたいことや、会話履歴を含めてを送ることになる\n","- この例では、userに、ユーザとChatGPTの両方の会話を入れ込んでいる\n","\n","しかしながら、本来は、assistantがAIからの回答であることから、userにはユーザからの発話履歴のみ、assistantはAIからの発話履歴のみを入れるという形が望ましい\n","- これについては後で説明する\n","\n","その他、様々なMemory moduleが提供されている\n","- ConversationBufferWindowMemory\n","  - ある範囲の会話履歴のみ入力する\n","- ConversationSummaryMemory\n","  - 会話履歴の要約を入力する"],"metadata":{"id":"sva3QIpBVImC"}},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"2JPsQbr0ZJ1z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Agents"],"metadata":{"id":"C0xTWbzzV4_n"}},{"cell_type":"markdown","source":["LLMが必要に応じて様々なタスクを実行すると便利と思うであろう\n","\n","例えば、\n","- 検索エンジンで検索させる\n","- 実際にコマンドを実行させる\n","- プログラミング言語やスクリプト言語でコードを実行させる\n","\n","これを行うのがAgents moduleである\n","\n","Agentsの利用により、実際にはLLMが何かを操作するわけではないが、LLMが何かしらアプリを操作しているかのように動作させることができる\n","\n","Agentsで操作可能なアプリの例\n","- bash (シェル)\n","- Google Search\n","- IFTTT WebHooks (スマートホーム等)\n","- Python REPL\n","- Requests (他のAPIを叩く)\n","- Wikipedia API"],"metadata":{"id":"xnb4KsklUOeo"}},{"cell_type":"markdown","source":["実際にAgentsを利用してみよう\n"],"metadata":{"id":"qmfqEmF_VsdA"}},{"cell_type":"code","source":["from langchain.agents import load_tools\n","from langchain.agents import initialize_agent\n","from langchain.chat_models import ChatOpenAI\n","\n","langchain.verbose = True\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","tools = load_tools([\"terminal\"], llm=chat)\n","agent_chain = initialize_agent(\n","    tools, chat, agent=\"zero-shot-react-description\")\n","\n","result = agent_chain.run(\"What is your current directory?\")\n","print(result)"],"metadata":{"id":"sbSTOTuKX7kJ","executionInfo":{"status":"ok","timestamp":1694769751710,"user_tz":-540,"elapsed":2300,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c60e988b-2498-45d0-dc20-8254fc228d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: What is your current directory?\n","Thought:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI can use the terminal to check the current directory.\n","Action: terminal\n","Action Input: pwd\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m/content\n","\u001b[0m\n","Thought:\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: What is your current directory?\n","Thought:I can use the terminal to check the current directory.\n","Action: terminal\n","Action Input: pwd\n","Observation: /content\n","\n","Thought:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI now know the final answer\n","Final Answer: The current directory is /content.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","The current directory is /content.\n"]}]},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"XbICnbceJ1nO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["単純に/content というディレクトリにいるという回答であるが、実際正解である\n","\n","ただ、ここで疑問が生じる **なぜ、ChatGPTはこちらのシェル環境のカレントディレクトリがわかったのだろうか？**\n","\n","これは、AgentsがMRKL(ミラクル)やReActなどを利用して動作しているためである\n","- MRKL(Multi-Round Knowledge Loop)\n","- ReAct (Reasoning/Acting) なお、Reactではない\n"],"metadata":{"id":"NCkT4uK8fHWE"}},{"cell_type":"markdown","source":["ログをみると、LangChainは次のようなプロンプトを生成している\n","```\n","Answer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","```\n","\n","翻訳すると、\n","```\n","次の質問にできるだけ答えてください。あなたは以下のツールにアクセスできる：\n","\n","terminal: このLinuxマシンでシェルコマンドを実行する。\n","\n","以下の書式を使う：\n","\n","Question: あなたが答えなければならない入力問題\n","Thought: 何をすべきかを常に考える。\n","Action: 取るべき行動。[terminal]のどれかであるべき。\n","Action Input: アクションへの入力\n","Observation: 行動の結果\n","...（このThought/Action/Action Input/ObservationはN回繰り返すことができる）\n","Thought: 最終的な答えがわかった\n","Final Answer: 元の入力された質問に対する最終的な答え\n","\n","始める！\n","```\n","\n","となっており、これらの書式を用いて処理が進む\n","```\n","Question: What is your current directory?\n","```\n","という問いかけに対して、\n","```\n","Thought:I can use the \"pwd\" command to find out the current directory.\n","Action: terminal\n","Action Input: pwd\n","```\n","とChatGPTが返答する\n","\n","そこで、AgentはAction Inputに記載されているコマンドを実行する\n","- その結果を Observationとして埋め込む\n","\n","さらに質問を続けるが、先のプロンプトに加えて、次の文章が加わっている\n","- つまり、これまでの動作をプロンプトに入力している\n","\n","```\n","Question: What is your current directory?\n","Thought:I can use the \"pwd\" command to find out the current directory.\n","Action: terminal\n","Action Input: pwd\n","Observation: /content\n","\n","Thought:\n","```\n","これに対して\n","```\n","I now know the final answer\n","Final Answer: The current directory is /content.\n","```\n","と回答している\n","\n","Final Answerとして現在のディレクトリは/contentであることが示されており、Final Answerが返されたので、実行を終了している"],"metadata":{"id":"-3eUMCemaz3X"}},{"cell_type":"markdown","source":["では、どんどんやってみよう"],"metadata":{"id":"uJ0Z4_VyZfbU"}},{"cell_type":"code","source":["result = agent_chain.run(\"Make a new directory called 'testdir-by-agent'\")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sX2ZcN2ZjT1","executionInfo":{"status":"ok","timestamp":1694770059777,"user_tz":-540,"elapsed":2500,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"fd3878dc-69f6-4f1e-e2fd-9ce2852cbea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: Make a new directory called 'testdir-by-agent'\n","Thought:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Make a new directory called \\'testdir-by-agent\\'\\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1077 request_id=4cab0ff23a08a167179269c2e5f17192 response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzOiTYiSfRAMc1v7Kmu5cMNecigw\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770048,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"I need to use the terminal to create a new directory.\\\\nAction: terminal\\\\nAction Input: mkdir testdir-by-agent\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 146,\\n    \"completion_tokens\": 24,\\n    \"total_tokens\": 170\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:29 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'1077\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'161\\', \\'x-ratelimit-remaining-tokens\\': \\'39823\\', \\'x-ratelimit-reset-requests\\': \\'4h36m11.716s\\', \\'x-ratelimit-reset-tokens\\': \\'265ms\\', \\'x-request-id\\': \\'4cab0ff23a08a167179269c2e5f17192\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd584f85944d1-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Make a new directory called \\'testdir-by-agent\\'\\\\nThought:I need to use the terminal to create a new directory.\\\\nAction: terminal\\\\nAction Input: mkdir testdir-by-agent\\\\nObservation: mkdir: cannot create directory \\\\u2018testdir-by-agent\\\\u2019: File exists\\\\n\\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to use the terminal to create a new directory.\n","Action: terminal\n","Action Input: mkdir testdir-by-agent\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mmkdir: cannot create directory ‘testdir-by-agent’: File exists\n","\u001b[0m\n","Thought:\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: Make a new directory called 'testdir-by-agent'\n","Thought:I need to use the terminal to create a new directory.\n","Action: terminal\n","Action Input: mkdir testdir-by-agent\n","Observation: mkdir: cannot create directory ‘testdir-by-agent’: File exists\n","\n","Thought:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mThe directory 'testdir-by-agent' already exists.\n","Final Answer: The directory 'testdir-by-agent' already exists.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","The directory 'testdir-by-agent' already exists.\n"]},{"output_type":"stream","name":"stderr","text":["message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1230 request_id=2887f91d67bf9e8320742c9a267d496d response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzOkrxRjSKx04g9TLbNwmMqW6A3C\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770050,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"The directory \\'testdir-by-agent\\' already exists.\\\\nFinal Answer: The directory \\'testdir-by-agent\\' already exists.\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 189,\\n    \"completion_tokens\": 25,\\n    \"total_tokens\": 214\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:31 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'1230\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'160\\', \\'x-ratelimit-remaining-tokens\\': \\'39774\\', \\'x-ratelimit-reset-requests\\': \\'4h43m22.574s\\', \\'x-ratelimit-reset-tokens\\': \\'339ms\\', \\'x-request-id\\': \\'2887f91d67bf9e8320742c9a267d496d\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd58c3cad44d1-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]}]},{"cell_type":"markdown","source":["ファイルも作ってみよう\n","\n","なお、途中で無料枠の場合はスロットを使い切ってしまうので、ワーニングメッセージと待ちが発生する"],"metadata":{"id":"hOQ0y-iOZ3W7"}},{"cell_type":"code","source":["result = agent_chain.run(\"Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16ILSPFfZ486","executionInfo":{"status":"ok","timestamp":1694770105591,"user_tz":-540,"elapsed":45818,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"d5b9da8b-e73f-4b3d-a161-75158521e91d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\n","Thought:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1247 request_id=d954d0aa4c12d1a49896fd4d7dcd0539 response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzOlnsOJ17droAajQJfcgXzGkIPs\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770051,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 161,\\n    \"completion_tokens\": 28,\\n    \"total_tokens\": 189\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:32 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'1247\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'159\\', \\'x-ratelimit-remaining-tokens\\': \\'39805\\', \\'x-ratelimit-reset-requests\\': \\'4h50m33.255s\\', \\'x-ratelimit-reset-tokens\\': \\'292ms\\', \\'x-request-id\\': \\'d954d0aa4c12d1a49896fd4d7dcd0539\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd594590a44d1-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=c683ceffaa6b362c408ce80fd0d53e1e response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:32 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'158\\', \\'x-ratelimit-remaining-tokens\\': \\'39770\\', \\'x-ratelimit-reset-requests\\': \\'4h57m43.946s\\', \\'x-ratelimit-reset-tokens\\': \\'345ms\\', \\'x-request-id\\': \\'c683ceffaa6b362c408ce80fd0d53e1e\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd59cad5e44d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to create a new file and write some text into it.\n","Action: terminal\n","Action Input: touch testdir-by-agent/test.txt\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\n","Thought:I need to create a new file and write some text into it.\n","Action: terminal\n","Action Input: touch testdir-by-agent/test.txt\n","Observation: \n","Thought:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=cfc499a1edd157621b33ee8527b25124 response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:36 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'157\\', \\'x-ratelimit-remaining-tokens\\': \\'39770\\', \\'x-ratelimit-reset-requests\\': \\'5h4m51.891s\\', \\'x-ratelimit-reset-tokens\\': \\'345ms\\', \\'x-request-id\\': \\'cfc499a1edd157621b33ee8527b25124\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd5b5fc6844d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=d2a4e2161e0d8c2fc376c065b9426ad8 response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:40 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'156\\', \\'x-ratelimit-remaining-tokens\\': \\'39770\\', \\'x-ratelimit-reset-requests\\': \\'5h11m59.838s\\', \\'x-ratelimit-reset-tokens\\': \\'345ms\\', \\'x-request-id\\': \\'d2a4e2161e0d8c2fc376c065b9426ad8\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd5cf49bd44d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=278c7b22f45f1aef19f17195218720d9 response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:44 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'155\\', \\'x-ratelimit-remaining-tokens\\': \\'39770\\', \\'x-ratelimit-reset-requests\\': \\'5h19m7.782s\\', \\'x-ratelimit-reset-tokens\\': \\'345ms\\', \\'x-request-id\\': \\'278c7b22f45f1aef19f17195218720d9\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd5e8aa7444d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1651 request_id=ec535fe5a6eba132a7f91f4fb7ad0aab response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzP6FLmO4WnZPwdiHs6qmp0VQzNz\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770072,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 195,\\n    \"completion_tokens\": 38,\\n    \"total_tokens\": 233\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:54 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'1651\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'154\\', \\'x-ratelimit-remaining-tokens\\': \\'39770\\', \\'x-ratelimit-reset-requests\\': \\'5h26m11.7s\\', \\'x-ratelimit-reset-tokens\\': \\'345ms\\', \\'x-request-id\\': \\'ec535fe5a6eba132a7f91f4fb7ad0aab\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd61b095844d1-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=8f6929ed5dd14533a6de6e16be63015a response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:54 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'153\\', \\'x-ratelimit-remaining-tokens\\': \\'39725\\', \\'x-ratelimit-reset-requests\\': \\'5h33m21.867s\\', \\'x-ratelimit-reset-tokens\\': \\'412ms\\', \\'x-request-id\\': \\'8f6929ed5dd14533a6de6e16be63015a\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd6268f6d44d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI have created a new file called test.txt in the directory testdir-by-agent.\n","Action: terminal\n","Action Input: echo \"This is a test\" > testdir-by-agent/test.txt\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n","\n","terminal: Run shell commands on this Linux machine.\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [terminal]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\n","Thought:I need to create a new file and write some text into it.\n","Action: terminal\n","Action Input: touch testdir-by-agent/test.txt\n","Observation: \n","Thought:I have created a new file called test.txt in the directory testdir-by-agent.\n","Action: terminal\n","Action Input: echo \"This is a test\" > testdir-by-agent/test.txt\n","Observation: \n","Thought:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=557e90140fae13a117480f57a7a21122 response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:27:58 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'152\\', \\'x-ratelimit-remaining-tokens\\': \\'39725\\', \\'x-ratelimit-reset-requests\\': \\'5h40m29.805s\\', \\'x-ratelimit-reset-tokens\\': \\'412ms\\', \\'x-request-id\\': \\'557e90140fae13a117480f57a7a21122\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd63ffe0f44d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=301ccacef74525c353e10c286a2c6bf9 response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:28:02 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'151\\', \\'x-ratelimit-remaining-tokens\\': \\'39725\\', \\'x-ratelimit-reset-requests\\': \\'5h47m37.746s\\', \\'x-ratelimit-reset-tokens\\': \\'412ms\\', \\'x-request-id\\': \\'301ccacef74525c353e10c286a2c6bf9\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd6595b9c44d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=5d9590fe863ec7f30f118092dbe2064a response_code=429\n","body='{\\n    \"error\": {\\n        \"message\": \"Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\",\\n        \"type\": \"requests\",\\n        \"param\": null,\\n        \"code\": \"rate_limit_exceeded\"\\n    }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:28:06 GMT\\', \\'Content-Type\\': \\'application/json; charset=utf-8\\', \\'Content-Length\\': \\'522\\', \\'Connection\\': \\'keep-alive\\', \\'vary\\': \\'Origin\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'150\\', \\'x-ratelimit-remaining-tokens\\': \\'39725\\', \\'x-ratelimit-reset-requests\\': \\'5h54m45.695s\\', \\'x-ratelimit-reset-tokens\\': \\'412ms\\', \\'x-request-id\\': \\'5d9590fe863ec7f30f118092dbe2064a\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd672baf944d1-ATL\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n","error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.' error_param=None error_type=requests message='OpenAI API error received' stream_error=False\n","WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-HrvXqeXQtUDWVEY1e05GXyuL on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n","message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\nterminal: Run shell commands on this Linux machine.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must answer\\\\nThought: you should always think about what to do\\\\nAction: the action to take, should be one of [terminal]\\\\nAction Input: the input to the action\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\\\nThought: I now know the final answer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\nBegin!\\\\n\\\\nQuestion: Create new file called test.txt in the directory of testdir-by-agent and store the text of This is test in the file.\\\\nThought:I need to create a new file and write some text into it.\\\\nAction: terminal\\\\nAction Input: touch testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:I have created a new file called test.txt in the directory testdir-by-agent.\\\\nAction: terminal\\\\nAction Input: echo \\\\\"This is a test\\\\\" > testdir-by-agent/test.txt\\\\nObservation: \\\\nThought:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"stop\": [\"\\\\nObservation:\", \"\\\\n\\\\tObservation:\"]}' message='Post details'\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[32;1m\u001b[1;3mI have successfully written the text \"This is a test\" into the file test.txt.\n","Final Answer: The file test.txt has been created in the directory testdir-by-agent and it contains the text \"This is a test\".\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","The file test.txt has been created in the directory testdir-by-agent and it contains the text \"This is a test\".\n"]},{"output_type":"stream","name":"stderr","text":["message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2105 request_id=a2f5e9b50c831a8d86b66f72b242839b response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzPSPtn7WSW1Yky8Bh7Xa57xlbnv\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770094,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"I have successfully written the text \\\\\"This is a test\\\\\" into the file test.txt.\\\\nFinal Answer: The file test.txt has been created in the directory testdir-by-agent and it contains the text \\\\\"This is a test\\\\\".\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 239,\\n    \"completion_tokens\": 46,\\n    \"total_tokens\": 285\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:28:17 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'2105\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'149\\', \\'x-ratelimit-remaining-tokens\\': \\'39725\\', \\'x-ratelimit-reset-requests\\': \\'6h1m49.637s\\', \\'x-ratelimit-reset-tokens\\': \\'412ms\\', \\'x-request-id\\': \\'a2f5e9b50c831a8d86b66f72b242839b\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd6a509c344d1-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]}]},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"sVBNXV0IKnbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["testdir-by-agentの下にtest.txtがあり、その中身がThis is a testであることを確認しよう"],"metadata":{"id":"M_GU_jxdadC8"}},{"cell_type":"markdown","source":["### MRKL(Multi-Round Knowledge Loop)\n","\n","例えば、「現在の日本の首相の年齢から現在のフランスの首相の年齢を引いたらいくつですか？」という問いに対して、ChatGPTは答えることができるか？\n","\n","これを直接WebのChatGPTに問い合わせても答えることができない\n","\n","しかしながら、APIでは答えることができる\n","- つまり、APIでChatGPTをアクセスすると、Webとは異なる仕組みでアクセスできるということ\n","\n","では、その手順であるが、まず質問に答えるための手順を考える\n","\n","- 最初に問い。「現在の日本の首相の年齢から現在のフランスの首相の年齢を引いたらいくつですか？」（Question）\n","\n","- Googleで未知の情報を調べるために検索ワードを考える(Thought)\n","\n","- 現在の日本とフランスの首相の年齢を知る必要がある\n","  - 検索ワードは「現在の日本の首相の年齢」(Action Input)\n","  - さらに検索ワードは「現在のフランス首相の年齢」(Action Input)\n","\n","- 検索を実行「現在の日本の首相の年齢」（Action）\n","  - 結果は65歳でした（obsabation)\n","\n","- 検索を実行します「現在のフランス首相の年齢」（Action）\n","  - 結果は61歳でした（obsabation)\n","\n","- 日本の首相の年齢とフランスの首相の年齢の差分を計算する必要がある（Thought）\n","\n","- 計算（Action）\n","\n","- 結果は4でした(obsabation)\n","\n","- 答えは4歳です (final)\n","\n","このようにMRKLは、ChatGPTが情報をもとに次のアクションを考え、結果を評価し、次のアクションを考えるというプロセスを繰り返すことで回答精度を上げる方法論である\n","\n","考察（Thought）、観察（Observation）、行動（Action）のサイクルを繰り返すことで、回答精度が向上する\n","\n","よく言われる、ステップバイステップで考えるように指示すると正答率が上がるのと似ているが、Agent側で実際に実行して応答できるように工夫されている"],"metadata":{"id":"cQzbRtM5hCkG"}},{"cell_type":"markdown","source":["### Prompt Coding\n","\n","プロンプトコーディングはChatGPTの活用において必須となる技術である\n","\n","ChatGPTから精度の高い回答を得るために、人間に質問するのと同様に、質問力が重要であり、その質問の仕方に関する研究が進められている\n","\n","例えば、以下のように役割の指定や回答の形式を細かく設定することで、正答率を上げることができる\n","- 質問や回答が定型化されており、プログラムで文字列を処理することが容易になり、解析が可能となる\n","\n","```\n","あなたは、英語の先生です。これから私の英語を英語教師として文法の誤りを訂正して下ださい。\n","回答のフォーマットは以下のようにします。\n","あなたの英語：{入力分}\n","訂正後の英文:{英文例}\n","文法の解説:{解説1000文字以内}\n","```"],"metadata":{"id":"ya0rvvL2jaAT"}},{"cell_type":"markdown","source":["### 実際のプロンプト\n","\n","先の年齢差を問う問題に答えさせる場合、次のようなプロンプトが想定される\n","- 内容は、シェルを実行するAgentの問い合わせと酷似する\n","\n","```\n","Answer the following questions as best you can.\n","You have access to the following tools:\\n\\n\n","\n","Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\n\n","Calculator: Useful for when you need to answer questions about math.\\n\\n\n","\n","Use the following format:\\n\\n\n","\n","Question: the input question you must answer\\n\n","Thought: you should always think about what to do\\n\n","Action: the action to take, should be one of [Search, Calculator]\\n\n","Action Input: the input to the action\\n\n","Observation: the result of the action\\n\n","... (this Thought/Action/Action Input/Observation can repeat N times)\\n\n","Thought: I now know the final answer\\n\n","Final Answer: the final answer to the original input question\\n\\n\n","\n","Begin!\\n\\n\n","\n","\n","Question: 現在の日本の首相の年齢から現在のフランスの首相の年齢を引いたらいくつですか？ 計算してください\\nThought:')\n","```\n","\n","最初の\"Use the following format:\\n\\n\" 以前について、\n","\n","ここで、toolsについて何がどのように利用できるかを伝えているが、重要な点は次の通りである\n","\n","- Searchというツール名\n","  - コロンの前にツール名が記載されている\n","- ユースケースを伝える\n","  - (時事問題に関する質問に答える必要があるときに便利です)\n","- 入力形式を指定する\n","  - (入力は、検索クエリである必要がある)\n","\n","「入力は検索クエリである必要がある」と伝えているため、半角スペース区切りの単語単位での検索クエリを作成するようになる\n","- ChatGPTは時事問題に関する内容は、Searchツールを使うようになる\n","\n","最初の\"Use the following format:\\n\\n\" 以降について\n","\n","進め方とフォーマットを伝えている\n","\n","- Question:質問内容を記載\n","- Thought:何をすべきかを常に考える必要がある\n","  - アクションを考えるように指示\n","- Action: 実行するアクションは、 [Search, Calculator]のいずれかである必要がある\n","  - アクション名はツール名と同じであり、ChatGPTからActionの指示が出る際には[Search,Calculator]のキーワードが出力される\n","- Action Input: アクションへの入力\n","  - Searchの場合は指示されたクエリ形式で入力する\n","- Observation:Actionの結果\n","  - アクションの結果を表示\n","\n","さらに、最後について\n","\n","- (this Thought/Action/Action Input/Observation can repeat N times)\n","  - N回繰り返すは、答えが出ない場合に打ち切る回数や、API利用料金を抑えるための制限回数として、Nを指定できるようにしている\n","- Thought:回答が判明したら下記に進みます\n","- Final Answer:最終的な回答をします"],"metadata":{"id":"3u5jaB1ikP5o"}},{"cell_type":"markdown","source":["実際に試行すると次のような結果を得ることができる\n","\n","```\n","> Entering new AgentExecutor chain...\n","I need to find out the age of the current Japanese and French Prime Ministers\n","Action: Search\n","Action Input: \"age of current Japanese Prime Minister\"params\n","\n","Observation: 65歳\n","Thought: Now I need to find out the age of the current French Prime Minister\n","Action: Search\n","Action Input: \"age of current French Prime Minister\"params\n","\n","Observation: 61歳\n","Thought: I now know the final answer\n","Final Answer: 4歳\n","```\n","\n"],"metadata":{"id":"3BoivuKFnmUn"}},{"cell_type":"markdown","source":["##  Chat API におけるプロンプトの構築"],"metadata":{"id":"bqrKxwnhlstV"}},{"cell_type":"markdown","source":["先のmemoryの例に加えて、\n","`import openai`\n","\n","および\n","\n","`langchain.verbose = True`\n","\n","を追加して、ログを詳細に取得する\n","\n","プロンプトに対して、\n","- Hi, I'm Keio Yukichi.\n","- Do you know my name?\n","- EOC\n","\n","と入力する\n"],"metadata":{"id":"XNIICFODuMO_"}},{"cell_type":"code","source":["from langchain.chains import ConversationChain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.memory import ConversationBufferMemory\n","import openai\n","\n","langchain.verbose = True\n","openai.log = \"debug\"\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n","conversation = ConversationChain(\n","    llm=chat,\n","    memory=ConversationBufferMemory()\n",")\n","\n","while True:\n","    user_message = input(\"You: \")\n","    if(user_message == 'EOC'):\n","      break\n","    ai_message = conversation.predict(input=user_message)\n","    print(f\"AI: {ai_message}\")"],"metadata":{"id":"jX1cLM9FJfbe","executionInfo":{"status":"ok","timestamp":1694770190572,"user_tz":-540,"elapsed":24856,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2a91dcc-5425-4def-d140-98955c688491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["You: Hi, I'm Keio Yukichi.\n","\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi, I'm Keio Yukichi.\n","AI:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\\\n\\\\nCurrent conversation:\\\\n\\\\nHuman: Hi, I\\'m Keio Yukichi.\\\\nAI:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": 100, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=636 request_id=644ea4c95e6883c8ac31f6f774fdb9fd response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzQchyZJ9Qq5yWxxhf7hHH9NDho1\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770166,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Hello Keio Yukichi! How can I assist you today?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 72,\\n    \"completion_tokens\": 13,\\n    \"total_tokens\": 85\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:29:26 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'636\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'148\\', \\'x-ratelimit-remaining-tokens\\': \\'39827\\', \\'x-ratelimit-reset-requests\\': \\'6h7m50.497s\\', \\'x-ratelimit-reset-tokens\\': \\'259ms\\', \\'x-request-id\\': \\'644ea4c95e6883c8ac31f6f774fdb9fd\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd8618e64b11e-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","AI: Hello Keio Yukichi! How can I assist you today?\n","You: Do you know my name?\n","\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, I'm Keio Yukichi.\n","AI: Hello Keio Yukichi! How can I assist you today?\n","Human: Do you know my name?\n","AI:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\\\n\\\\nCurrent conversation:\\\\nHuman: Hi, I\\'m Keio Yukichi.\\\\nAI: Hello Keio Yukichi! How can I assist you today?\\\\nHuman: Do you know my name?\\\\nAI:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": 100, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=950 request_id=a1062ddf513a883c5bdc92d9744d5941 response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzQlKc7LGXLeCdoGVG4ppVT0i97F\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770175,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Yes, your name is Keio Yukichi. You just mentioned it in your previous message.\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 95,\\n    \"completion_tokens\": 19,\\n    \"total_tokens\": 114\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:29:36 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'950\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'147\\', \\'x-ratelimit-remaining-tokens\\': \\'39807\\', \\'x-ratelimit-reset-requests\\': \\'6h14m52.812s\\', \\'x-ratelimit-reset-tokens\\': \\'289ms\\', \\'x-request-id\\': \\'a1062ddf513a883c5bdc92d9744d5941\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd89e391fb11e-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","AI: Yes, your name is Keio Yukichi. You just mentioned it in your previous message.\n","You: EOC\n"]}]},{"cell_type":"markdown","source":["ログを参照することで、動作の詳細を獲得できる\n","\n","例えば、Memoryにより過去の履歴をプロンプトを与えることができるが、具体的には次のような動作をしている\n","\n","```\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\\\n\\\\nCurrent conversation:\\\\nHuman: Hi, I\\'m Keio Yukichi.\\\\nAI: Hello Keio Yukichi! How can I assist you today?\\\\nHuman: Do you know my name?\\\\nAI:\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": 100, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n","```\n","\n","このように、すべてuserメッセージとして混入している\n","\n","本来は、ChatGPTの言葉は、assistantとして入力するべきであろうことがわかる"],"metadata":{"id":"Ke23qQpWvIZM"}},{"cell_type":"markdown","source":["そこで、これを使い分けるには、次のようにする\n","\n","SystemMessage, HumanMessage、またAIMessageを用いて、それぞれの会話を仕分けできる"],"metadata":{"id":"Nv6G19MewSJN"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n","\n","messages = [\n","    SystemMessage(content=\"You are a helpful assistant.\"),\n","    HumanMessage(content=\"Hi! I'm Keio Yukichi!\"),\n","    AIMessage(content=\"Yes, You are Keio Yukichi.\")\n","]\n","\n","result = chat(messages)\n","print(result)"],"metadata":{"id":"X90oA5kIPGYG","executionInfo":{"status":"ok","timestamp":1694770191350,"user_tz":-540,"elapsed":780,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d38f8955-dfe1-4aee-86ea-9f141489e112"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Hi! I\\'m Keio Yukichi!\"}, {\"role\": \"assistant\", \"content\": \"Yes, You are Keio Yukichi.\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": 100, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n"]},{"output_type":"stream","name":"stdout","text":["content='Hello Keio Yukichi! How can I assist you today?' additional_kwargs={} example=False\n"]},{"output_type":"stream","name":"stderr","text":["message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=637 request_id=052f35a55c3bed8aa9180f7b6db726a6 response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzQs3Rewykru3OhxVax2fFBXcSet\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770182,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Hello Keio Yukichi! How can I assist you today?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 39,\\n    \"completion_tokens\": 13,\\n    \"total_tokens\": 52\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:29:42 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'637\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'146\\', \\'x-ratelimit-remaining-tokens\\': \\'39878\\', \\'x-ratelimit-reset-requests\\': \\'6h21m58.438s\\', \\'x-ratelimit-reset-tokens\\': \\'183ms\\', \\'x-request-id\\': \\'052f35a55c3bed8aa9180f7b6db726a6\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fd8c59f24b11e-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]}]},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"wij-UYXMLZzW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["これを踏まえて、先ほどのループ問い合わせプログラムを改善する\n","\n","```\n","    memory.chat_memory.add_user_message(user_message)\n","    ai_message = chat(memory.chat_memory.messages)\n","    memory.chat_memory.add_ai_message(ai_message.content)\n","```\n","とすることで、memoryに対してだれの発言かを仕分けして登録するようにする\n","\n","実際に実行して、次のようにプロンプトに入力する\n","- Hi. I'm Keio Yukichi.\n","- Do you know my name?\n","- EOC\n","\n","ログを見てみると、Do you know my name? の問い合わせの後、\n","\n","`\"messages\": [{\"role\": \"user\", \"content\": \"Hi. I\\'m Keio Yukichi.\"}`とuserが入力した後、`{\"role\": \"assistant\", \"content\": \"Hello Keio Yukichi! How can I assist you today?\"}'とassistantが返答、さらに`{\"role\": \"user\", \"content\": \"Do you know my name?\"}`とuserが入力といった具合に、正しく仕分けされている\n"],"metadata":{"id":"GamQYH-iwucs"}},{"cell_type":"code","source":["langchain.verbose = True\n","\n","chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","memory = ConversationBufferMemory()\n","\n","while True:\n","    user_message = input(\"You: \")\n","    if(user_message == 'EOC'):\n","      break\n","    memory.chat_memory.add_user_message(user_message)\n","    ai_message = chat(memory.chat_memory.messages)\n","    memory.chat_memory.add_ai_message(ai_message.content)\n","    print(f\"AI: {ai_message.content}\")\n"],"metadata":{"id":"gZAE9dogmna_","executionInfo":{"status":"ok","timestamp":1694770353876,"user_tz":-540,"elapsed":49578,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b446f0f0-f1e4-4bbd-9595-0a8f729fc2f4"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["You: Hi. I'm Keio Yukichi.\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Hi. I\\'m Keio Yukichi.\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=693 request_id=b416770493eb1ed78edf090cfcb4fe79 response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzTJWyWuMfRVELqrLOiEnUR9NUrr\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770333,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Hello Keio Yukichi! How can I assist you today?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 16,\\n    \"completion_tokens\": 13,\\n    \"total_tokens\": 29\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:32:14 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'693\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'143\\', \\'x-ratelimit-remaining-tokens\\': \\'39977\\', \\'x-ratelimit-reset-requests\\': \\'6h48m14.912s\\', \\'x-ratelimit-reset-tokens\\': \\'34ms\\', \\'x-request-id\\': \\'b416770493eb1ed78edf090cfcb4fe79\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fdc790af4b11e-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]},{"name":"stdout","output_type":"stream","text":["AI: Hello Keio Yukichi! How can I assist you today?\n","You: Do you know my name?\n"]},{"output_type":"stream","name":"stderr","text":["message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n","api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Hi. I\\'m Keio Yukichi.\"}, {\"role\": \"assistant\", \"content\": \"Hello Keio Yukichi! How can I assist you today?\"}, {\"role\": \"user\", \"content\": \"Do you know my name?\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0}' message='Post details'\n","message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1011 request_id=e078f88bbd8cdc4cc465d6bd3f1b6f6e response_code=200\n","body='{\\n  \"id\": \"chatcmpl-7yzTR4PlojDnYJ7atOoAPz9c9ZglK\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694770341,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Yes, you mentioned your name as Keio Yukichi. How can I help you, Keio Yukichi?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 43,\\n    \"completion_tokens\": 23,\\n    \"total_tokens\": 66\\n  }\\n}\\n' headers='{\\'Date\\': \\'Fri, 15 Sep 2023 09:32:22 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-3ayltofgziignqdsvkwyx6sh\\', \\'openai-processing-ms\\': \\'1011\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'142\\', \\'x-ratelimit-remaining-tokens\\': \\'39959\\', \\'x-ratelimit-reset-requests\\': \\'6h55m19.321s\\', \\'x-ratelimit-reset-tokens\\': \\'61ms\\', \\'x-request-id\\': \\'e078f88bbd8cdc4cc465d6bd3f1b6f6e\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'806fdca88e50b11e-ATL\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"]},{"name":"stdout","output_type":"stream","text":["AI: Yes, you mentioned your name as Keio Yukichi. How can I help you, Keio Yukichi?\n","You: EOC\n"]}]},{"cell_type":"code","source":["#スロット待ち\n","if openai_wait:\n","  time.sleep(60)"],"metadata":{"id":"5j0TQZvcMZU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gradioについて"],"metadata":{"id":"vy5mm7Trmjh4"}},{"cell_type":"markdown","source":["Webアプリを簡単に実装できるPythonライブラリ\n","\n","百聞は一見に如かずということで、早速実行してみよう"],"metadata":{"id":"LHpGhwMab4H1"}},{"cell_type":"markdown","source":["## gradio のインストール方法\n","\n","```\n","pip install gradio\n","```\n","\n","とし、例えば、\n","\n","```\n","import gradio as gr\n","```\n","とすることで利用可能となる"],"metadata":{"id":"jhssf_w9moNv"}},{"cell_type":"code","source":["!pip -q install gradio"],"metadata":{"id":"mWx4JDa-MGDa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["シンプルなWeb UIを作成して起動させる例を示す\n","- 名前を入力し、名前へのあいさつを出力するWeb UIである\n","\n","Colab上で実行すると、Colabのwebに統合される\n","- URLが出力されている通り、そのURLにアクセスできる環境にあれば、webのページとして表示される\n","- この例では、`https://localhost:7860/`などと表示されているが、クリックすると実は`https://wq0lbccui9-496ff2e9c6d22116-7860-colab.googleusercontent.com/`に転送されており、ネットワークセキュリティ上隔離されたColabの外からアクセスできるようになる\n","- Colab環境では、セキュリティ上の問題もあり、このようなグローバルアドレスが提供されない場合は、別途ボートフォーワーディングなどの知識が必要な場合がある\n","- また、ローカル上で他のWeb UIアプリを動作させているなどにより、ポートが競合する可能性がある\n","  - この場合、7860 が 7861 や 7862 といった番号に変わることがある\n","\n","\n","また、gradio clientを用いることで、作成したwebアプリケーションをweb APIのように利用することもできる\n","- 下に小さく「Use via API」と記載されているが、これをクリックし、記載の通りに実行すると動作がわかるであろう\n","·"],"metadata":{"id":"miQy3qBhcQNz"}},{"cell_type":"code","source":["import gradio as gr\n","\n","# あいさつの関数\n","def greet(name):\n","    return \"Hello \" + name + \"!\"\n","\n","# Interfaceの作成\n","demo = gr.Interface(\n","    fn=greet,\n","    inputs=\"text\",\n","    outputs=\"text\"\n",")\n","\n","# 起動\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"O8KX4wgicW2Z","executionInfo":{"status":"ok","timestamp":1694770361133,"user_tz":-540,"elapsed":420,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"12b7b22c-e34e-4631-9fe5-6b66a6fba700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7869, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["## 設計手順\n","\n","次の手順となる\n","- コールバック関数を定義\n","- レイアウトを定義\n","- WebUIの起動\n","\n","それぞれについて概要をみてみよう"],"metadata":{"id":"lslskTPQflov"}},{"cell_type":"markdown","source":["\n","### コールバック関数\n","\n","まず、コールバック関数として、画面レイアウトでボタンが押された時に呼び出したい関数を記述する  \n","\n","例えば、名前(text)、表示フラグ(boolean)、値(0から100の値)の3つを受け取る関数として次のような関数を想定する  \n","```\n","def my_func(my_name, is_disp, my_value):\n","    return f'### {my_name} ###', my_value * 100\n","```\n","\n"],"metadata":{"id":"ZKnVtHYXgNiu"}},{"cell_type":"markdown","source":["### Interface\n","\n","「Interface」は、関数をUIでラップするためのクラスであり、主なパラメータは次のとおり\n","- fn : ラップする関数\n","- inputs : 入力コンポーネント (\"text\"、\"image\"、\"audio\"など)\n","- outputs : 出力コンポーネント (\"text\"、\"image\"、\"label\"など)\n","\n","画面レイアウトの作成として、画面に表示したいUIパーツと、ボタンなどが押された時のアクション(呼ぶ出したいコールバック関数の名前)を記述する  \n","- 入力UIとして、my_nameは\"text\"であり、is_dispは\"checkbox\"であり、my_valueは、0から100の値をスライダーで入力させるとすると、gr.Slider(0, 100)となり、上からこの順に入力UIがレイアウトされる\n","- 出力UIとして、ここでは、文字と数字を想定する\n","\n","最終的に、次のような関数定義となる  \n","```\n","demo = gr.Interface(\n","    fn = my_func,\n","    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n","    outputs=[\"text\", \"number\"],\n",")\n","```\n","\n","なお、\"text\"に対して、より詳細な情報を与えることもできる\n","\n","```\n","demo = gr.Interface(\n","    fn=my_func,\n","    inputs=[\n","      gr.Textbox(\n","        lines=2,  # 行数\n","        placeholder=\"Name Here...\"  # プレースホルダ\n","      ),\n","      \"checkbox\", gr.Slider(0, 100)\n","    ]\n","    outputs=[\"text\", \"number\"],\n",")\n","\n","```"],"metadata":{"id":"2PxgV9NKnkjK"}},{"cell_type":"markdown","source":["\n","- 最後にWebUIを起動する  \n","シンプルに、  \n","```\n","demo.launch()\n","```\n","とするだけでよい\n","\n","inputs には「クリアボタン」と「送信」ボタンが、outputs には「フラグする」ボタンが自動で追加される(フラグボタンは出力をローカルファイルに保存する)\n","\n","簡易的なWebサーバが起動し、ブラウザ上でWeb UIが表示される\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/gradio1.jpg\" width=700>\n"],"metadata":{"id":"XjaSRRUCgmsO"}},{"cell_type":"markdown","source":["## より実践的な例\n","\n","他にも様々な機能があるため、調べてみるとよい\n","\n","```\n","import gradio as gr\n","\n","# コールバック関数の定義\n","def callback_func(val1,val2,val3):\n","    return str(int(val1) * int(val2)), f\"気温は {val3} 度です\"\n","\n","# 画面レイアウトの定義(Interfaceを使用)\n","app = gr.Interface(\n","    title=\"計算機\",\n","    fn=callback_func,\n","    inputs=[\n","        gr.Textbox(label=\"入力欄1\",lines=3, placeholder=\"ここに数値を入れてください...\"),\n","        gr.Textbox(label=\"入力欄2\",lines=5, placeholder=\"ここに数値を入れてください...\"),\n","        gr.Slider(label=\"温度\",minimum=0,maximum=100,step=1)\n","    ],\n","    outputs=[\n","        gr.Label(label=\"計算結果1\",lines=3),\n","        gr.Textbox(label=\"計算結果2\",lines=3)\n","    ]\n","    )\n","\n","# Web UIの起動\n","app.launch(inbrowser=True)\n","```\n","\n","\n"],"metadata":{"id":"fcPpqmEnt4qW"}},{"cell_type":"markdown","source":["### Blocks\n","\n","簡易的に使用する場合はInterfaceを使い、より複雑なレイアウトを作る場合はBlocksを使う\n","\n","- Interfaceのメリット\n","\n","  - ショートカット文字列の使用が可能(Blocksでは使用不可)\n","  - Interfaceでは基本的なボタンを自動生成\n","\n","- Blocksのメリット\n","\n","  - Blocksでのみ利用可能なレイアウトがある\n","  - レイアウトが複雑になった場合でもwith文で可読性の高いコードが書ける\n","\n","Blocksではレイアウトを指定でき、次のようなレイアウトがある\n","\n"],"metadata":{"id":"WXViJMW_oVc5"}},{"cell_type":"markdown","source":["#### コンポーネントを横や縦に並べる  \n","gr.Row()やgr.Column()を利用する\n","\n","コード中にコメントがあるので、切り替えてみるとよい"],"metadata":{"id":"cGy7qHvAtH4x"}},{"cell_type":"code","source":["import gradio as gr\n","def greet(name): return \"Hello \" + name + \"!\"\n","with gr.Blocks() as app:\n","  with gr.Row():\n","#  with gr.Column(scale=2):\n","    inputs = gr.Textbox(placeholder=\"名前を入力してね!\", label=\"名前\")\n","    outputs = gr.Textbox(label=\"挨拶\")\n","    btn = gr.Button(\"クリックしてね!\")\n","app.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"iQxV_PT9rq2P","executionInfo":{"status":"ok","timestamp":1694770361952,"user_tz":-540,"elapsed":821,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"50881e09-2db7-44cf-85d9-e177fe4aee3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7870, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["#### タブで表示する  \n"],"metadata":{"id":"4Itelzr_sjVE"}},{"cell_type":"code","source":["import gradio as gr\n","def greet(name): return \"Hello \" + name + \"!\"\n","with gr.Blocks() as app: # 入力タブを定義\n","  with gr.Tab(\"入力タブ\"):\n","    inputs = gr.Textbox(placeholder=\"名前を入力してね!\", label=\"名前\")\n","    btn = gr.Button(\"クリックしてね!\") # 出力タブを定義\n","  with gr.Tab(\"出力タブ\"):\n","    outputs = gr.Textbox(label=\"挨拶\")\n","    btn.click(fn=greet, inputs=inputs, outputs=outputs)\n","app.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"pyByV3fYsmGQ","executionInfo":{"status":"ok","timestamp":1694770362336,"user_tz":-540,"elapsed":386,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"fc444964-287a-491f-95cc-883426494159"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7871, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["#### 丸角の子要素を設ける\n","\n","角が丸く、周囲にパディングがあるボックスである"],"metadata":{"id":"nkv4_Mj4s_qW"}},{"cell_type":"code","source":["import gradio as gr\n","def greet(name): return \"Hello \" + name + \"!\"\n","with gr.Blocks() as app: # Box()関数でレイアウトを定義\n","  with gr.Box():\n","    inputs = gr.Textbox(placeholder=\"名前を入力してね!\", label=\"名前\")\n","    outputs = gr.Textbox(label=\"挨拶\")\n","    btn = gr.Button(\"クリックしてね!\") # イベントを定義\n","    btn.click(fn=greet, inputs=inputs, outputs=outputs)\n","app.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"V1IMxhLDtS9j","executionInfo":{"status":"ok","timestamp":1694770363386,"user_tz":-540,"elapsed":1053,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"304d8996-5d27-41ee-bee6-22f6044f8f08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7872, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["#### 子要素を折りたたみ可能にする\n","\n","Accordionは、子要素を折りたたみ可能なセクションに配置する\n","\n","openパラメータにより初期状態で開いているか(True)、閉じているか(False)を指定でき、デフォルトはOpen(True)\n"],"metadata":{"id":"NnTwV4PrtfLK"}},{"cell_type":"code","source":["import gradio as gr\n","def greet(name): return \"Hello \" + name + \"!\"\n","with gr.Blocks() as app: # Accordion()関数でレイアウトを定義\n","  with gr.Accordion(label=\"アプリを見る\", open=False):\n","    inputs = gr.Textbox(placeholder=\"名前を入力してね!\", label=\"名前\")\n","    outputs = gr.Textbox(label=\"挨拶\")\n","    btn = gr.Button(\"クリックしてね!\") # イベントを定義\n","    btn.click(fn=greet, inputs=inputs, outputs=outputs)\n","app.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"wCdTBWZduNgD","executionInfo":{"status":"ok","timestamp":1694770364234,"user_tz":-540,"elapsed":853,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"5ffb2c0d-5613-43b7-f07f-dd0aa429bbc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7873, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["### チャットを実装する\n","\n","なんでもなく、\"How are you?\", \"I know you\", \"I'm very hungry\"のどれかをランダムに答えるアプリである"],"metadata":{"id":"HiEG9ZpVpKGJ"}},{"cell_type":"code","source":["import gradio as gr\n","import random\n","import time\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox()\n","    clear = gr.ClearButton([msg, chatbot])\n","\n","    def respond(message, chat_history):\n","        bot_message = random.choice([\"How are you?\", \"I know you\", \"I'm very hungry\"])\n","        chat_history.append((message, bot_message))\n","        time.sleep(2)\n","        return \"\", chat_history\n","\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"8hAUuk-oo47w","executionInfo":{"status":"ok","timestamp":1694770572457,"user_tz":-540,"elapsed":3,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"33a3f3cd-0f50-459a-ac78-5349518f4703"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7878, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","source":["## LLMチャットの実装\n","\n"],"metadata":{"id":"WKL_t_xT02BX"}},{"cell_type":"code","source":["import langchain\n","from langchain.chat_models import ChatOpenAI\n","\n","langchain.verbose = True\n","\n","def chat(message: str) -> str:\n","    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","    return llm.predict(message)\n"],"metadata":{"id":"BgGEEYyY1KxH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実際に試してみよう\n","\n","- 私の名前は出田です。\n","- 私の名前がわかりますか？\n","\n","と入力すると、\n","「いいえ、私はあなたの名前を知りません。」\n","といった回答になる"],"metadata":{"id":"KYCXt_wRU6bb"}},{"cell_type":"code","source":["import gradio as gr\n","\n","def respond(message, chat_history):\n","    bot_message = chat(message)\n","    chat_history.append((message, bot_message))\n","    return \"\", chat_history\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox()\n","    clear = gr.Button(\"Clear\")\n","\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"vinBiFGT1N6n","executionInfo":{"status":"ok","timestamp":1694770868121,"user_tz":-540,"elapsed":234,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"8f236e40-c8f1-4fd8-df93-a7b0b5a960f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7880, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["次のコードここから連続して実行するとエラーになる\n","- 上記のコードがエラーになるため、まず実行を留める\n","- 確認が終わったら、その先のコードを待ってから実行すること"],"metadata":{"id":"R5yNd7nzN8io"}},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"5T7TiWyfNxRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --quiet langchain openai gradio"],"metadata":{"id":"-woqtscRRQjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv(verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qz31TJxtTH2_","executionInfo":{"status":"ok","timestamp":1694772682240,"user_tz":-540,"elapsed":12,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"d7f4c36c-63a6-4cd1-b623-f70e8ae48290"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import langchain\n","from langchain.chat_models import ChatOpenAI\n","\n","langchain.verbose = True\n","\n","def chat(message: str) -> str:\n","    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","    return llm.predict(message)"],"metadata":{"id":"KaPFLon4QX9t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["次に、過去の会話履歴を踏まえて回答するように chat関数を次のように更新する\n"],"metadata":{"id":"GoYskNFqH4ud"}},{"cell_type":"code","source":["import langchain\n","from langchain.chat_models import ChatOpenAI\n","from langchain.memory import ChatMessageHistory\n","from langchain.schema import HumanMessage\n","\n","langchain.verbose = True\n","\n","def chat(message: str, history: ChatMessageHistory) -> str:\n","    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","    messages = history.messages\n","    messages.append(HumanMessage(content=message))\n","\n","    return llm(messages).content"],"metadata":{"id":"igs39-zMH-b4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実際に試してみよう\n","\n","- 私の名前は出田です。\n","- 私の名前がわかりますか？\n","\n","と入力すると、\n","「はい、先ほど出田さんとおっしゃいましたよね。」\n","といった回答になる"],"metadata":{"id":"ayaQTKNLVQUu"}},{"cell_type":"code","source":["import gradio as gr\n","from langchain.memory import ChatMessageHistory\n","\n","def respond(message, chat_history):\n","    history = ChatMessageHistory()\n","    for [user_message, ai_message] in chat_history:\n","        history.add_user_message(user_message)\n","        history.add_ai_message(ai_message)\n","\n","    bot_message = chat(message, history)\n","    chat_history.append((message, bot_message))\n","    return \"\", chat_history\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox()\n","    clear = gr.Button(\"Clear\")\n","\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"JH7cYHuOSLio","executionInfo":{"status":"ok","timestamp":1694785893040,"user_tz":-540,"elapsed":389,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"a04a14c1-0c79-4b72-8b1d-fbfb76ff0221"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7864, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# 課題\n","\n","履歴付きチャットボットを改造し、常に回答が子供の対応であるようにプロンプトエンジニアリングを行いなさい\n","\n","単純に、入力問い合わせに対して、「考え方や言葉遣いを6歳の子供のようにして答えなさい」といった言葉を付け加えなさい"],"metadata":{"id":"OEnQXDE_G8Ju"}}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/keioNishi/lec-dataai/blob/main/dataai-text-J-Diffusion.ipynb","timestamp":1661617425151},{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb","timestamp":1661425026567}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}