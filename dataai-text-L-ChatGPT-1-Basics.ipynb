{"cells":[{"cell_type":"markdown","metadata":{"id":"bHZ54p4iIfem"},"source":["---\n",">「おそらく世の中で最高の話し上手は、人に話をさせる人だろう。」\n",">\n","> ジョン・スタインベック\n","---"]},{"cell_type":"markdown","metadata":{"id":"L9HXMz2Zvn8D"},"source":["# ChatGPTとは何か\n","\n","2022年末、話題をかっさらったChaptGPT、人間のように自然に対話するモデルであり、自然言語で入力されたテキストを受け取ると、それに対応する返事をテキストとして出力する\n","\n","質問の仕方にかなり忠実に答えるため、例えばプログラムコードを出力させることや、数学・科学・物理などの問題を解かせることなども可能\n","\n","ChatGPTについて述べた論文が出版されていないため、詳細は不明であるが、公式で次のように説明されている\n","\n","- ChatGPTはReinforcement Learning from Human Feedback(RLHF)で学習\n","- InstructGPTと同じ学習手法だが、データ集めの工程が異なる\n"]},{"cell_type":"markdown","source":["https://chat.openai.com/chat"],"metadata":{"id":"vSAkg_I5GTBO"}},{"cell_type":"markdown","source":["次は、ChatGPTに、「ChatGPTとはなんですか？」と聞いてみた答えである\n","\n","![ChatGPTによる説明](https://class.west.sd.keio.ac.jp/dataai/text/chatgptans.png)"],"metadata":{"id":"C-33nxuVHvkD"}},{"cell_type":"markdown","source":["# 基盤モデル(foundation model)について\n","\n","基盤モデルとは、大量・多様なデータから高い汎化性能を獲得したAIのことで、単体で従来のAIには解けなかった多様なタスクを解けることから、AIにパラダイムシフトをもたらすと期待されている\n","\n","- 大量かつ多様なデータで訓練され、多様な下流タスクに適応(ファインチューニングなど)できるモデルで、BERTや、GPT-3、GPT-Rも含まれる\n","\n","なお、同様にAGI(Artificial General Intelligence)もほぼ同じ意味で扱われ、AGI特化型AIに対し人間と同様の感性や思考回路をもつ人工知能のことを指す\n","\n","基盤モデルは、大量のデータで学習したというだけでなく、次のような違いがある\n","- 従来のAIは、解きたいタスクごとにデータセットや人力ラベリングなどを準備し、適切なアーキテクチャモデルを設計・訓練する必要があった\n","- 基盤モデルは、タスクごとに集めるデータは少量でも、目的のタスクに特化させることがなく、分布外データに対する予測性能も優れている\n","- GPT-3など、タスクの内容を自然言語で記述して入力に含めることで、オープンエンドなタスクに数例の訓練サンプルで適応(in-context learning)できるモデルが提供されている\n","\n","従来のAIと基盤モデルの違いを次にまとめる\n","\n","|      | タスク毎に必要なデータ量 | タスク毎のモデリング | 分布外データへの頑健性 |\n","| --- | :---: | :---: | :---: |\n","| 従来 | 大きい | 個別に実施 | 弱い |\n","| 基盤モデル | 小さい | 適応するのみ | 強い |\n","\n","基盤モデルは次のような経緯で発展を遂げている\n","\n","- 2018年発表の大規模言語モデルBERTが、基盤モデルにとって大きな転換期となり、これ以降基盤モデルの議論が活性化した\n","  - BERTはファインチューニングを必要とするが、汎化性能の高さから産業界や別の研究分野で活用され、大規模言語モデルへの注目を集めた\n","\n","- 2020年登場のGPT-3はBERTよりも1,000倍以上多いパラメータを保有しち、in-context learningにより多様なタスクを解くことで話題となった\n","  - in-context learningでは、モデルに入力文だけでなくタスクの説明と入出力例をセットにして入力する\n","  - 感情分析や文書要約を行う場合も、タスクの説明を適切に変更するだけで対応でき、訓練データを集める必要がない\n","  - GPT-3は文章生成、翻訳、文書分類、質問応答などから果ては四則演算や簡単なプログラミングまで行うことができる\n","  - GPT-3のようなモデルでは、予測精度は訓練データや特徴量、モデル、ではなくモデルに与える説明文や入出力例によって大きく影響を受ける\n","    - 予測精度を上げるためには、モデルにとってわかりやすい説明文や入出力例を与えることが重要\n","    - そのための工夫を、特徴量エンジニアリングに対してプロンプトエンジニアリング(prompt engineering)と呼ぶ\n","\n","- 2021年登場の CLIPは、視覚・言語を扱う基盤モデルの道を開いた\n","  - CLIPはテキストと画像を同じ特徴空間に写像する2つのエンコーダで構成される\n","  - CLIPを使うと、次のように任意の画像分類問題を追加の学習なしで解くことができる\n","  - CLIPは画像とテキストというモードの異なる情報を意味的な近さによって結びつけることを可能とした\n","  - テキストから画像を生成するモデルを訓練することも可能となり、その最初の例がDALL·Eであり、その後DALL·E2、Imagen、Parti、Imagen、さらにはStable Diffusionなどが登場\n","\n","- 2022年登場のPaLMは因果関係や常識の理解を要する難しいタスクも解けるようになった\n","  - 入出力の例を示す際に思考過程を含めることで、それまでは解けなかった問題を解けるようになるとも報告されている\n","  \n","- 2022年登場のFlamingoは画像から文章を出力する\n","  - 画像分類に限らず、OCRや動画像に基づく質問応答のようなフリーテキストで回答することができる\n","\n","- 同様に2022登場のGotoは、数値(連続・離散問わず)を扱えるため、ロボットハンドの操作から画像のキャプション生成までを1つのモデルで解くことができる\n","  - 言語や視覚情報を理解できるロボットの実現へ大きく進歩した\n","\n","なお、スケール仮説により膨大なデータ・パラメータ・計算資源を用いた協力なモデルが、2022年5月に発表された言語モデルPaLMのフルモデルは BIG-bench で初めて人間の平均スコアを超えており、自然言語においても人間を凌駕している\n"],"metadata":{"id":"nNm8NrrTMPLQ"}},{"cell_type":"markdown","source":["# プロンプトエンジニアリング\n","\n","プロンプトエンジニアリングは、ChatGPT（GPT-4）などの大規模言語モデル（LLM）を利用する際に、より望ましい結果を得るための必須技術の一つであり、「AI、特に自然言語処理を担う言語モデル(LM)さらにいえば大規模言語モデル(LLM)を効率的に使用するために、言語モデルへの命令(prompt)を開発・最適化する技術」のことである\n","\n","次のような処理をさす\n","\n","- AIが実行するタスクに、適切な質問や指示を与えることで、より望ましい結果を引き出す\n","- LMやLLMでは、工夫せず直接的な(直観的な)質問や指示を与えるだけでは必要としている適切な出力を獲得できない場合があるため、適切なプロンプトを設定することで、AIが効率的に作業を行い、より精度が高く、望ましい結果を出力する確率を高めることができるようになる\n","- 敵対的なプロンプトに対するリスクを軽減するために、プロンプトエンジニアによって対策のためのプロンプトを作成し、プロンプト学習と呼ばれる方法で言語モデルを訓練する\n"],"metadata":{"id":"Z2PNV5cxj9Gf"}},{"cell_type":"markdown","source":["## プロンプトとは\n","\n","言語モデルに対する入力に限らず、次のような内容もプロンプトの構成要素であるが、モデルに依頼するタスクごとに必要な要素は異なる\n","\n","- 指示(Instruction): モデルが実行する特定のタスクや命令\n","- 背景(Context): モデルの回答制度を高めるための追加の情報や文脈\n","- 入力データ(Input Dat): モデルに応答を求める入力や質問\n","- 出力形式/出力指示子(Output Indicator): 出力タイプやフォーマット\n","\n","\n"],"metadata":{"id":"RJawbSHdmDEC"}},{"cell_type":"markdown","source":["## 関連する用語\n","\n","few-shot学習と同じ文脈で、few-shot学習を行うためのプロンプト（テキスト）の\n","書き方に着目したFew-shot Prompting、さらに、例文として「問題を解く手順」までも含めたプロンプトを与えることで、思考の連鎖（CoT：Chain of Thought）few-shotを組み合わせたプロンプティングのテクニックであるFew-shot-CoTがある\n","\n","より大きな言語モデルになるほど文脈内の情報をより効率的に利用できることがわかっており、これをコンテキスト内学習（In-Context Learning）と呼ぶ\n","\n","以下、実際に試行してみよう"],"metadata":{"id":"2gMC36NZsiwH"}},{"cell_type":"markdown","source":["## Zero-shot prompting\n","\n","例やデモンストレーションなしに、いきなり質問を投げる手法\n","\n","- 事前情報を与えずに直接モデルに応答を求める\n","- ChatGPTなど、大量データでトレーニングされ、調整されている言語モデルであれば、Zero-shot promptingだけで十分正しい回答を導くことができる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/zero-shot-prompting.jpg\" width=600>\n","\n","このように、モデルに事前情報を提供することなく、質問と指示を入力して、最終的に必要な応答を求めている\n","\n","シンプルであるが、モデルの回答精度を下げる場合も想定される\n"],"metadata":{"id":"MoVKlvPqm_kF"}},{"cell_type":"markdown","source":["## Few-shot prompting\n","\n","モデルに例やデモンストレーションを提供し、文脈学習を通して質問や指示と回答のパターンを学習させる手法\n","- プロンプトで示した例題が、その回答に対する条件付けとして使われる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/few-shot-prompting.jpg\" width=600>\n","\n","例題の数が多いほど、適切な回答を出力する確率が高まることが期待される\n","\n","Few-shot promptingでは、使う形式も性能に重要な役割を果たします。ランダムなラベルを使用する場合、ラベルと入力テキストの分布の両方が重要です。\n","\n","ラベルを用いた例も示す\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/few-shot-prompting2.jpg\" width=600>\n","\n","この質問では、独特のフォーマットを利用しているが、モデルは正しいラベルを予測する"],"metadata":{"id":"yFRxjPsqt4AB"}},{"cell_type":"markdown","source":["## Chain-of-Thought Prompting\n","\n","連鎖的な思考をさせることで、出力精度を高める手法\n","- 「与えられた問いに対する最終的な答えの思考過程」も言語モデルが生成できるようにすること\n","\n","論理的な思考能力（Reasoning）が求められるタスクなどで、Few-shotでは精度向上が困難な場合への対応として検討された\n","\n","モデルが段階的な推論を必要とする連鎖的な思考において、Chain-of-Thought Promptingにより途中の推論や考え方を学習させておくことで、適切な処理を遂行させることができるとともに、推論をステップに分けて示すことで、回答を間違えた際にミスした段階がわかる\n","\n","次の例のように、思考過程が示されている\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Chain-of-Thought-Prompting.jpg\" width=600>\n"],"metadata":{"id":"q0I61x8_xHCr"}},{"cell_type":"markdown","source":["## Zero-shot CoT\n","\n","Chain-of-Thought（CoT）PromptingをZero-shot Promptingで用いる手法\n","\n","- 回答に至るまでにプロセスを生成することで、精度を向上させる\n","- 具体的に例を与えることなく、「ステップに分けて考えてください」といった一文を付け足し、段階的に推論を進めるよう指示する\n","\n","これだけで精度が向上することが知られている\n","\n","例を示すが、この問題に対して、ChatGPT3.5は正しく解答できなかった。ChatGPT4は、Zero-short CoTを用いずとも正しく解答することができるようになっている\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Zero-shot-CoT.jpg\" width=600>"],"metadata":{"id":"UHEnWB5X1iKJ"}},{"cell_type":"markdown","source":["## Self-Consistency\n","\n","複雑な推論タスクを遂行するために、Few-shot promptingを組み合わせて多様な推論のプロセスを示し、その中から最も整合性の高い回答を選ぶように指示する手法\n","\n","Self-Consistencyの効果を確かめるために、まずは質問をそのまま入力する\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Self-Consistency.jpg\" width=600>\n","\n","正解しているが、連立法的式を用いてきたので、小学校の知識で回答できる鶴亀算を用いるように改めさせる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Self-Consistency2.jpg\" width=600>\n","\n","\n"],"metadata":{"id":"5nH1KnEb4t7W"}},{"cell_type":"markdown","source":["## Generate Knowledge Prompting (知識生成プロンプティング)\n","\n","プロンプトの一部に使用する知識や情報を組み込む手法\n","- 入力文の中に知識を加えることで、正しい推論の出力を得られる可能性が高くなる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Generate-Knowledge-Prompting.jpg\" width=600>\n","\n","プロンプト内に知識を加えることで、より正確な推論の出力が得られている"],"metadata":{"id":"3wEnOjM9CBhv"}},{"cell_type":"markdown","source":["## ReAct\n","\n","「（行動理由の）推論」と「（推論に基づいた）行動」を組み合わせて、言語モデルで推論とタスクを遂行する手法\n","\n","- ReasoningとActingを組み合わせてReActと呼ぶ\n","\n","シンプルな入力プロンプトを用いてタスクに対して推論を行った後、具体的なアクションを列挙する\n","- 推論と行動を交互に実行することで、相乗効果によってより高精度な回答を獲得できるようにする\n","\n","- Wikipediaなどの外部環境から追加情報を推論に組み込むこともでき、「行動」として、外部環境から新しい情報を収集でき、これを「観察」と呼ぶ\n","\n","ReActプロンプトの型としては、以下が使われます。\n","\n","- 文章（質問または指示）\n","- Thought :\n","- Action :\n","- Observation :\n","\n","この場合、Thoughtでは、汎用的な推論となりがちであるが、Actionによって具体的な方法やアドバイスを挙げさせることで、より深い観察を行うことができるようになる\n","\n","但し、試した範囲ではChatGPT May 24 Versionによいて、Thoughtなどの指示を無視し、最初からかなり完璧といえる解答を与えるようである\n","- 解釈する場合も、Actionなどその言葉のままに理解するため、期待している内容とは若干異なるようである"],"metadata":{"id":"HdXbbV61GK7k"}},{"cell_type":"markdown","source":["# ChatGPT向けプロンプトエンジニアリング"],"metadata":{"id":"f3J6bAhJoj3u"}},{"cell_type":"markdown","source":["## プロンプトの要素\n","\n","プロンプトには、以下のいずれかのコンポーネントが含まれることがある\n","\n","- 命令 - モデルに実行してほしい特定のタスクまたは命令\n","- 文脈 - 外部情報や追加の文脈が含まれる場合があり、モデルをより良い応答に導くことができます。\n","- 入力データ - 応答を見つけたい入力または質問\n","- 出力指示子 - 出力のタイプや形式を示します。"],"metadata":{"id":"PQ-lfuISooMt"}},{"cell_type":"markdown","source":["## 事例\n","\n","OpenAIがChatGPTのプロンプトエンジニアリングのベストプラクティスについて示している\n","\n","抜粋して、以下に説明する\n","\n","- 命令をプロンプトの先頭に置き、###または\"\"\"で命令とコンテキストを区切ること\n","  - BAD：  \n","```\n","以下の文章を、最も重要な点を箇条書きにまとめてください。\n","{ここにテキストを入力}。\n","```\n","  - GOOD：  \n","```\n","以下の文章を最も重要な点を箇条書きにまとめてください。\n","\n","テキスト \"\"\"\n","{テキスト入力｝\n","\"\"\"\n","```\n","\n","- 希望する文脈、結果、長さ、形式、スタイルなどについて、具体的、説明的、かつ可能な限り詳細に記述する\n","  - BAD  \n","```\n","OpenAIについて詩を書こう。\n","```\n","  - GOOD:\n","```\n","最近のDALL-Eの製品発表（DALL-Eはテキストから画像へのMLモデル）に焦点を当て、OpenAIに関する感動的な短い詩を｛有名な詩人｝のスタイルで書きなさい。\n","```\n","\n","- 望ましい出力形式を明示すること\n","\n","  - BAD:   \n","```\n","以下のテキストで言及されているエンティティを抽出する。企業名、人名、特定の話題、テーマの4つのエンティティを抽出する。\n","\n","テキスト： {テキスト}。\n","```\n","このような形では、どのように示してよいのかの指示がないためクオリティが落ちる  \n","具体的なフォーマット要件を示すと、モデルはよりよく反応し、プログラムによる複数の出力の確実な解析も容易になる\n","\n","  - GOOD：  \n","```\n","以下のテキストで言及されている重要なエンティティを抽出します。最初にすべての会社名を抽出し、次にすべての人名を抽出し、次に内容に合った特定のトピックを抽出し、最後に一般的な包括的テーマを抽出しなさい。\n","\n","望ましい形式\n","会社名 <comma_separated_list_of_company_names> (コンマで区切られた会社名リスト)\n","人名: -||-人名\n","特定のトピック -||-\n","一般的なテーマ: -||-\n","\n","テキスト {テキスト｝\n","```\n","\n","- Zero-shot, Few-shot, Fine-tuneの順に試すこと\n","  - Zero-shot\n","```\n","以下のテキストからキーワードを抽出しなさい。\n","\n","テキスト {テキスト｝\n","\n","キーワード\n","```\n","  - Few-shot\n","```\n","例をいくつか挙げてください。\n","\n","以下の対応するテキストからキーワードを抽出しなさい。\n","\n","テキスト1: Stripeは、ウェブ開発者がウェブサイトやモバイルアプリケーションに決済処理を統合するために使用できるAPIを提供しています。\n","キーワード1：Stripe、決済処理、API、ウェブ開発者、ウェブサイト、モバイルアプリケーション\n","##\n","テキスト2：OpenAIは、テキストを理解し生成するのに非常に優れた最先端の言語モデルを訓練してきました。私たちのAPIはこれらのモデルへのアクセスを提供し、言語処理を含む事実上すべてのタスクを解決するために使用することができます。\n","キーワード2：OpenAI、言語モデル、テキスト処理、API。\n","##\n","テキスト3：{text}。\n","キーワード 3：\n","```\n","  - Fine-tune  \n","  APIにある調整パラメタを利用して調整する\n","\n","- 不明確な記述を減らす\n","\n","- 何をすべきでないかを言うのではなく、何をすべきかを言う\n","\n","- Code Generation Specific  \n","モデルを特定のパターンに誘導するために「先行詞」を使う  \n","  - BAD:  \n","```\n","# 次の簡単なpythonの関数を書きなさい\n","# 1. マイルで数値を求める\n","# 2. マイルをキロメートルに変換する\n","```\n","  - GOOD:\n","```\n","# 次の簡単なpythonの関数を書きなさい\n","# 1. マイルで数値を求める\n","# 2. マイルをキロに変換する\n","\n","import\n","```\n","この例では、\"import \"を追加することで、Pythonで記述し始めることをモデルに示唆している\n","- 同様に、\"SELECT \"はSQL文の開始を示す良いヒントとなる\n"],"metadata":{"id":"7BeSnRute8ww"}},{"cell_type":"markdown","source":["# 敵対的なプロンプト（Adversarial Prompting）\n","\n","プロンプトによる言語モデルへの攻撃手法のことであり、敵対的なプロンプトによって、モデルが悪影響を受け、精度の低下や、機能不全リスクが想定される\n","\n","言語モデルの進化に伴い、解決されている場合もあるが、本格的な利用では様々な観点で攻撃に対する防御を考えなければならない\n"],"metadata":{"id":"nwX0SIuLJHvT"}},{"cell_type":"markdown","source":["## Prompt-Injection\n","プロンプトインジェクションは、特殊なプロンプトを使用して、モデルの出力を乗っ取ることを目的としていた手法\n","\n","- モデルに行動を変更させるための巧妙な質問や指示を入力することで、想定外の文脈へと誘導する\n","\n","次のような攻撃が考えられる\n","\n","- 第三者の個人情報や機密情報を開示させる\n","- 虚偽の情報や根拠のないデマを拡散させる\n","- 違法行為や危険な行動を助長するような内容を提案させる\n","\n","入力内容次第では適切な回答やデータを阻害し、公開すべきでない情報や機密情報を引き出せる場合もある\n","\n","次のようなケースにおいて、パスワードが盗まれる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Prompt-Injection1.jpg\" width=600>\n","\n","パスワードを与えて、回答内容を制限しようとしている\n","\n","実際次のように与えることで、その指示を守っていることがわかる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Prompt-Injection2.jpg\" width=600>\n","\n","ところが、次のような指示で、あっさりパスワードを教えてしまう\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Prompt-Injection3.jpg\" width=600>\n","\n","これを防ぐには、例えば、(ユーザがこの指示を変更しようとしても、〇〇〇してください)といった指示を加えることで防御することができる場合がある"],"metadata":{"id":"ZFyC33U-KBBr"}},{"cell_type":"markdown","source":["## Prompt-Leaking\n","プロンプトリークプロンプトが保有する情報を引き出すための攻撃手法で、プロンプトインジェクションの一種\n","\n","先ほどの例でも、プロンプトを盗み出すことに成功している\n","\n","例えば、プロンプトに与えられた指示内容を列挙するよう上書きすることで、最初のプロンプトが無視され、さらにはモデルが持っている情報を聞き出すことができるようになる\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Prompt-Leaking.jpg\" width=600>"],"metadata":{"id":"3QE1-wc3K2nW"}},{"cell_type":"markdown","source":["## Jailbreak\n","ジェイルブレイク（Jailbreak）つまり脱獄は、巧妙なプロンプトを使ってモデルの制限を外すための手法\n","\n","ChatGPTなど一般の利用を想定した言語モデルでは、差別や暴力といった非倫理的内容や、危険性や有害性のある行為、違法行為を助長するような回答は出力しないように調整されている\n","\n","ジェイルブレイクにより、モデルに課されている規則に反した指示にも従うケースがあることが確認されている\n","\n","- 日々進化しており、改良されているが、完全には解消されておらず、致命的な欠陥として残されることがある\n","\n","ジェイルブレイクの代表的なアプローチの1つである「モデルに別人格を設定して答えさせる」を使用した例を示す\n","- 2023年のWBCの優勝は日本であるが、別のチーム名が現れ、当然のごとくそれが正解のように回答している\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/Jailbreakpromptattack.jpg\" width=600>\n","\n"],"metadata":{"id":"LWw_UA-l1Zg5"}},{"cell_type":"markdown","source":["## 対策\n","\n","これらに対して、引用符や追加の書式を使うことで、どこがユーザの入力化をわかるようにする工夫、敵対的プロンプトかどうかをLLMに判断するように指示する手法などが提案されている\n","\n","また、アタックをチェックするツールを利用する、ファインチューニングなどで問題となるパターンを排除するなども対策として考えられる\n"],"metadata":{"id":"Cx6KxeKMtqn3"}},{"cell_type":"markdown","source":["# GPT-3\n","\n","GPT-3は、TransformerのDecoderのみで構成された補完モデル、言語モデルであり、そのDecoderモデルを96個重ねた構造を持つ\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/GPT3.png\" width=300>\n","\n","補完モデル、つまり入力された文に自然に続く単語を出力するモデルであり、「今日はとても」と入力すると、例えば「疲れた」と出力され、「今日はとても疲れた」と入力すると、「ので」など出力される\n","\n","言語モデルは教師なし学習であり、人間による調教が不要で、大量の文例があれば、それを学習して、入力文に続く単語を予測し、文章を完成するモデルである\n","\n","GPT-3はそれ自体、かなり正確かつ妥当な文章を生成するモデルであり、その実現のため、1750億個のパラメータを含むモデルを、570GB以上の文章(コーパス)を用いて学習された\n","- この文章はおもにCommon Crawlデータセットと呼ばれる、「インターネットをクロールして取得したコーパス」を用いている\n","- 2016年から2019年にクローリングされた45TBものデータから、学習に有用である570GB以上のデータ抽出され、学習に利用された\n","- GPT-3は入力に対する予測単語の妥当性や、汎用性の高さから広く認知されるようになったが、不正確な文章を生成する、非道徳的な文を生成するといった問題が生じた\n","\n","GPT-3の問題点、つまり、このアラインメント問題を解決するため、InstructGPTが開発された\n","\n","まとめると、次の通りとなる\n","\n","- GPT-3をAlighnmentしてInstructGPTを構築\n","- InstructGPTを対話特化させてChatGPTを構築\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/GPT-3-ChatGPT.png\" width=300>"],"metadata":{"id":"aSrLcM-UZyyl"}},{"cell_type":"markdown","source":["# InstructGPT\n","\n","InstructGPTは望まれない文章が生成されるというアラインメント問題に対処することを目的として開発された\n","\n","望まれる文章か、そうれはないのかを損失関数などを用いて表現するのは非現実的であるため、人間が直接「良い悪い」というフィードバックを学習に組み込めばよい\n","- そこで、人間のフィードバックをもとにモデルを学習させるようにしたのが、InstructGPTであり、RLHF（＝Reinforcement Learning from Human Feedback） とよばれる手法を用いる\n","\n","InstructGPTの学習の流れは次の通りである\n","\n","- 教師ありファインチューニング\n","- Reward Modelの獲得\n","- RLHF\n","\n","RLHFが終わったらふたたびReward Modelの獲得に戻り、よりよいReward Model求めてRLHFを行うという処理を繰り返す\n"],"metadata":{"id":"tPTo3hx__Gwq"}},{"cell_type":"markdown","source":["## STEP1: 教師ありファインチューニング\n","\n","GPT-3に対して教師ありファインチューニング(Supervised Fine-Tuning, SFT)を行う\n","\n","- 純粋な教師あり学習ですあり、GPT-3の初期値として教師なし事前学習した言語モデルを用いる\n","\n","GPT-3はインターネット上の文章で学習されており、さらにGPT-3を人間の好みにアラインメントさせるため、人間好みの文章でGPT-3をファインチューニングする\n","\n","- 訓練済みのラベル付け職人(Trained Labeler)が入力プロンプトとそれに対する所望の出力文を用意する\n","\n","- このように準備したデータでGPT-3をファインチューニングする\n","\n","InstructGPTではこのペアを1万3千文ほど用意している\n","- これをSFTモデルと呼ぶ"],"metadata":{"id":"LL2_1uRT_6_2"}},{"cell_type":"markdown","source":["https://qiita.com/omiita/items/c355bc4c26eca2817324#1-chatgpt%E3%81%A8%E3%81%AF"],"metadata":{"id":"pVgDQAiiANIL"}},{"cell_type":"markdown","source":["## STEP2: Reward Modelの学習"],"metadata":{"id":"mCOlKIp4t1kM"}},{"cell_type":"markdown","source":["### Reward Modelの入力および出力\n","\n","Reward Modelは、人間の代わりに「文の良さ」を評価するモデルであり、入力文とそれに対する文の良さを表したスコア(スカラー)を出力する\n","\n","InstructGPTは文の良さとして次の評価軸を用いている\n","- Truthfullness(正当性)：デマやミスリードの情報かどうか\n","- Harmlessness(無害性): 人や環境を物理的・精神的に傷つけているかどうか\n","- Helpfulness(有益性)：ユーザーのタスクを解決してくれるかどうか\n","\n","Reward Modelのアーキテクチャはパラメータ数60億のGPT-3で構築されている\n","- Reward Modelはあらかじめ質問応答や自然言語推論などの複数のタスクでファインチューニングされている\n","- Reward Modelはスカラーを吐き出すためGPT-3の最終層をスカラー値を出力する層に取り替えている\n","- Reward Modelの初期値はSFTモデルを用いる"],"metadata":{"id":"yDLGWYvmtxg5"}},{"cell_type":"markdown","source":["### Reward Modelの学習について\n","\n","文の良し悪しを評価するReward Model$r_\\theta$の学習方法は次の通りである\n","\n","$\\theta$をReward Modelの重み、プロンプトを$x$、$x$に対する言語モデル(SFTモデルなど)の出力文を$y$とする\n","\n","Reward Modelは入力としてプロンプト$x$およびそれに続く$y$を受け取り、出力としてその良し悪しを表したスカラー値$r_\\theta(x,y)$を出力する\n","\n","さらに詳細には次のとおりである\n","\n","1. プロンプトに対する複数の出力文を用意\n","2. 人間がランク付け\n","3. ランキングをReward Model(RM)に学習させる\n","\n","これらについて順に説明する\n"],"metadata":{"id":"3IfqATj3ADg5"}},{"cell_type":"markdown","source":["1. 入力プロンプト$x$に対するモデルの出力文を$K$個用意する  \n","$K$は$4∼9$の整数値をとり、ここでは例として$K=4$とし、出力文を$y_A,y_B,y_C,y_D$とする\n","\n","2. つづいて人間、すなわち訓練済みのラベル付け職人がこれらの文にランク付けを行う\n","  たとえば、人間の見た目で、$y_D>y_C>y_A=y_B$という結果になった場合、この序列をRMに学習させる\n","\n","3. ランクをRMに学習させる\n","\n","例えば$y_D$と$y_C$の序列をReward Modelに覚えさせる場合、ランキング付けをした人間は$y_D$が$y_C$よりも良いとしているため、Reward Modelの出力も$r_\\theta(x,y_D) > r_\\theta(x,y_C)$となればよい\n","- つまり、$r_\\theta(x,y_D)−r_\\theta(x,y_C)$が最大化されるようにReward Modelを学習させれば良い\n","- 値にシグモイド関数や対数を適用しても同様である\n","\n","これを損失とするため、次の形にして値を最小化するように学習させる\n","\n","$−\\log(\\sigma(r_\\theta(x,y_D)−r_\\theta(x,y_C)))$\n","\n","同様の損失を$y_A,y_B,y_C,y_D$のすべてのペア、すなわち6通り定義する\n","- 任意のペアにおいてランキングが高い方を$y_w$、ランキングが低い方を$y_l$とする\n","- $y_C$と$y_D$のペアの例では$y_w=y_D$、$y_l=y_C$となる\n","- その後、$y_w,y_l$を用いて上式の期待値、つまり平均値を算出する\n","\n","人間によってランキング付けされたデータを$\\mathcal{D}$とすると、\n","\n","$−\\frac{1}{6}\\mathbb{E}_{(x,y_w,y_l)∼\\mathcal{D}}[log(\\sigma(r_\\theta(x,y_w)−r_\\theta(x,y_l)))]$\n","\n","この関数を任意の$K$に対応させると、損失関数は以下の式の通りとなり、これがReward Modelの損失関数となる\n","\n","$loss(\\theta):=−\\frac{1}{_KC_2}\\mathbb{E}_{(x,y_w,y_l)∼\\mathcal{D}}[\\log(\\sigma(r_\\theta(x,y_w)−r_\\theta(x,y_l)))]$\n","\n","以上により、人間のフィードバックとして、文の良さをスカラーで出力するReward Modelが獲得でき、3万3千文のプロンプトを用いて、獲得したReward Modelを最大化するように言語モデルを学習させる\n"],"metadata":{"id":"oUx0cTwQvPL0"}},{"cell_type":"markdown","source":["次のステップ3では、このReward Modelを人間の代わりに使いながらInstuctGPTを学習させるイメージです。"],"metadata":{"id":"zi65rLlopdgN"}},{"cell_type":"markdown","source":["## STEP3: Reinforcement Learning from Human Feedback\n","\n","強化学習を用いてSupervised Fine Tuning (SFT)モデルを人間好みに訓練する\n","- これには、Reward Modelを最大化するようにSFTモデルを学習させる\n","\n","強化学習によりSFTモデルをファインチューニングする\n","- 学習対象のSFTモデルをPolicyと呼ぶ\n","- その学習アルゴリズムに、PPO(Proximal Policy Optimization)を用いる\n","  - PPOはポリシーの大きな更新を抑えながら最適化する手法であり、安定していることから強化学習で幅広く利用されている\n","\n","PPOの目的関数、つまりInstructGPTの目的関数がどのように構成されているかについて説明する\n","\n","Reinforcement Learning from human Feedback(RLHF)の目的であるReward Modelの出力の最大化について、学習対象であるPolicyを$\\pi^{RL}_{\\phi}$とすると、Reward Model $r_\\theta$を最大化することから、次のように表記できる\n","\n","$\\mathbb{E}_{(x,y)∼D_{\\pi^{RL}_{\\phi}}}[r_\\theta(x,y)]$\n","\n","ただし、この式だけでは、Reward Modelの$r_\\theta$の最大化のみにこだわり、出力される文章がでたらめで文章として成立しないという状況が発生しうる\n","\n","そこで、Policyの出力文が、元々のSFTの出力文から大きく変化しすぎないように、KL正則化項を追加する\n","\n","- 復習として、KLダイバージェンスは2つの確率分布間の違い(距離)を求めることができるため、元の文と生成文が離れすぎないようにできる\n","\n","SFTを$\\pi^{S}$、KL正則化項の係数を$\\beta$とすると、KL項を組み込んだ目的関数は下の式のように記述できる\n","\n","$objective_{PPO}(\\phi):=\\mathbb{E}_{(x,y)∼D_{\\pi^{RL}_{\\phi}}}[r_\\theta(x,y)−\\beta log(\\frac{\\pi^{RL}_{\\phi}(y|x)}{\\pi^S(y|x)})]$\n","\n","ここでInstructGPTでは$\\beta=0.02$であり、その項がKL項である\n","\n","KL項の値が大きい、つまり、文が乖離すると全体の値が小さくなる\n","- ここでは目的関数の最大化のため、Policyの学習は、KL項をなるべく小さく抑えつつ学習を進めることになる\n","\n","目的関数にKL項を追加するアイデアは既に存在していたが、InstructGPTではさらに言語モデルの対数尤度を表す項も追加している\n","- これは$objective_{PPO}(\\phi)$で学習したモデルがNLPのベンチマーク性能が劣化した問題を解決するため\n","- Policyの汎化性能低下を抑えるため、対数尤度も目的関数に追加する\n","\n","最終的に、InstructGPTのSTEP3における目的関数は次の通りとなる\n","\n","$objective_{PPO-ptx}(\\phi):=\\mathbb{E}_{(x,y)∼D_{\\pi^{RL}_{\\phi}}}[r_\\theta(x,y)−\\beta log(\\frac{\\pi^{RL}_{\\phi}(y|x)}{\\pi^S(y|x)})]+\\gamma=\\mathbb{E}_{∼D_{pretrain}}[log(\\pi^{RL}_{\\phi})]$\n","\n","$D_{pretrain}$は、GPT-3の事前学習に使われたデータセットからサンプリングされたデータ、$\\gamma=27.8$と比較的大きな値が設定されている\n","\n","STEP2とSTEP3を繰り返し実行することでさらに良い言語モデルが獲得できる\n","\n","STEP3では31,000のプロンプトが使用されており、評価においても、例えば13億パラメータのPPO-ptxが1,750億パラメータのGPTよりもはるかに人間好みの文を出力するといった結果が得られており、さらに、SFTモデルよりもPPOモデルの方が効果的に働いていることから、アラインメント問題の解決にはRLHFがかなり効果的といえる"],"metadata":{"id":"jTF75BUlARo2"}},{"cell_type":"markdown","source":["# ChatGPTとは\n","\n","ChatGPTはInstructGPTとほとんど同じ方法で構築されており、ChatGPTは対話特化型InstructGPTと表現できる\n","\n","ChatGPTとInstructGPTの違いは大きく以下の2点である\n","\n","- モデル: GPT-3.5を利用\n","\n","GPT-3.5では、学習データにはテキストだけでなく、コードも含まれている\n","\n","- データ: 会話データを利用\n","\n","人間が「ユーザーとAI同士の会話」というデータを作成して利用している"],"metadata":{"id":"hVDdCmcTAp4D"}},{"cell_type":"markdown","source":["# ChatGPTの問題点\n","\n","良いことばかりではなく、問題点も\n","\n","現状で、技術的に優れていることはわかるが、即利用可能かは吟味必要\n","- 特に問題となるのが、提供される内容の正確性の検証をどうするかという問題\n","- もう一つが運用面の、責任・補償をどうするかという点\n","\n","AGIでは、この授業そのものの意味もなくなる\n","\n","何故なら、例えば画像認識はAGIで解決する\n","\n","機械の異常検知も、データを渡して、これが正常、これが異常と教えれば、かなり精度の良いモデルを内部に構築し、異常予測をするようになる可能性もある\n","\n","- 他人にデータを渡すのか？という大きな問題をクリアでき、巨大なモデルが構築できれば\n","\n","この運用面で様々な議論が必要で、とんでもないお金が必要(この金額をこの程度と考えられるかどうか）\n","\n","- 数億円規模の投資でnVIDIAのGPUクラスタを導入\n","  - GPT-3のパラメータ数は約1750億個\n","  - GPT-4は嘘ともいわれているが100兆個とささやかれている\n","\n","- 大量のデータを入手するコストはさらにその数十倍\n","  - GPT-3で学習テキストデータ量が45TBから生成した約570GB\n","  - 最初の開発で、40人の契約社員を雇い教師ありトレーニングデータセットを作成\n","  - その後も大量の人を投入してデータを加工し強化学習を行う(詳細不明)\n","\n","- マイクロソフトだけで投資は数千億円\n","- クラウド利用の場合5憶円の利用料を払って漸く計算できる程度のモデルが利用されている\n","- さらに、現在のChatGPTを稼働させるためだけに1億円/日の利用料が必要\n","  - 但し、利用収益もあるため、実際にはそれほどひどい状態ではないが、基本的に収支バランスは取れていない状況\n","\n","\n","### 現状の基盤モデルの問題\n","\n","今後のAI研究のいて重要ではあるが、データ収集コストが大きい、実装コストが高いなどにより、GoogleやMicrosoftなどごく一部の大企業によって研究開発が寡占されている\n","- 基盤モデルに関する成果を秘匿化する潮流があり、AIの脱民主化、つまり開発者や受益者が一部の集団に偏ることが問題視されている"],"metadata":{"id":"3gy6h9nNQkFG"}},{"cell_type":"markdown","source":["# フリーの大規模LLMモデル\n","\n","huggingfaceをハブとしているフリーの大規模LLMモデルは、次のリンクを参照するとよい(git-lfsなど巨大ファイル専用のダウンローダが必要となる)\n","\n","https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"],"metadata":{"id":"5mXEN7BRnjM9"}},{"cell_type":"markdown","source":["# 試してみる(だけどChatGPTは各自でお願い)\n","\n","ここでは、ChatGPTそのものは試すことはできないので(フリーバージョンは各自で http://chat.openai.com にアクセスして試すこと)、Vicunaを試す\n","\n"],"metadata":{"id":"uk7mfqFdn66k"}},{"cell_type":"markdown","source":["## Stable Vicunaとは\n","\n","Stable Vicnaは、Vicuna 13BはLLMモデルをRLHFで学習させたモデル\n","\n","- Vicuna13BはLLaMa(MetaAI)の13BモデルをShareGPTから得られたユーザー同士の会話を利用してFine Tuningしたモデル\n","- Stable Vicuna 13Bモデルは26GBの重みを読み込み、GPUメモリを30GBとCPUも30GBのメモリを消費する\n","\n","Google colabのfree枠で利用するために4bitモデルを利用する\n","- text-generation-webuiを用いることでWebUIでchatやAPIなど様々な形式でLLMのモデルを試すことができる\n","- GPTQ-for-LLaMaは4bit化されたLLMモデルを推論させる際に利用する\n","  - このレポジトリには各種LLMモデルを4bit化した省メモリモデルが入手できる"],"metadata":{"id":"JTDPRMIApyng"}},{"cell_type":"markdown","source":["## Wizard Vicunaとは\n","\n","Wizard Vicunaは、WizardのデータセットとChatGPTの会話拡張、Vicunaのチューニング手法を組み合わせることで従来のLLMモデルよりもさらに性能の良いLLMを生み出そうとする取り組み\n","- Vicuna 13Bを超えてGPT3.5の97%の性能を達成"],"metadata":{"id":"KRuDGHBArV4d"}},{"cell_type":"markdown","source":["## 環境構築\n","\n","GPTQとtext-generation-webuiのインストールする"],"metadata":{"id":"VtLbugBOrnMz"}},{"cell_type":"code","source":["!git clone https://github.com/oobabooga/text-generation-webui\n","%cd text-generation-webui\n","!pip install -r requirements.txt\n","!git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n","%cd GPTQ-for-LLaMa\n","!python setup_cuda.py install\n","!cp -r /content/text-generation-webui/GPTQ-for-LLaMa/* /content/text-generation-webui/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PxmsL5Piq7QQ","executionInfo":{"status":"ok","timestamp":1692405429545,"user_tz":-540,"elapsed":179842,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"e580d24d-6bca-48ea-b48f-369a87137562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'text-generation-webui'...\n","remote: Enumerating objects: 10586, done.\u001b[K\n","remote: Counting objects: 100% (2611/2611), done.\u001b[K\n","remote: Compressing objects: 100% (324/324), done.\u001b[K\n","remote: Total 10586 (delta 2411), reused 2341 (delta 2287), pack-reused 7975\u001b[K\n","Receiving objects: 100% (10586/10586), 3.49 MiB | 17.33 MiB/s, done.\n","Resolving deltas: 100% (7214/7214), done.\n","/content/text-generation-webui\n","Collecting git+https://github.com/huggingface/peft@4b371b489b9850fd583f204cdf8b5471e098d4e4 (from -r requirements.txt (line 23))\n","  Cloning https://github.com/huggingface/peft (to revision 4b371b489b9850fd583f204cdf8b5471e098d4e4) to /tmp/pip-req-build-6c883uur\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-6c883uur\n","  Running command git rev-parse -q --verify 'sha^4b371b489b9850fd583f204cdf8b5471e098d4e4'\n","  Running command git fetch -q https://github.com/huggingface/peft 4b371b489b9850fd583f204cdf8b5471e098d4e4\n","  Resolved https://github.com/huggingface/peft to commit 4b371b489b9850fd583f204cdf8b5471e098d4e4\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting git+https://github.com/huggingface/transformers@baf1daa58eb2960248fd9f7c3af0ed245b8ce4af (from -r requirements.txt (line 24))\n","  Cloning https://github.com/huggingface/transformers (to revision baf1daa58eb2960248fd9f7c3af0ed245b8ce4af) to /tmp/pip-req-build-nb8ivzgn\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-nb8ivzgn\n","  Running command git rev-parse -q --verify 'sha^baf1daa58eb2960248fd9f7c3af0ed245b8ce4af'\n","  Running command git fetch -q https://github.com/huggingface/transformers baf1daa58eb2960248fd9f7c3af0ed245b8ce4af\n","  Running command git checkout -q baf1daa58eb2960248fd9f7c3af0ed245b8ce4af\n","  Resolved https://github.com/huggingface/transformers to commit baf1daa58eb2960248fd9f7c3af0ed245b8ce4af\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Ignoring bitsandbytes: markers 'platform_system == \"Windows\"' don't match your environment\n","Ignoring auto-gptq: markers 'platform_system == \"Windows\"' don't match your environment\n","Collecting auto-gptq==0.4.1+cu117 (from -r requirements.txt (line 29))\n","  Downloading https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.1/auto_gptq-0.4.1+cu117-cp310-cp310-linux_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hIgnoring exllama: markers 'platform_system == \"Windows\"' don't match your environment\n","Collecting exllama==0.0.10+cu117 (from -r requirements.txt (line 31))\n","  Downloading https://github.com/jllllll/exllama/releases/download/0.0.10/exllama-0.0.10+cu117-cp310-cp310-linux_x86_64.whl (355 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hIgnoring llama-cpp-python: markers 'platform_system == \"Windows\"' don't match your environment\n","Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\"' don't match your environment\n","Collecting llama-cpp-python-cuda==0.1.78+cu117 (from -r requirements.txt (line 38))\n","  Downloading https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.1.78+cu117-cp310-cp310-linux_x86_64.whl (12.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hIgnoring gptq-for-llama: markers 'platform_system == \"Windows\"' don't match your environment\n","Collecting gptq-for-llama==0.1.0+cu117 (from -r requirements.txt (line 42))\n","  Downloading https://github.com/jllllll/GPTQ-for-LLaMa-CUDA/releases/download/0.1.0/gptq_for_llama-0.1.0+cu117-cp310-cp310-linux_x86_64.whl (728 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.7/728.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ctransformers==0.2.22+cu117 (from -r requirements.txt (line 45))\n","  Downloading https://github.com/jllllll/ctransformers-cuBLAS-wheels/releases/download/AVX2/ctransformers-0.2.22+cu117-py3-none-any.whl (14.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles==23.1.0 (from -r requirements.txt (line 1))\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Collecting fastapi==0.95.2 (from -r requirements.txt (line 2))\n","  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio_client==0.2.5 (from -r requirements.txt (line 3))\n","  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio==3.33.1 (from -r requirements.txt (line 4))\n","  Downloading gradio-3.33.1-py3-none-any.whl (20.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.21.0 (from -r requirements.txt (line 6))\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama (from -r requirements.txt (line 7))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting datasets (from -r requirements.txt (line 8))\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops (from -r requirements.txt (line 9))\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.4.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.5.3)\n","Collecting Pillow>=9.5.0 (from -r requirements.txt (line 13))\n","  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.31.0)\n","Collecting safetensors==0.3.1 (from -r requirements.txt (line 16))\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.10.1)\n","Collecting sentencepiece (from -r requirements.txt (line 18))\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (2.12.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (4.66.1)\n","Collecting wandb (from -r requirements.txt (line 21))\n","  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bitsandbytes==0.41.1 (from -r requirements.txt (line 26))\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-cpp-python==0.1.78 (from -r requirements.txt (line 34))\n","  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 (from fastapi==0.95.2->-r requirements.txt (line 2))\n","  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi==0.95.2->-r requirements.txt (line 2))\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client==0.2.5->-r requirements.txt (line 3)) (2023.6.0)\n","Collecting httpx (from gradio_client==0.2.5->-r requirements.txt (line 3))\n","  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio_client==0.2.5->-r requirements.txt (line 3))\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client==0.2.5->-r requirements.txt (line 3)) (23.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio_client==0.2.5->-r requirements.txt (line 3)) (4.7.1)\n","Collecting websockets (from gradio_client==0.2.5->-r requirements.txt (line 3))\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (3.8.5)\n","Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (4.2.2)\n","Collecting ffmpy (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (3.0.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (2.1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (3.7.1)\n","Collecting mdit-py-plugins<=0.3.3 (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.33.1->-r requirements.txt (line 4)) (2.16.1)\n","Collecting python-multipart (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting uvicorn>=0.14.0 (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->-r requirements.txt (line 6)) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->-r requirements.txt (line 6)) (2.0.1+cu118)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78->-r requirements.txt (line 34))\n","  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 8)) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements.txt (line 8))\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets->-r requirements.txt (line 8))\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 8))\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 15)) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 15)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 15)) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 15)) (2023.7.22)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.0.0)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (2.3.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.41.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 21)) (8.1.6)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 21))\n","  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 21))\n","  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 21))\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb->-r requirements.txt (line 21))\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb->-r requirements.txt (line 21))\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 21)) (1.4.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0->-r requirements.txt (line 24)) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0->-r requirements.txt (line 24)) (2023.6.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.0.dev0->-r requirements.txt (line 24))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge (from auto-gptq==0.4.1+cu117->-r requirements.txt (line 29))\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers==0.2.22+cu117->-r requirements.txt (line 45)) (9.0.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (0.12.0)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 21)) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.33.1->-r requirements.txt (line 4)) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 19)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 19)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 19)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 19)) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.33.1->-r requirements.txt (line 4)) (0.1.2)\n","Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.33.1->-r requirements.txt (line 4)) (2.0.2)\n","INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n","Collecting mdit-py-plugins<=0.3.3 (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n","  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n","INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n","  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n","  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n","  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n","  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n","  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n","Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi==0.95.2->-r requirements.txt (line 2)) (3.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (16.0.6)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.33.1->-r requirements.txt (line 4))\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio_client==0.2.5->-r requirements.txt (line 3))\n","  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio_client==0.2.5->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 4)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 4)) (4.42.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 4)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->-r requirements.txt (line 2)) (1.1.3)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 4)) (0.9.2)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.33.1->-r requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 19)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 19)) (3.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0->-r requirements.txt (line 6)) (1.3.0)\n","Building wheels for collected packages: llama-cpp-python, peft, transformers, ffmpy, pathtools\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl size=294844 sha256=51a89101f7a4ff5c18e8ddd2da1f015fc8b7659805cb792fcacabce29e038db5\n","  Stored in directory: /root/.cache/pip/wheels/61/f9/20/9ca660a9d3f2a47e44217059409478865948b5c8a1cba70030\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for peft: filename=peft-0.5.0.dev0-py3-none-any.whl size=82316 sha256=c75fbbfe4b620dac99671af1c9dee588785557dda96346e4635d4b4ec3851e22\n","  Stored in directory: /root/.cache/pip/wheels/a6/dd/65/e8a3c594282a37ef6a4033d96c998c74d3cb4d7978f25bd580\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7446865 sha256=18eb942142b8d34b887fbcb4804ae6dfec0afbaff25b376186317e95568e6b2c\n","  Stored in directory: /root/.cache/pip/wheels/f6/48/92/9e4123ac1ebdcbfb22ad4c8490a4c2425b143314be3957af7b\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=fc3b9f89e2b57d646fa216cc27f44bf13a06c612a2a0e29bc2ba5e711b38376d\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=03253f4910e917137391b2eec585ae871d7433b4baba1fcf1a02062d4ca0cbb9\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built llama-cpp-python peft transformers ffmpy pathtools\n","Installing collected packages: tokenizers, sentencepiece, safetensors, pydub, pathtools, gptq-for-llama, ffmpy, bitsandbytes, xxhash, websockets, smmap, setproctitle, sentry-sdk, semantic-version, rouge, python-multipart, pydantic, Pillow, orjson, markdown-it-py, h11, einops, docker-pycreds, diskcache, dill, colorama, aiofiles, uvicorn, starlette, multiprocess, mdit-py-plugins, llama-cpp-python-cuda, llama-cpp-python, huggingface-hub, httpcore, gitdb, transformers, httpx, GitPython, fastapi, ctransformers, wandb, gradio_client, datasets, gradio, accelerate, peft, exllama, auto-gptq\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.1.1\n","    Uninstalling pydantic-2.1.1:\n","      Successfully uninstalled pydantic-2.1.1\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 9.4.0\n","    Uninstalling Pillow-9.4.0:\n","      Successfully uninstalled Pillow-9.4.0\n","  Attempting uninstall: markdown-it-py\n","    Found existing installation: markdown-it-py 3.0.0\n","    Uninstalling markdown-it-py-3.0.0:\n","      Successfully uninstalled markdown-it-py-3.0.0\n","  Attempting uninstall: mdit-py-plugins\n","    Found existing installation: mdit-py-plugins 0.4.0\n","    Uninstalling mdit-py-plugins-0.4.0:\n","      Successfully uninstalled mdit-py-plugins-0.4.0\n","Successfully installed GitPython-3.1.32 Pillow-10.0.0 accelerate-0.21.0 aiofiles-23.1.0 auto-gptq-0.4.1+cu117 bitsandbytes-0.41.1 colorama-0.4.6 ctransformers-0.2.22+cu117 datasets-2.14.4 dill-0.3.7 diskcache-5.6.1 docker-pycreds-0.4.0 einops-0.6.1 exllama-0.0.10+cu117 fastapi-0.95.2 ffmpy-0.3.1 gitdb-4.0.10 gptq-for-llama-0.1.0+cu117 gradio-3.33.1 gradio_client-0.2.5 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 llama-cpp-python-0.1.78 llama-cpp-python-cuda-0.1.78+cu117 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 multiprocess-0.70.15 orjson-3.9.5 pathtools-0.1.2 peft-0.5.0.dev0 pydantic-1.10.12 pydub-0.25.1 python-multipart-0.0.6 rouge-1.0.1 safetensors-0.3.1 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 starlette-0.27.0 tokenizers-0.13.3 transformers-4.32.0.dev0 uvicorn-0.23.2 wandb-0.15.8 websockets-11.0.3 xxhash-3.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Cloning into 'GPTQ-for-LLaMa'...\n","remote: Enumerating objects: 818, done.\u001b[K\n","remote: Counting objects: 100% (120/120), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 818 (delta 107), reused 100 (delta 100), pack-reused 698\u001b[K\n","Receiving objects: 100% (818/818), 469.29 KiB | 13.80 MiB/s, done.\n","Resolving deltas: 100% (497/497), done.\n","/content/text-generation-webui/GPTQ-for-LLaMa\n","running install\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` directly.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` and ``easy_install``.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://github.com/pypa/setuptools/issues/917 for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","running bdist_egg\n","running egg_info\n","creating quant_cuda.egg-info\n","writing quant_cuda.egg-info/PKG-INFO\n","writing dependency_links to quant_cuda.egg-info/dependency_links.txt\n","writing top-level names to quant_cuda.egg-info/top_level.txt\n","writing manifest file 'quant_cuda.egg-info/SOURCES.txt'\n","/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n","reading manifest file 'quant_cuda.egg-info/SOURCES.txt'\n","writing manifest file 'quant_cuda.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_ext\n","/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n","  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n","building 'quant_cuda' extension\n","creating build\n","creating build/temp.linux-x86_64-cpython-310\n","x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c quant_cuda.cpp -o build/temp.linux-x86_64-cpython-310/quant_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=quant_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n","/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c quant_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-310/quant_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=quant_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++17\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n","          detected during:\n","            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n","(61): here\u001b[0m\n","            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n","/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\u001b[0m\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n","          detected during:\n","            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n","(61): here\u001b[0m\n","            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n","/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\u001b[0m\n","\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  222 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:154:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  122 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1010:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1031:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1055:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1082:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1105:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:1998:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:2019:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:2042:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:2068:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:166:2091:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  166 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  222 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:154:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  122 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1010:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1031:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1055:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1082:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1105:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:1998:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:2019:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:2042:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:2068:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:261:2091:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  261 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  222 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:154:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  122 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1010:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1031:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1055:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1082:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1105:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:1998:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:2019:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:2042:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:2068:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:420:2091:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  420 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  222 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:154:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  122 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n","      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1010:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1031:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1055:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1082:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1105:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:1998:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:2019:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:2042:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:2068:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[Kquant_cuda_kernel.cu:507:2091:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n","  507 |   AT_DISPATCH_FLOATING_TYPES(\n","      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n","\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:244:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  244 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n","      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","creating build/lib.linux-x86_64-cpython-310\n","x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/quant_cuda.o build/temp.linux-x86_64-cpython-310/quant_cuda_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/quant_cuda.cpython-310-x86_64-linux-gnu.so\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","copying build/lib.linux-x86_64-cpython-310/quant_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n","creating stub loader for quant_cuda.cpython-310-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/quant_cuda.py to quant_cuda.cpython-310.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying quant_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying quant_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying quant_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying quant_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","zip_safe flag not set; analyzing archive contents...\n","__pycache__.quant_cuda.cpython-310: module references __file__\n","creating dist\n","creating 'dist/quant_cuda-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing quant_cuda-0.0.0-py3.10-linux-x86_64.egg\n","creating /usr/local/lib/python3.10/dist-packages/quant_cuda-0.0.0-py3.10-linux-x86_64.egg\n","Extracting quant_cuda-0.0.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n","Adding quant-cuda 0.0.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/quant_cuda-0.0.0-py3.10-linux-x86_64.egg\n","Processing dependencies for quant-cuda==0.0.0\n","Finished processing dependencies for quant-cuda==0.0.0\n"]}]},{"cell_type":"markdown","source":["## 推論\n","\n","モデルのダウンロード"],"metadata":{"id":"ijPIv66or6Vy"}},{"cell_type":"code","source":["%cd /content/text-generation-webui\n","!python download-model.py TheBloke/wizard-vicuna-13B-GPTQ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xHJIHn7q9Xk","executionInfo":{"status":"ok","timestamp":1692405455766,"user_tz":-540,"elapsed":26226,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"9d9ec74b-11a8-4bfa-8c69-68da897b833a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/text-generation-webui\n","Downloading the model to models/TheBloke_wizard-vicuna-13B-GPTQ\n","100% 9.01k/9.01k [00:00<00:00, 46.4MiB/s]\n","100% 551/551 [00:00<00:00, 4.50MiB/s]\n","100% 132/132 [00:00<00:00, 1.21MiB/s]\n","100% 57.0/57.0 [00:00<00:00, 469kiB/s]\n","100% 435/435 [00:00<00:00, 3.61MiB/s]\n","100% 500k/500k [00:00<00:00, 34.3MiB/s]\n","100% 727/727 [00:00<00:00, 5.85MiB/s]\n","100% 194k/194k [00:00<00:00, 2.28MiB/s]\n","100% 7.26G/7.26G [00:24<00:00, 296MiB/s]\n"]}]},{"cell_type":"markdown","source":["WebUI起動"],"metadata":{"id":"W1cuohFar-l4"}},{"cell_type":"code","source":["%cd /content/text-generation-webui\n","!python3 server.py --model TheBloke_wizard-vicuna-13B-GPTQ --wbits 4 --group 128 --chat --share --auto-devices  --model_type=llama"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQnEh9rWrAJU","executionInfo":{"status":"ok","timestamp":1692406000259,"user_tz":-540,"elapsed":544504,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"34c17866-06ea-4b23-bb6b-14ad47c745a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/text-generation-webui\n","2023-08-19 00:37:25 WARNING:\u001b[33mThe --chat flag has been deprecated and will be removed soon. Please remove that flag.\u001b[0m\n","2023-08-19 00:37:25 WARNING:\u001b[33mThe gradio \"share link\" feature uses a proprietary executable to create a reverse tunnel. Use it with care.\u001b[0m\n","2023-08-19 00:37:30.767248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-08-19 00:37:32 INFO:\u001b[32mLoading TheBloke_wizard-vicuna-13B-GPTQ...\u001b[0m\n","2023-08-19 00:37:32 WARNING:\u001b[33mAuto-assiging --gpu-memory 15 for your GPU to try to prevent out-of-memory errors. You can manually set other values.\u001b[0m\n","2023-08-19 00:37:32 INFO:\u001b[32mThe AutoGPTQ params are: {'model_basename': 'wizard-vicuna-13B-GPTQ-4bit.compat.no-act-order', 'device': 'cuda:0', 'use_triton': False, 'inject_fused_attention': True, 'inject_fused_mlp': True, 'use_safetensors': True, 'trust_remote_code': False, 'max_memory': {0: '15GiB', 'cpu': '99GiB'}, 'quantize_config': None, 'use_cuda_fp16': True, 'disable_exllama': False}\u001b[0m\n","2023-08-19 00:37:34 WARNING:\u001b[33mThe safetensors archive passed at models/TheBloke_wizard-vicuna-13B-GPTQ/wizard-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors does not contain metadata. Make sure to save your model with the `save_pretrained` method. Defaulting to 'pt' metadata.\u001b[0m\n","2023-08-19 00:37:44 WARNING:\u001b[33mskip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\u001b[0m\n","2023-08-19 00:37:44 WARNING:\u001b[33mmodels/TheBloke_wizard-vicuna-13B-GPTQ/tokenizer_config.json is different from the original LlamaTokenizer file. It is either customized or outdated.\u001b[0m\n","2023-08-19 00:37:44 WARNING:\u001b[33mmodels/TheBloke_wizard-vicuna-13B-GPTQ/special_tokens_map.json is different from the original LlamaTokenizer file. It is either customized or outdated.\u001b[0m\n","2023-08-19 00:37:44 INFO:\u001b[32mLoaded the model in 12.75 seconds.\n","\u001b[0m\n","2023-08-19 00:37:44 INFO:\u001b[32mLoading the extension \"gallery\"...\u001b[0m\n","Running on local URL:  http://127.0.0.1:7860\n","Running on public URL: https://1a53a278974d02ede1.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","Output generated in 5.16 seconds (2.13 tokens/s, 11 tokens, context 44, seed 1747089653)\n","Output generated in 3.08 seconds (15.24 tokens/s, 47 tokens, context 90, seed 549430180)\n","Output generated in 7.28 seconds (16.49 tokens/s, 120 tokens, context 173, seed 1919053974)\n","\n","Killing tunnel 127.0.0.1:7860 <> https://1a53a278974d02ede1.gradio.live\n","^C\n"]}]},{"cell_type":"markdown","source":["次のようなリンクが最後に出力されるはずである\n","```\n","INFO:Loading the extension \"gallery\"...\n","Running on local URL:  http://127.0.0.1:7860\n","Running on public URL: https://87f0162cbf194df9a3.gradio.live\n","```\n","出力された、実際にアクセスする\n","- アクセスするのはgradio.liveの方である"],"metadata":{"id":"bEiWDP0_sKGw"}},{"cell_type":"markdown","source":["## 試してみよう\n","\n","英語でも、日本語でも会話できる\n","\n","ChatpGPTの無料版は、GPT-3.5であるため、有料版でなければほぼ変わらない性能を発揮するはずである\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/vicuna.jpg\">"],"metadata":{"id":"XbSun-absmlo"}},{"cell_type":"markdown","source":["# 課題\n","\n","Stable VicunaもしくはChatGPTを用いて、実際にプロンプトエンジニアリングを行いその効果を確認しなさい"],"metadata":{"id":"kfA1hQ5N0lU6"}}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/keioNishi/lec-dataai/blob/main/dataai-text-J-Diffusion.ipynb","timestamp":1661617425151},{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb","timestamp":1661425026567}],"gpuType":"V100","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}