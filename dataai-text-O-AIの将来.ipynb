{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vA0-Do6hDCKDgIOHDUYKbB-NESiYNhz4","timestamp":1550400382117}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"1tORJzc5R6Tc"},"source":["---\n",">「 変わることがなければ成長することもない。\\\n","> 成長することがなければ真に生きていない。」\\\n","> ビル・ゲイツ\n","\n","> 「科学の基礎をなすものは、物理界に於いても、化学界に於いても、\\\n","> すべて仮説だ。肉眼で見とどける事の出来ない仮説から出発している。\\\n","> この仮説を信仰するところから、すべての科学が発生するのだ。」\\\n","> 太宰治\n","\n",">「理論とは仮説です。それは仮説に過ぎません。」\\\n",">スティーヴン・ホーキング\n","---"]},{"cell_type":"markdown","source":["# 深層学習の本質への探究\n","\n","DNNには本質を理解する上で大きなヒントとなるであろう仮説がいくつか存在する\n","\n","- DNNの世界では、証明されていないことの方が多いため、どちらかというと仮説しか存在しない\n","\n","既に多様体仮説については説明したが、ここでは、相転移仮説、スケーリング仮説、平坦解仮説などについて説明する\n","\n","きちんと証明されていないが、これら仮説を理解することで、このわけのわからないものを解釈しなければならない、という状況を改善する一助になるであろう\n","- 仮説ファンには面白い話かもしれない"],"metadata":{"id":"X5Cc3Ul0sfzj"}},{"cell_type":"markdown","source":["## Grokking (ですよねー現象）と相転移仮説\n","\n","grokkingとは、過学習した後しばらくすると、急に汎化誤差が下がる、つまり正解率が上昇する現象\n","- 2022年に初めて報告された\n","- 正解率上昇の時間差は、訓練データが多いほど小さくなる\n","- 大量に訓練データが準備することでこの現象を利用する試みが既になされている\n","\n","次の図のように、trainロスが改善してもvalidationロスは改善せず、遅れて改善する\n","\n","また、データセットが多いほど、その間のタイムラグが短くなる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/grokkingpower.png\" width=800>\n","\n","この現象を説明する仮説として相転移仮説がある\n","- 学習は初期化、過学習、表現学習の順で進むが、grokkingは過学習から表現学習への相転移であると解釈できる\n","- 検証データへの汎化性能は表現学習によって獲得されるが、データが少ないとそのプロセスが阻害され、相転移にかかる時間が拡大する\n","\n","\n"],"metadata":{"id":"m2vRFaPisnlA"}},{"cell_type":"markdown","source":["## スケーリング仮説 (スケーリング則)\n","\n","性能が数や量などに比例など一定の関係で向上し、飽和しない、もしくは飽和しにくい難い場合にスケールする、スケーラビリティが高いなどと表現する\n","\n","スケーラビリティがあるとき、その関係をスケーリング則と呼ぶ\n","\n","スケーリング仮説は、NNの性能にスケーリング則があるという仮説である\n","\n","言語モデルなどのNNの性能が、訓練ステップ数、データセットのサイズ、パラメータ数のそれぞれについてべき乗則に従うという経験則\n","- 要するにデータセット・モデル・計算資源それぞれに対して指数関数的に性能が高くなり、またその向上に制限がないということ\n","\n","図はx軸が計算資源、y軸が検証ロス値、色がパラメータ数を表し、どのような学習モデルケースでも同様に当てはまることがわかる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/scalingrule.png\" width=700>\n","\n","この経験則が2020年に報告されて以来、モデルの大規模化やデータセットの巨大化が深層学習の一大トレンドとなった\n","\n","- AGIの開発を目指すOpenAIが5億円の開発費(人件費込みで15億円)を投じて1750億パラメータのGTP-3の作成に着手する動機として十分であった、その後さらにGPT-4へと繋がっている\n","\n","- しかしながら、実際にはべき関数の指数は小さく、これがボトルネックとなっており、データを2倍に増やしても誤答率が2%しか改善しないといった結果となる場合もある\n","\n","データセットのサイズについては、データを増やすに従って情報利得の小さいサンプル(汎化性能を高め精度向上に寄与しないサンプル)の割合が増えるためと考えられる\n","\n","- なお、このスケーリング則は多様体仮説により説明できるとされている\n","\n","- この考えを逆に利用し、そのような情報利得の小さいデータを除去することで学習効率を改善できるはずであり、実際そのような結果を得ることができている\n","- ChatGPTも同様の処理を手作業で行っている\n","\n","さらに、データが不十分なときは簡単な(決定境界から遠い)サンプルのみを、十分なときは難しい(決定境界から近い)サンプルのみを残すという除去方法により、学習効率をべき関数($x^k$)から指数関数($k^x$)に改善することができるとされている\n","\n","- この結果はCIFAR-10などのデータを使った場合でも矛盾しない結果が得られており、かなり美しい曲線をもって評価できることがわかっている\n","  - データセットをどのように入力するかがかなり重要ということ\n","- 単層パーセプトロンを用いた場合の、「サンプルサイズ対パラメータ数の比」と「テスト誤差」の関係が次のように評価されており、全データを使う場合は両対数グラフ上で直線として示すことができ、ここから、パレートフロンティアの曲線へ学習効率を改善できることが示されている\n","  - パレート解：多目的最適化問題において、目的関数同士が異なる最適化における支配関数を有するなかで、理想的な解にできるだけ近い解\n","  - パレートフロンティア：複数のパレート解で構成される曲面\n","\n","なお、スケーリング則をべき関数でフィッティングすることの妥当性そのものに疑問の声もある\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/scalingsorscher.png\" width=500>\n"],"metadata":{"id":"N1SSejTZw__e"}},{"cell_type":"markdown","source":["人間に当てはめようとは考えないこと\n","- データセット(学ぶ材料の良さ)、訓練ステップ数(勉強時間)、パラメータ数(地頭の良さ・引き出しの多さ)のべき乗に成績が比例し、学ぶ材料を工夫することで指数関数まで持っていける(お金をかける)などと考えると若干悲しい気もする"],"metadata":{"id":"-cgI2PFEO0B_"}},{"cell_type":"markdown","source":["## オプティマイザの発展\n"],"metadata":{"id":"4KyhzNPAyaMF"}},{"cell_type":"markdown","source":["### 平坦解仮説の利用\n","\n","深層学習が汎化性能を持つ理由を平坦解(flat minima)として説明する仮説\n","- パラメータ空間で損失関数がとる曲面を考えたときに、解周辺が平坦な解の汎化誤差は小さいという仮説\n","- 平坦解の獲得には、層を重ねることや、正規化層を入れることなども貢献することが示されている\n","- さらに、平坦解の概念を積極的に取り入れたオプティマイザとして、SWA(stochastic weight averaging)やSAM(sharpness-aware minization)が提案されている\n","  - このようにオプティマイザも発展を遂げている\n"],"metadata":{"id":"UZQi-hxy1lfI"}},{"cell_type":"markdown","source":["### Adamハイパーパラメータ解析\n","\n","- Adamのハイパーパラメータであるβ1とβ2が収束・発散にどう影響するかを理論的に解析することで、β1とβ2を適切に選べばAdamは勾配に関する制約なしに収束することが示されている\n","  - 要するに2つのパラメータを変化させたときのAdamの収束・発散領域が示されている\n","  - さらに、実用的なβ1とβ2の決定方法として、β2をなるべく大きくとり、β1はβ1<√β2の範囲で選ぶ手法も提案されている\n","\n","  <img src=\"http://class.west.sd.keio.ac.jp/dataai/text/zang.png\" width=800>\n"],"metadata":{"id":"WkMeYwL_1orr"}},{"cell_type":"markdown","source":["### 再帰的ハイパーパラメータ推定\n","\n","- 勾配降下法のステップサイズやモメンタムの係数などのハイパーパラメータの最適値を、これまた勾配降下法で求める、さらにその勾配降下法におけるハイパーパラメータの最適な値も勾配降下法で求める、という再帰的な方法で求める手法\n","  - 再帰を繰り返すほど、ハイパーパラメータの初期値の影響を受けにくくなる\n","\n","著名なオプティマイザも継続してその向上が図られている\n"],"metadata":{"id":"NwUocmDs1rs1"}},{"cell_type":"markdown","source":["# ニューラルネットワークへの攻撃\n"],"metadata":{"id":"1GvZFn_01iTW"}},{"cell_type":"markdown","source":["## 攻撃の種類\n","\n","- NNへの攻撃として敵対的入力(adversarial example)が有名\n","  - 既に説明した通り、例えば、分類器が正しく分類できていた画像に、人の目では判別できない程度のノイズをのせることで、作為的に分類器の判断を誤らせることができるなど\n","\n","- 分類モデルから訓練サンプルを復元する攻撃\n","  - 訓練サンプルの復元が生成モデルで可能なことは知られているが、分類モデルでもパラメータが既知という仮定の下では可能であることが示されている\n","\n","- NNへのバックドア攻撃\n","  - サプライチェーン上に仕掛けをすることで、特定の入力に対して意図した振る舞いをするように学習させる攻撃\n","  - データや訓練コードを操作する方法が知られているが、NNのパラメータを手動で改ざんする手法も存在する\n"],"metadata":{"id":"YbNwT8JJ13A7"}},{"cell_type":"markdown","source":["# バイアス属性と攻撃との関係\n","\n","バイアス属性とは、本来無関係である対象を、学習データにおいて共起することが多いがゆえに、予測結果に影響を与える属性のこと\n","\n","例えば画像認識において鳥を認識する場合、一般に空と共に映っている場合が多く、本来は空は鳥と認識されるものではないが、見かけ上の相関として空と鳥を一緒に鳥と認識するような結果をえること\n","\n","- 深層学習モデルの予測はバイアス属性の影響を受けやすいことが知られている\n","\n","これに対処するためには、訓練データにバイアス属性と異なるサンプルを多く含めればよい\n","\n","- 例えば、地上を歩く、もしくは飛んでいる鳥で空が映っていないといった画像を多く集めればよいが、そのようなデータの収取そのものが困難であることが多い\n","\n","一方で検証する際も、同様にバイアス属性を含む絵で検証されることが多いため、認識精度そのものに大きく影響することもない\n","\n","- このことが、例えば空にノイズをいれることで、鳥そのものの認識も困難になるといった原因になりえる"],"metadata":{"id":"5vQWcpQJ15ix"}},{"cell_type":"markdown","source":["# 学習済みモデルに対する評価と評価向上のための編集\n","\n","大規模モデルは作成すると配布するなどして広く利用することを前提としているため、そのモデルを多角的に評価しておく必要がある\n","\n","- NNが獲得した表現の良さをタスクに依存しない形で評価する手法や、画像を扱うモデルの望ましくない挙動を体系的に検査するフレームワークなどが提案されている\n","- さらに、評価プロセスで見つかった「望ましくない挙動」を訓練後に修正する方法として、悪い挙動の原因となっている訓練サンプルを特定し、その影響を取り消す手法、分布外(異常値ともいえる)サンプルに対する確信度を調節する手法などがある\n","\n","\n"],"metadata":{"id":"p9I-hWcp3I5G"}},{"cell_type":"markdown","source":["# 生成AI\n","\n"],"metadata":{"id":"SzS8W8R3F3pF"}},{"cell_type":"markdown","source":["## 分類\n","\n","生成AIは、何を生成するかによって大別できる\n","\n","テキスト、プログラムコード、画像、動画、3Dモデル(CAD)、音声など\n","\n","画像であれば、若き日にあらゆる画風を描きえた画家の名前を冠する「DALL-E2」、Discord上で用いる「Midjourney」、データモデルが一般公開された「Stable Diffusion」など\n","\n","文書であれば、話題のChatGPTのもとになっている「GPT-2」「GPT-3」「GPT-4」、Google検索にも活用されている「BERT」「PaLM」など"],"metadata":{"id":"MqzxcQkMGWyb"}},{"cell_type":"markdown","source":["## 違い\n","\n","従来はデータの集合から何らかの傾向を抽出し、特定のデータを抽出する「特定」「予測」が主であった\n","- これらをまとめてDiscriminative AI と呼ぶ\n","\n","生成AIは、新たにデータを生成することができるため、「創造」が可能となる\n","\n","今まで人間が行っていた0から何かを生み出すことがAIでもできるようになるのではないかと期待されている\n","\n","画像領域におけるビジネスの転換が話題かつ問題点も指摘されているが、今後執筆・レポート・コピーライティング、コーディング、動画編集、作曲や3Dモデリングに関しても、同様の流れが進むと考えられる\n","\n","マーケティング資料はAIにコンセプトのみ伝えれば完成する、自分の好みの音楽をいくつか指示するだけでオリジナル楽曲が再生される、テイストを指示すれば家具や内装も美麗にデザインを決めてくれるど\n","\n"],"metadata":{"id":"CVWqc3NwGUR6"}},{"cell_type":"markdown","source":["## 問題\n","\n","\n"],"metadata":{"id":"XCf_rddTHTMh"}},{"cell_type":"markdown","source":["### 開発や公開時のリスク、権利、倫理を巡る問題\n","\n","- 学習に用いたデータそのものの著作権をどのように扱うのか\n"," - 多くの画像生成AIはNSFW(Not Safe For Work)フィルターを用いているが、完全ではない\n","- Deepfakeをどのように判断するのか\n","- 現実世界における明確な権利や責任などの立場を持たない\n","  - AIが生成したコンテンツが帰属する著作権が明確になっていない\n","  - 生成モデルを攻撃することで学習データを復元できるという研究がある\n","\n","> 対策(既出)\n","> - スケーリング則による大規模データセットの利用\n","> - 応答の安全性確保のため、人の好みに合わせて強化学習する際の報酬をより詳細に設計する\n"],"metadata":{"id":"f93ZH6ZuwYSk"}},{"cell_type":"markdown","source":["### 技術課題\n","\n","- ChatGPTを例にとると、流暢だが正しい内容と全く異なる生成結果を出力する問題(hallucination)\n","  - hallucinationには、入力したテキストを読み違える場合や、外部知識が必要な場合に捏造する場合の2つに分類され、多くが後者である\n","\n","> 対策(一部既出)\n","> - 外部の知識ソースを参照する機能を付与する\n","> - 生成結果にウェブ検索による根拠を提示する\n","> - 学習データを特定用途に限定する\n","\n","- 帰納的な論理構造を問う質問には6割程度しか正答できない\n","\n","\n","- 専門性の高い医療レポートを非専門家向けに要約するタスクではおよそ正しく実行できるが、結果の3割は重要な情報が欠損した\n","- 画像生成において生成をコントロールしにくい(最近できつつある)\n","\n","> 対策(一部既出)\n","> - 推論の中間結果をモデルに出力させる\n","> - 生成指示テキストを思考段階に分け、質問意図を解釈しやすくする\n","> - 画像生成では、入力テキストの変更部分を検出して画像の生成過程に反映する、生成したいスタイルや構図の画像を入力の一部として使用する\n","> - その他入力プロンプトの工夫"],"metadata":{"id":"u5zsLpZUwaSK"}},{"cell_type":"markdown","source":["## リスク\n","\n","生成AI技術は、社会と経済に革命的な変化をもたらし、人間の表現に含まれている虚偽の情報や、偏見や差別、スティグマといった非倫理的な要素も学習する可能性があり、多くの生成AIは、フィルタリングや強化学習などの手段を用いて、虚偽の内容や非倫理的な内容を表現することが抑制されている\n","\n","ChatGPTは技術的な背景を持たない人々も簡単にAIを活用することができるようになり、AI活用の民主化が進んでいる\n","\n","このような時代にあることは、米オープンAIのサム・アルトマンが慶應三田での講演で、「あなたたちは幸運な世代だ。新しい技術について心配する必要はなく、なじむことが大切だ」と発言しているとおり、チャンスであり、チャンスを生かさない手はない\n","- これは、丁度1980年代に計算機が民主化されたときと同じ状況にあ\n","- サムは、計算機登場の時に数学が要らなくなる、数学教育が不要となる極論があった時代と同じと言っている\n","\n","一方で正しくリスクも理解する\n","\n","- プロンプトや生成物に関する著作権の問題は複雑化する\n","  - 日本国内では現在、画像生成AIが著作権のある画像を学習しても改正著作権法に違反しているとは見なされない\n","  - 著作物をもとに生成した画像などのアウトプットに著作権が付くのか、複数の著作物から生成した生成物の著作権はどうなるのかなど、具体的な法整備が必要\n","\n","- また誰でも気軽にAIを活用することができるようになった反面、技術的背景のないないユーザがリスクを十分に認識せず、個人情報などを悪意なくプロンプトに入力し、問題に発展するとことも想定される\n","\n","- フィッシングメールやマルウェアプログラム、Fake情報などを簡単に生成し、サイバー犯罪に加担するケースも想定される\n","\n","守りガバナンスの功罪\n","\n","AI活用上守るべき透明性や説明可能性を確認し、必要事項を運用ポリシーに含めて順守、継続的に状況を確認するなど、インシデントを未然に防ぐ守りガバナンスを構築する一方で、イノベーションの阻害要因となりえることも認識する必要がある\n","\n","AI活用はビジネスの重要要素となり、既存業務の再構築が必要になる\n","- 経営者は迅速な経営判断が数多く求められるようになる\n","- 他分野の管理者に安易に兼務させず、専門家管理を任せ、ガバナンスをサポートする体制が必要となる\n","- 要するに人材が必要\n","\n","インシデント発生時の事前対応協議も必要\n","- AIの暴走や不具合よりも、使う上でのミスによるインシデントの方が重要\n","- 政府としてどのように対応すべきかというガイドラインも必要"],"metadata":{"id":"I1XcRDDyJkxE"}},{"cell_type":"markdown","source":["# 大規模言語モデル\n"],"metadata":{"id":"06nZknlc4JN4"}},{"cell_type":"markdown","source":["## LLMにおけるテキスト内学習\n","\n","GPT-3/4などのLLMは、推論時に与えるプロンプトからタスクを学ぶコンテキスト内学習(in-context learning)を行っている"],"metadata":{"id":"JRvk-0TnXw2B"}},{"cell_type":"markdown","source":["## Chain-of-thought prompting\n","\n","どれくらいの精度でタスクを解けるようになるかはプロンプトの与え方に依存するため、LLMの性能を最大化するようなプロンプトの与え方が研究されている\n","- 実際、このように入力せよといったノウハウが蓄積している\n","\n","例えば、LLMは小学校の算数の文章題を解くことができるが、2つ以上の思考ステップを踏む問題は苦手である\n","- 例えば、「りんごが12個あります。2個を食べ、4個をアップルパイに使いました。残りは何個あるでしょう？」という問いに対して、プロンプトで「具体例の回答部分に思考過程を含める」という工夫を行うと、解けるようになる\n","  - この挙動はまるで人間のようであるが、LLMはこのような汎化性能を有している\n","\n","- 回答を “Let's think step by step.” といった一文を入れるだけで、LLMが思考過程を含めた出力を行い、結果的に精度が上がることも知られている"],"metadata":{"id":"vzp9PJZAXwYy"}},{"cell_type":"markdown","source":["## 自然言語以外のタスク\n","\n","LLMは数学やプログラミングなど、自然言語では表現しきれない問題においても一定の成果を出している\n","\n","- PaLM LLMを数学や物理の問題集でファインチューニングした「Minerva」はこれらの問題を既存手法を大幅に上回る精度で解くことができている\n","- ソースコードのコーパスを用いた事前学習と強化学習によるファインチューニングを行ったCodeRLは競技プログラミングの問題を解くことができる\n","\n","- 視覚言語モデル(vision-language model; VLM)と呼ばれる、画像や動画データも扱えるLLMが提案されている\n","  - Flamingoは、LLMと画像エンコーダをAttentionで繋ぐことで、画像情報を踏まえたテキスト生成が可能"],"metadata":{"id":"h4p2lyYfX5nc"}},{"cell_type":"markdown","source":["### 人間との協調\n","\n","LLMは様々なタスクに適応する能力を有している一方、事前学習ではあくまで「次のトークンを予測するように」訓練されていることから、生成される文章の品質や正確さは最適とは言えない\n","\n","- 例えば、ループ再生のように同じ言葉を繰り返す場合や、もっともらしく嘘や自己矛盾を生成するなどの挙動が発生する\n","\n","そこでLLMの協調性(alignment)という概念が注目されている\n","\n","- この協調性には、ユーザの指示を汲み取って適切な返答をするだけではなく、社会通念に反しないことといった暗黙的な要求も含まれる\n","\n","協調性で重要な例がInstructGPTとよばれるGPT-3をベースとしたモデルであり、次のようにして訓練されている\n","1. プロンプトと望ましい出力のペアを人手で作る\n","1. 1.を教師データとしてGPT-3をファインチューニングする(これを方策の初期値とする)\n","1. プロンプトを2.の方策に入れて複数の出力をサンプルし、人手で好ましい順に序列を与える\n","1. 3.を教師データとして報酬モデル(GPT-3だが2.とは別物)を訓練する\n","1. 4.の報酬モデルを使って2.の方策を強化学習で訓練する(InstructGPT)\n","\n","人間によるフィードバックに基づいてLLMを強化学習させる試みはRLHF(Reinforcement Learning from Human Feedback)と呼ばれ、フロンティアとして注目を集めており、ChatGPT もその一例である"],"metadata":{"id":"7XsBX1pGX8iF"}},{"cell_type":"markdown","source":["## 計算コストの削減\n","\n","LLMは計算コストが大きいため、実用上の制約も大きい\n","\n","- この緩和のために、訓練時のコスト削減や訓練後のモデル軽量化など様々な対策が考案されている\n","\n","Chinchillaでは、次のような方針で軽量化を図っている\n","\n","- 与えられた(小さめの)FLOPsの中でTransformer型LMの最適なパラメータ数を探索する予備実験を実施\n","\n","  - FLOPS(Floating-point Operations Per Second)は、計算機の性能指標指標であり、一般に用いられ、本来こちらを指すと考えた方が良い\n","\n","  - FLOPs(FLoating-point OPerationS)は、単純に計算量であり、単位時間ではない\n","\n","- 得られたFLOPsと最適なパラメータ数の組をべき関数でフィッティングすることで、GPT-3などはFLOPsに対してパラメータ数が多すぎることがわかる\n","\n","  - Chinchillaこのようにして得られた最適なパラメータ数に従って設計されている\n","\n","- Chinchillaは同じFLOPsでより多いパラメータを持つGopherモデルよりも下流タスクにおいて良いスコアを獲得していることから次のこと明らかにした\n","  - 単にLLMが軽量化できるということだけでなく、多くのLLMが十分に訓練されていない点も明らかにした\n","  - FLOPsを増やすためには、より大規模なデータセットを作成する必要がある\n","\n","- FlashAttentionはFLOPsではなくメモリIOに着目しAttentionの計算を近似なしで効率化\n","  - Attentionの計算ボトルネックがGPUのSRAMとHBM(high bandwidth memory)間のデータのやり取りにあることから、これを削減するための計算方法を考案している\n","  - Attentionの計算で2倍から4倍の高速化と10倍から20倍のメモリ削減を達成\n","  - GPT-2の訓練で2倍以上の高速化\n","  - FlashAttentionはすでにPyTorchやtransformersなどの主要ライブラリに実装されている\n","- 訓練後のモデル軽量化という観点で、LLMやTransformerに特化した量子化や蒸留、枝刈りなどの手法が提案されている"],"metadata":{"id":"zMBVO6qlgJO3"}},{"cell_type":"markdown","source":["# 強化学習\n"],"metadata":{"id":"lOvD0jrMXt1T"}},{"cell_type":"markdown","source":["\n","## オフライン強化学習としてのDecision Transformer\n","\n"],"metadata":{"id":"ShuS68Xj1Wcb"}},{"cell_type":"markdown","source":["### 分布シフト\n","\n","強化学習では、試行錯誤により足りない情報を適宜収集して学習する手法を選択する\n","\n","オフライン強化学習では追加でデータを収集することができないため、データが存在しない部分の価値を適切な値に設定することができない、つまり、価値の過大評価につながる\n","\n","このような問題を分布シフトと呼ぶ\n"],"metadata":{"id":"nWTdBgpo1ZDj"}},{"cell_type":"markdown","source":["### Decision Transformer\n","\n","Decision Transformerはオフライン強化学習手法の1つであるが、強化学習問題を系列問題として扱うため分布シフトが発生せず、オフライン強化学習の問題を言語モデリングのようにして解くTransformer\n","\n","- Decision Transformerの入力は報酬・状態・行動、出力は行動\n","- 報酬はスカラー、状態や行動はベクトルであり、扱うデータは画像やモータの角度など多種多様に対応\n","- 報酬・状態・行動ごとに別々の埋め込み層を適用しTransformerへ入力できるベクトルへサイズへと変換し、最後にPositional Encdingを当てはめてTransformerへ入力する\n","- 評価の際の報酬部分は人間で決める\n","  - Decision Transformerでは、強化学習を報酬による条件付き系列問題として解いているため、指定する報酬の値が小さいと、質の低いとされる行動が出力され、逆に大きいと、質の高いとされる行動が出力される\n","\n","価値を定義して方策を学習するタイプの強化学習手法の場合、価値が最大となる行動の確率分布しか分かりませんが、Decision Transformerでは、それ以外の行動についても報酬の予測値を変えてあげることで出力させることができます。\n","\n","このように、Decision Transformerでは、強化学習を系列問題として解き、他の強化学習手法とは全く異なる\n","- 未知のタスクへの適応性やスケーリング則のようなLLMが持つ性質をDecision Transformerでも確認されている\n","- 特に何かしらの条件を伴う状態遷移、例えばゴールに単純に近づくだけでなく、ゴールの扉をあけるために事前に鍵を取得しなければならないといった問題では断トツの性能を発揮する"],"metadata":{"id":"ENshkYJs1etI"}},{"cell_type":"markdown","source":["# 最後に"],"metadata":{"id":"gEvkoi6nw8Cf"}},{"cell_type":"markdown","source":["コンテンツやモノを膨大なデータを用いて学習し、結果として創造的かつ現実的な、新しいアウトプットを生み出す機械学習手法(Generative AI)が席巻している\n","\n","実際、以下のキーワードを元に調べてみるとよい\n","\n","- 画像をテキストから生成 (Stable diffusion)\n","- 答えとなるテキストを質問や会話から生成 (ChatGPT)\n","- ソフトウェアコードを自動生成 (Copilot)\n","- 動画をテキストから生成 (Phenaki)\n","- 音楽をテキストから生成 (Mubert)\n","- ごく短い音声から真似た音声を生成 (VALL-E)\n","- テキストから3Dオブジェクト(DreamFusion)\n","\n","これらは、例えば画像認識のように特定の課題にのみ対応するのではなく、人間と同様各種課題を同時に処理可能な人工知能を汎用人工知能(Artificial General Intelligence)と呼ぶが、その前Proto-AGIと呼ばれるようになった\n","\n","もちろん、AGIは実現していない。ただ、AGIとの共存を本当に考えるような時期になったのかもしれない。\n","\n","例えば複数の入力情報をもとに処理を行うマルチモーダルAIも注目されている\n","\n","- 言語も画像も動画も一つのモデルで理解つまり区別する視覚言語モデル(Flamingo、PaLI)\n","- 映像基盤モデルとしてビデオ分類、テキストビデオ検索、ビデオキャプション、ビデオ質問応答モデル(VideoCoca)、ビデオ認識・検出、ビデオ言語アライメントなど様々なビデオタスク処理モデル(InternVideo)\n","- 自然言語で指示すると処理順序なども含めて対応するロボット制御(PaLM-SayCan)、その発展(RT-1)\n","様々なゲーム、チャット、ロボット操作ができる(Generarlist Agenet Gato)\n","\n","など、2022年はさらに発展した。これを追いかけるのか?もはやその判断が求められている\n","- そしてここに、ChatGPTの発展がある\n","- ChatGPTのマルチモーダル化に期待\n"],"metadata":{"id":"XCcdok1QqyGo"}},{"cell_type":"markdown","source":["# 試してみよう\n","\n","既に、Stable Diffusion、ChatGPTは例を示している\n","\n"],"metadata":{"id":"bjOCmCRDvqAv"}},{"cell_type":"markdown","source":["## Copilot\n","\n","### Visual Studio 2022をインストールする\n","こちらは、各自で行って下さい\n","- コミュニティバージョンは無償で利用できます\n","\n","### Visual Studio 拡張機能をインストールする\n","- GitHub Copilot を使うには、最初に Visual Studio 拡張機能をインストールする必要がある\n","  - Visual Studio ツールバーの\"拡張機能\"にある\"拡張機能の管理\"を選択\n","  - \"拡張機能の管理\"ウィンドウで、\"Visual Studio Marketplace\"を選択、GitHub Copilot 拡張機能を検索しダウンロードする\n","  - Visual Studioを再起動する\n","  - Visual Studioでプロジェクトを開く\n","  - デバイスのアクティブ化コードをコピーする\n","    - ブラウザーにデバイスのアクティブ化ウィンドウが表示されるので、Visual Studioに表示されている8桁文字のデバイスコードを貼り付け\"Continue\"を選択\n","    - ブラウザでAuthorize GitHub Copilot Pluginを選択\n","  - コードを貼り付けるか実際に記述する\n","  - GitHub からGitHub Copilot に必要なアクセス許可が要求されるので、\"GitHub Copilot プラグインの認可(Allow)\"を選択する\n","  - アクセス許可を承認すると、Visual Studio に確認が表示される\n","\n","これで準備ができたので、最初の候補を表示してみるとよい\n","\n"],"metadata":{"id":"GWaLOar6xM3Y"}}]}